- [**H∆∞·ªõng D·∫´n C√†i ƒê·∫∑t MongoDB Sharded Cluster**](#h∆∞·ªõng-d·∫´n-c√†i-ƒë·∫∑t-mongodb-sharded-cluster)
  - [**M·ª•c L·ª•c L√Ω Thuy·∫øt v√† Th·ª±c H√†nh**](#m·ª•c-l·ª•c-l√Ω-thuy·∫øt-v√†-th·ª±c-h√†nh)
    - [**Ph·∫ßn I: L√Ω Thuy·∫øt N·ªÅn T·∫£ng MongoDB Sharding**](#ph·∫ßn-i-l√Ω-thuy·∫øt-n·ªÅn-t·∫£ng-mongodb-sharding)
    - [**Ph·∫ßn II: Th·ª±c H√†nh Tri·ªÉn Khai**](#ph·∫ßn-ii-th·ª±c-h√†nh-tri·ªÉn-khai)
  - [**Ph·∫ßn I: L√Ω Thuy·∫øt N·ªÅn T·∫£ng MongoDB Sharding**](#ph·∫ßn-i-l√Ω-thuy·∫øt-n·ªÅn-t·∫£ng-mongodb-sharding-1)
    - [**Ch∆∞∆°ng 1: Ki·∫øn Tr√∫c MongoDB Sharded Cluster**](#ch∆∞∆°ng-1-ki·∫øn-tr√∫c-mongodb-sharded-cluster)
      - [**C√°c Th√†nh Ph·∫ßn C·ªët L√µi:**](#c√°c-th√†nh-ph·∫ßn-c·ªët-l√µi)
    - [**Ch∆∞∆°ng 2: Nguy√™n L√Ω Ph√¢n T√°n D·ªØ li·ªáu (Data Distribution)**](#ch∆∞∆°ng-2-nguy√™n-l√Ω-ph√¢n-t√°n-d·ªØ-li·ªáu-data-distribution)
      - [**Shard Key - Ch√¨a Kh√≥a C·ªßa Sharding**](#shard-key---ch√¨a-kh√≥a-c·ªßa-sharding)
    - [**Ch∆∞∆°ng 3: C∆° Ch·∫ø Replica Set v√† High Availability**](#ch∆∞∆°ng-3-c∆°-ch·∫ø-replica-set-v√†-high-availability)
      - [**Replica Set Fundamentals**](#replica-set-fundamentals)
    - [**Ch∆∞∆°ng 4: Security Authentication v√† Authorization Flow**](#ch∆∞∆°ng-4-security-authentication-v√†-authorization-flow)
      - [**Multi-Layer Security Architecture**](#multi-layer-security-architecture)
    - [**Ch∆∞∆°ng 5: Backup Strategy v√† Disaster Recovery**](#ch∆∞∆°ng-5-backup-strategy-v√†-disaster-recovery)
      - [**Comprehensive Backup Strategy**](#comprehensive-backup-strategy)
  - [**Ki·∫øn Tr√∫c Tri·ªÉn Khai C·ª• Th·ªÉ**](#ki·∫øn-tr√∫c-tri·ªÉn-khai-c·ª•-th·ªÉ)
    - [**Giai ƒëo·∫°n 1: Chu·∫©n b·ªã M√¥i tr∆∞·ªùng (L√†m tr√™n C·∫¢ 3 M√ÅY)**](#giai-ƒëo·∫°n-1-chu·∫©n-b·ªã-m√¥i-tr∆∞·ªùng-l√†m-tr√™n-c·∫£-3-m√°y)
      - [**1. C·∫•u h√¨nh File `/etc/hosts`**](#1-c·∫•u-h√¨nh-file-etchosts)
      - [**2. T·∫Øt Transparent Huge Pages (THP)**](#2-t·∫Øt-transparent-huge-pages-thp)
      - [**3. Tinh ch·ªânh Kernel (`sysctl`) v√† Gi·ªõi h·∫°n (`ulimit`)**](#3-tinh-ch·ªânh-kernel-sysctl-v√†-gi·ªõi-h·∫°n-ulimit)
    - [**Giai ƒëo·∫°n 2: C√†i ƒë·∫∑t v√† Chu·∫©n b·ªã T√†i nguy√™n**](#giai-ƒëo·∫°n-2-c√†i-ƒë·∫∑t-v√†-chu·∫©n-b·ªã-t√†i-nguy√™n)
      - [**1. C√†i ƒë·∫∑t MongoDB**](#1-c√†i-ƒë·∫∑t-mongodb)
      - [**2. T·∫°o KeyFile (X√°c th·ª±c n·ªôi b·ªô)**](#2-t·∫°o-keyfile-x√°c-th·ª±c-n·ªôi-b·ªô)
      - [**3. T·∫°o Th∆∞ m·ª•c D·ªØ li·ªáu v√† Log**](#3-t·∫°o-th∆∞-m·ª•c-d·ªØ-li·ªáu-v√†-log)
      - [**4. M·ªü Firewall**](#4-m·ªü-firewall)
    - [**Giai ƒëo·∫°n 3: D·ª±ng C·ª•m Config Server**](#giai-ƒëo·∫°n-3-d·ª±ng-c·ª•m-config-server)
      - [**1. T·∫°o File C·∫•u h√¨nh (Tr√™n C·∫¢ 3 M√ÅY)**](#1-t·∫°o-file-c·∫•u-h√¨nh-tr√™n-c·∫£-3-m√°y)
      - [**2. Kh·ªüi ƒë·ªông Config Server**](#2-kh·ªüi-ƒë·ªông-config-server)
      - [**3. Kh·ªüi t·∫°o Replica Set v√† T·∫°o User Admin**](#3-kh·ªüi-t·∫°o-replica-set-v√†-t·∫°o-user-admin)
      - [**4. B·∫≠t X√°c th·ª±c v√† Kh·ªüi ƒë·ªông l·∫°i**](#4-b·∫≠t-x√°c-th·ª±c-v√†-kh·ªüi-ƒë·ªông-l·∫°i)
      - [**4. B·∫≠t X√°c th·ª±c v√† Kh·ªüi ƒë·ªông l·∫°i**](#4-b·∫≠t-x√°c-th·ª±c-v√†-kh·ªüi-ƒë·ªông-l·∫°i-1)
    - [**Giai ƒëo·∫°n 4: D·ª±ng c√°c C·ª•m Shard**](#giai-ƒëo·∫°n-4-d·ª±ng-c√°c-c·ª•m-shard)
      - [**1. T·∫°o File C·∫•u h√¨nh (Tr√™n C·∫¢ 3 M√ÅY)**](#1-t·∫°o-file-c·∫•u-h√¨nh-tr√™n-c·∫£-3-m√°y-1)
      - [**2. Kh·ªüi ƒë·ªông v√† Kh·ªüi t·∫°o Replica Set cho t·ª´ng Shard**](#2-kh·ªüi-ƒë·ªông-v√†-kh·ªüi-t·∫°o-replica-set-cho-t·ª´ng-shard)
    - [**C·∫•u h√¨nh Replica Set cho Shard1**](#c·∫•u-h√¨nh-replica-set-cho-shard1)
    - [**C·∫•u h√¨nh Replica Set cho Shard2**](#c·∫•u-h√¨nh-replica-set-cho-shard2)
    - [**C·∫•u h√¨nh Replica Set cho Shard3**](#c·∫•u-h√¨nh-replica-set-cho-shard3)
  - [Nh∆∞ v·∫≠y, **Primary ƒë∆∞·ª£c ph√¢n b·ªï ƒë·ªÅu tr√™n ba server**, ƒë·∫£m b·∫£o t√†i nguy√™n ƒë∆∞·ª£c s·ª≠ d·ª•ng t·ªëi ∆∞u v√† h·ªá th·ªëng **c√¢n b·∫±ng t·∫£i t·ªët h∆°n**.](#nh∆∞-v·∫≠y-primary-ƒë∆∞·ª£c-ph√¢n-b·ªï-ƒë·ªÅu-tr√™n-ba-server-ƒë·∫£m-b·∫£o-t√†i-nguy√™n-ƒë∆∞·ª£c-s·ª≠-d·ª•ng-t·ªëi-∆∞u-v√†-h·ªá-th·ªëng-c√¢n-b·∫±ng-t·∫£i-t·ªët-h∆°n)
    - [**Giai ƒëo·∫°n 5: D·ª±ng Mongos v√† Ho√†n thi·ªán Cluster**](#giai-ƒëo·∫°n-5-d·ª±ng-mongos-v√†-ho√†n-thi·ªán-cluster)
      - [**1. T·∫°o File C·∫•u h√¨nh Mongos (Tr√™n 1 m√°y)**](#1-t·∫°o-file-c·∫•u-h√¨nh-mongos-tr√™n-1-m√°y)
      - [**2. Kh·ªüi ƒë·ªông Mongos**](#2-kh·ªüi-ƒë·ªông-mongos)
      - [**3. Th√™m c√°c Shard v√†o Cluster**](#3-th√™m-c√°c-shard-v√†o-cluster)
      - [**4. K√≠ch ho·∫°t Sharding v√† Test**](#4-k√≠ch-ho·∫°t-sharding-v√†-test)
    - [**Giai ƒëo·∫°n 6: Debug, Ki·ªÉm tra v√† L∆∞u √Ω Production**](#giai-ƒëo·∫°n-6-debug-ki·ªÉm-tra-v√†-l∆∞u-√Ω-production)
    - [**Giai ƒëo·∫°n 7: Thao t√°c v√† Truy v·∫•n D·ªØ li·ªáu (Aggregation Framework)**](#giai-ƒëo·∫°n-7-thao-t√°c-v√†-truy-v·∫•n-d·ªØ-li·ªáu-aggregation-framework)
      - [**1. B√†i to√°n 1: L·ªçc, S·∫Øp x·∫øp v√† ƒê·ªãnh h√¨nh D·ªØ li·ªáu**](#1-b√†i-to√°n-1-l·ªçc-s·∫Øp-x·∫øp-v√†-ƒë·ªãnh-h√¨nh-d·ªØ-li·ªáu)
      - [**2. B√†i to√°n 2: Th·ªëng k√™ v√† Nh√≥m D·ªØ li·ªáu**](#2-b√†i-to√°n-2-th·ªëng-k√™-v√†-nh√≥m-d·ªØ-li·ªáu)
      - [**3. B√†i to√°n 3: Join D·ªØ li·ªáu gi·ªØa c√°c Collection**](#3-b√†i-to√°n-3-join-d·ªØ-li·ªáu-gi·ªØa-c√°c-collection)
    - [**Giai ƒëo·∫°n 8: Qu·∫£n tr·ªã B·∫£o m·∫≠t v√† Ng∆∞·ªùi d√πng**](#giai-ƒëo·∫°n-8-qu·∫£n-tr·ªã-b·∫£o-m·∫≠t-v√†-ng∆∞·ªùi-d√πng)
      - [**1. T·∫°o User v√† G√°n Role c√≥ s·∫µn**](#1-t·∫°o-user-v√†-g√°n-role-c√≥-s·∫µn)
      - [**2. T·∫°o Role T√πy ch·ªânh (Custom Role)**](#2-t·∫°o-role-t√πy-ch·ªânh-custom-role)
      - [**3. C·∫•u h√¨nh Audit Log (Ghi l·∫°i ho·∫°t ƒë·ªông)**](#3-c·∫•u-h√¨nh-audit-log-ghi-l·∫°i-ho·∫°t-ƒë·ªông)
    - [**Giai ƒëo·∫°n 9: Qu·∫£n tr·ªã N√¢ng cao v√† V·∫≠n h√†nh Replica Set**](#giai-ƒëo·∫°n-9-qu·∫£n-tr·ªã-n√¢ng-cao-v√†-v·∫≠n-h√†nh-replica-set)
      - [**1. ƒêi·ªÅu ch·ªânh Primary (Election)**](#1-ƒëi·ªÅu-ch·ªânh-primary-election)
      - [**2. C·∫•u h√¨nh Hidden Node**](#2-c·∫•u-h√¨nh-hidden-node)
      - [**3. ƒêi·ªÅu ch·ªânh K√≠ch th∆∞·ªõc Oplog**](#3-ƒëi·ªÅu-ch·ªânh-k√≠ch-th∆∞·ªõc-oplog)
    - [**Giai ƒëo·∫°n 10: Sao l∆∞u, Ph·ª•c h·ªìi v√† Gi√°m s√°t**](#giai-ƒëo·∫°n-10-sao-l∆∞u-ph·ª•c-h·ªìi-v√†-gi√°m-s√°t)
      - [**1. Sao l∆∞u v√† Ph·ª•c h·ªìi (`mongodump` / `mongorestore`)**](#1-sao-l∆∞u-v√†-ph·ª•c-h·ªìi-mongodump--mongorestore)
      - [**2. Ph·ª•c h·ªìi t·∫°i m·ªôt th·ªùi ƒëi·ªÉm (Point-in-Time Recovery)**](#2-ph·ª•c-h·ªìi-t·∫°i-m·ªôt-th·ªùi-ƒëi·ªÉm-point-in-time-recovery)
      - [**3. Gi√°m s√°t Hi·ªáu nƒÉng**](#3-gi√°m-s√°t-hi·ªáu-nƒÉng)
    - [**Giai ƒëo·∫°n 11: T·ªëi ∆∞u Hi·ªáu nƒÉng Truy v·∫•n v·ªõi Index**](#giai-ƒëo·∫°n-11-t·ªëi-∆∞u-hi·ªáu-nƒÉng-truy-v·∫•n-v·ªõi-index)
      - [**1. C√°c lo·∫°i Index c∆° b·∫£n v√† c√°ch t·∫°o**](#1-c√°c-lo·∫°i-index-c∆°-b·∫£n-v√†-c√°ch-t·∫°o)
      - [**2. Ph√¢n t√≠ch K·∫ø ho·∫°ch Th·ª±c thi (Execution Plan)**](#2-ph√¢n-t√≠ch-k·∫ø-ho·∫°ch-th·ª±c-thi-execution-plan)
    - [**Giai ƒëo·∫°n 12: Chi·∫øn l∆∞·ª£c Sharding v√† Ph√¢n ph·ªëi D·ªØ li·ªáu**](#giai-ƒëo·∫°n-12-chi·∫øn-l∆∞·ª£c-sharding-v√†-ph√¢n-ph·ªëi-d·ªØ-li·ªáu)
      - [**1. L·ª±a ch·ªçn Chi·∫øn l∆∞·ª£c Shard Key**](#1-l·ª±a-ch·ªçn-chi·∫øn-l∆∞·ª£c-shard-key)
      - [**2. B·∫´y ng∆∞·ªùi m·ªõi khi ch·ªçn Shard Key**](#2-b·∫´y-ng∆∞·ªùi-m·ªõi-khi-ch·ªçn-shard-key)
      - [**3. Ki·ªÉm tra Ph√¢n ph·ªëi D·ªØ li·ªáu**](#3-ki·ªÉm-tra-ph√¢n-ph·ªëi-d·ªØ-li·ªáu)
    - [**Giai ƒëo·∫°n 13: Gi√°m s√°t N√¢ng cao v√† T·ª± ƒë·ªông h√≥a V·∫≠n h√†nh**](#giai-ƒëo·∫°n-13-gi√°m-s√°t-n√¢ng-cao-v√†-t·ª±-ƒë·ªông-h√≥a-v·∫≠n-h√†nh)
      - [**1. Ph√¢n t√≠ch c√°c T√°c v·ª• ƒëang ch·∫°y (`db.currentOp`)**](#1-ph√¢n-t√≠ch-c√°c-t√°c-v·ª•-ƒëang-ch·∫°y-dbcurrentop)
      - [**2. "H·∫° s√°t" c√°c Truy v·∫•n G√¢y h·∫°i (`db.killOp`)**](#2-h·∫°-s√°t-c√°c-truy-v·∫•n-g√¢y-h·∫°i-dbkillop)
      - [**3. T·ª± ƒë·ªông h√≥a Gi√°m s√°t T√¨nh tr·∫°ng Replica Set**](#3-t·ª±-ƒë·ªông-h√≥a-gi√°m-s√°t-t√¨nh-tr·∫°ng-replica-set)
    - [**Giai ƒëo·∫°n 14: K·ªπ thu·∫≠t Ph·ª•c h·ªìi N√¢ng cao - Point-in-Time Recovery (PITR)**](#giai-ƒëo·∫°n-14-k·ªπ-thu·∫≠t-ph·ª•c-h·ªìi-n√¢ng-cao---point-in-time-recovery-pitr)
      - [**Quy tr√¨nh C·ª©u d·ªØ li·ªáu khi X√≥a nh·∫ßm**](#quy-tr√¨nh-c·ª©u-d·ªØ-li·ªáu-khi-x√≥a-nh·∫ßm)
    - [**Giai ƒëo·∫°n 15: Tinh ch·ªânh T·∫ßng L∆∞u tr·ªØ (Storage Engine Tuning)**](#giai-ƒëo·∫°n-15-tinh-ch·ªânh-t·∫ßng-l∆∞u-tr·ªØ-storage-engine-tuning)
      - [**1. C·∫•u h√¨nh K√≠ch th∆∞·ªõc WiredTiger Cache**](#1-c·∫•u-h√¨nh-k√≠ch-th∆∞·ªõc-wiredtiger-cache)
    - [**T·ªïng k·∫øt v√† Con ƒë∆∞·ªùng Ti·∫øp theo**](#t·ªïng-k·∫øt-v√†-con-ƒë∆∞·ªùng-ti·∫øp-theo)
  - [**Ph·∫ßn III: V·∫≠n H√†nh Production v√† Best Practices**](#ph·∫ßn-iii-v·∫≠n-h√†nh-production-v√†-best-practices)
    - [**Giai ƒëo·∫°n 16: Production Readiness Checklist**](#giai-ƒëo·∫°n-16-production-readiness-checklist)
      - [**1. Security Hardening cho Production**](#1-security-hardening-cho-production)
      - [**2. Systemd Service Files cho Production**](#2-systemd-service-files-cho-production)
      - [**3. Advanced Monitoring v·ªõi Prometheus v√† Grafana**](#3-advanced-monitoring-v·ªõi-prometheus-v√†-grafana)
    - [**Giai ƒëo·∫°n 17: Advanced Operational Procedures**](#giai-ƒëo·∫°n-17-advanced-operational-procedures)
      - [**1. Zero-Downtime Maintenance Procedures**](#1-zero-downtime-maintenance-procedures)
      - [**2. Disaster Recovery Procedures**](#2-disaster-recovery-procedures)
    - [**Giai ƒëo·∫°n 18: Performance Optimization v√† Capacity Planning**](#giai-ƒëo·∫°n-18-performance-optimization-v√†-capacity-planning)
      - [**1. Advanced Performance Monitoring**](#1-advanced-performance-monitoring)
      - [**2. Capacity Planning Guidelines**](#2-capacity-planning-guidelines)
    - [**Giai ƒëo·∫°n 19: Troubleshooting Common Issues**](#giai-ƒëo·∫°n-19-troubleshooting-common-issues)
      - [**1. Balancer Issues**](#1-balancer-issues)
      - [**2. Replica Set Election Issues**](#2-replica-set-election-issues)
    - [**K·∫øt lu·∫≠n: MongoDB Production Excellence**](#k·∫øt-lu·∫≠n-mongodb-production-excellence)


# **H∆∞·ªõng D·∫´n C√†i ƒê·∫∑t MongoDB Sharded Cluster**

## **M·ª•c L·ª•c L√Ω Thuy·∫øt v√† Th·ª±c H√†nh**

### **Ph·∫ßn I: L√Ω Thuy·∫øt N·ªÅn T·∫£ng MongoDB Sharding**
- [**Ch∆∞∆°ng 1: Ki·∫øn Tr√∫c MongoDB Sharded Cluster**](#ch∆∞∆°ng-1-ki·∫øn-tr√∫c-mongodb-sharded-cluster)
- [**Ch∆∞∆°ng 2: Nguy√™n L√Ω Ph√¢n T√°n D·ªØ Li·ªáu (Data Distribution)**](#ch∆∞∆°ng-2-nguy√™n-l√Ω-ph√¢n-t√°n-d·ªØ-li·ªáu-data-distribution)
- [**Ch∆∞∆°ng 3: C∆° Ch·∫ø Replica Set v√† High Availability**](#ch∆∞∆°ng-3-c∆°-ch·∫ø-replica-set-v√†-high-availability)
- [**Ch∆∞∆°ng 4: Security Authentication v√† Authorization Flow**](#ch∆∞∆°ng-4-security-authentication-v√†-authorization-flow)
- [**Ch∆∞∆°ng 5: Backup Strategy v√† Disaster Recovery**](#ch∆∞∆°ng-5-backup-strategy-v√†-disaster-recovery)

### **Ph·∫ßn II: Th·ª±c H√†nh Tri·ªÉn Khai**

---

## **Ph·∫ßn I: L√Ω Thuy·∫øt N·ªÅn T·∫£ng MongoDB Sharding**

### **Ch∆∞∆°ng 1: Ki·∫øn Tr√∫c MongoDB Sharded Cluster**

```mermaid
flowchart TD
    subgraph "Conceptual Architecture"
        APP[Client Applications] --> ROUTER[Query Router<br/>Mongos]
        ROUTER --> METADATA[Metadata Storage<br/>Config Servers]
        ROUTER --> SHARDS[Data Storage<br/>Shards]
        
        subgraph "High-Level Components"
            METADATA --> CS[Config Server<br/>Replica Set]
            SHARDS --> S1[Shard 1<br/>Replica Set]
            SHARDS --> S2[Shard 2<br/>Replica Set]
            SHARDS --> S3[Shard N<br/>Replica Set]
        end
    end
    
    subgraph "Data Flow"
        WRITE[Write Operation] --> ROUTER
        READ[Read Operation] --> ROUTER
        ROUTER --> |"Route based on<br/>Shard Key"| TARGET[Target Shard]
        TARGET --> RESULT[Operation Result]
        RESULT --> APP
    end
    
    style APP fill:#e3f2fd
    style ROUTER fill:#fff3e0
    style METADATA fill:#f3e5f5
    style SHARDS fill:#e8f5e8
```

**MongoDB Sharded Cluster** l√† m·ªôt ki·∫øn tr√∫c ph√¢n t√°n ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi·∫£i quy·∫øt hai th√°ch th·ª©c ch√≠nh trong qu·∫£n l√Ω c∆° s·ªü d·ªØ li·ªáu quy m√¥ l·ªõn:

1. **Horizontal Scaling (M·ªü r·ªông theo chi·ªÅu ngang)**: Thay v√¨ n√¢ng c·∫•p ph·∫ßn c·ª©ng c·ªßa m·ªôt m√°y ch·ªß duy nh·∫•t (vertical scaling), sharding cho ph√©p ph√¢n t√°n d·ªØ li·ªáu v√† t·∫£i truy v·∫•n tr√™n nhi·ªÅu m√°y ch·ªß.

2. **High Availability (T√≠nh s·∫µn s√†ng cao)**: M·ªói th√†nh ph·∫ßn trong cluster ƒë·ªÅu ƒë∆∞·ª£c tri·ªÉn khai d∆∞·ªõi d·∫°ng Replica Set, ƒë·∫£m b·∫£o kh√¥ng c√≥ Single Point of Failure.

#### **C√°c Th√†nh Ph·∫ßn C·ªët L√µi:**

**1. Mongos (Query Router)**
- L√† ƒëi·ªÉm ti·∫øp x√∫c duy nh·∫•t gi·ªØa ·ª©ng d·ª•ng v√† cluster
- Kh√¥ng l∆∞u tr·ªØ d·ªØ li·ªáu, ch·ªâ ƒë·ªãnh tuy·∫øn truy v·∫•n
- Ph√¢n t√≠ch Shard Key ƒë·ªÉ x√°c ƒë·ªãnh shard ƒë√≠ch
- C√≥ th·ªÉ tri·ªÉn khai nhi·ªÅu instance ƒë·ªÉ c√¢n b·∫±ng t·∫£i

**2. Config Servers**
- L∆∞u tr·ªØ metadata c·ªßa to√†n b·ªô cluster
- Qu·∫£n l√Ω th√¥ng tin v·ªÅ chunks, shards, v√† shard keys
- Lu√¥n tri·ªÉn khai d∆∞·ªõi d·∫°ng Replica Set (t·ªëi thi·ªÉu 3 nodes)
- C·ª±c k·ª≥ quan tr·ªçng - n·∫øu m·∫•t Config Server, to√†n b·ªô cluster s·∫Ω kh√¥ng ho·∫°t ƒë·ªông

**3. Shards**
- C√°c m√°y ch·ªß th·ª±c s·ª± l∆∞u tr·ªØ d·ªØ li·ªáu
- M·ªói shard l√† m·ªôt Replica Set ƒë·ªôc l·∫≠p
- D·ªØ li·ªáu ƒë∆∞·ª£c ph√¢n ph·ªëi d·ª±a tr√™n Shard Key
- C√≥ th·ªÉ th√™m/b·ªõt shard theo nhu c·∫ßu

### **Ch∆∞∆°ng 2: Nguy√™n L√Ω Ph√¢n T√°n D·ªØ li·ªáu (Data Distribution)**

```mermaid
flowchart TD
    subgraph "Sharding Process"
        DOC["New Document<br/>{_id: 'abc', userId: 12345, data: '...'}"] --> SK["Extract Shard Key<br/>userId: 12345"]
        SK --> HASH["Calculate Hash/Range<br/>hash(12345) = 0x7A2B..."]
        HASH --> CHUNK["Determine Target Chunk<br/>Chunk_A: [0x7000... - 0x8000...]"]
        CHUNK --> SHARD["Route to Shard<br/>Shard02"]
        SHARD --> STORE["Store Document"]
    end
    
    subgraph "Chunk Management"
        SIZE["Monitor Chunk Size"] --> SPLIT{"Size > 64MB?"}
        SPLIT -->|Yes| DIVIDE["Split Chunk"]
        SPLIT -->|No| CONTINUE["Continue Monitoring"]
        DIVIDE --> BALANCE["Trigger Balancer"]
        BALANCE --> MIGRATE["Migrate Chunks"]
    end
    
    style DOC fill:#e3f2fd
    style SHARD fill:#e8f5e8
    style SPLIT fill:#fff3e0
```

#### **Shard Key - Ch√¨a Kh√≥a C·ªßa Sharding**

Shard Key l√† m·ªôt ho·∫∑c nhi·ªÅu tr∆∞·ªùng trong document ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ quy·∫øt ƒë·ªãnh document ƒë√≥ s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ tr√™n shard n√†o. ƒê√¢y l√† quy·∫øt ƒë·ªãnh quan tr·ªçng nh·∫•t khi thi·∫øt k·∫ø sharded cluster.

**C√°c Chi·∫øn L∆∞·ª£c Shard Key:**

1. **Hashed Sharding**
   - MongoDB t√≠nh hash c·ªßa shard key value
   - Ph√¢n ph·ªëi ƒë·ªÅu nh·∫•t, tr√°nh hotspot
   - Kh√¥ng hi·ªáu qu·∫£ cho range queries
   - Th√≠ch h·ª£p cho write-heavy workloads

2. **Ranged Sharding**
   - Ph√¢n chia d·ª±a tr√™n gi√° tr·ªã th·ª±c c·ªßa shard key
   - Hi·ªáu qu·∫£ cho range queries
   - C√≥ nguy c∆° t·∫°o hotspot n·∫øu ch·ªçn key kh√¥ng ph√π h·ª£p
   - Th√≠ch h·ª£p khi c√≥ query patterns r√µ r√†ng

**Chunk v√† Balancing:**
- D·ªØ li·ªáu ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh c√°c chunk (m·∫∑c ƒë·ªãnh 64MB)
- Balancer t·ª± ƒë·ªông di chuy·ªÉn chunk gi·ªØa c√°c shard
- Qu√° tr√¨nh migration di·ªÖn ra trong su·ªët, kh√¥ng ·∫£nh h∆∞·ªüng availability

### **Ch∆∞∆°ng 3: C∆° Ch·∫ø Replica Set v√† High Availability**

```mermaid
sequenceDiagram
    participant C as Client
    participant P as Primary
    participant S1 as Secondary 1
    participant S2 as Secondary 2
    participant A as Arbiter
    
    Note over P,S2: Normal Operation
    C->>P: Write Operation
    P->>S1: Replicate via Oplog
    P->>S2: Replicate via Oplog
    P->>C: Acknowledge Write
    
    Note over P,S2: Primary Failure Scenario
    P->>X: Primary Fails
    S1->>S2: Election Request
    S1->>A: Request Vote
    S2->>S1: Vote Granted
    A->>S1: Vote Granted
    S1->>S1: Becomes New Primary
    
    Note over S1,S2: Service Resumed
    C->>S1: Write Operation (to new primary)
    S1->>S2: Continue Replication
```

#### **Replica Set Fundamentals**

M·ªói shard trong MongoDB cluster ƒë·ªÅu ƒë∆∞·ª£c tri·ªÉn khai d∆∞·ªõi d·∫°ng Replica Set ƒë·ªÉ ƒë·∫£m b·∫£o high availability v√† data durability.

**C√°c Lo·∫°i Node trong Replica Set:**

1. **Primary Node**
   - Nh·∫≠n t·∫•t c·∫£ write operations
   - C√≥ th·ªÉ ph·ª•c v·ª• read operations
   - Duy tr√¨ oplog (operations log)
   - T·ª± ƒë·ªông ƒë∆∞·ª£c b·∫ßu ch·ªçn qua election process

2. **Secondary Nodes**
   - Sao ch√©p d·ªØ li·ªáu t·ª´ Primary via oplog
   - C√≥ th·ªÉ ph·ª•c v·ª• read operations (v·ªõi read preference)
   - Tham gia v√†o election process
   - C√≥ th·ªÉ ƒë∆∞·ª£c c·∫•u h√¨nh v·ªõi different priorities

3. **Arbiter Node** (Optional)
   - Ch·ªâ tham gia voting, kh√¥ng l∆∞u tr·ªØ d·ªØ li·ªáu
   - Gi√∫p ph√° tie trong election v·ªõi s·ªë node ch·∫µn
   - Ti·∫øt ki·ªám t√†i nguy√™n trong small deployments

**Election Process:**
- Heartbeat mechanism gi·ªØa c√°c nodes
- Automatic failover khi Primary kh√¥ng response
- Majority voting ƒë·ªÉ b·∫ßu Primary m·ªõi
- Write concern v√† read concern ƒë·ªÉ control consistency

### **Ch∆∞∆°ng 4: Security Authentication v√† Authorization Flow**

```mermaid
flowchart TD
    subgraph "Client Authentication Flow"
        CLIENT[Client Application] --> MONGOS[Mongos Router]
        MONGOS --> |"1. Validate Credentials"| AUTHDB[(Authentication Database)]
        AUTHDB --> |"2. Return User Info + Roles"| MONGOS
        MONGOS --> |"3. Authorize Request"| OPERATION[Perform Operation]
    end
    
    subgraph "Internal Cluster Authentication"
        MONGOS2[Mongos] --> |"KeyFile/x.509"| CONFIG[Config Server]
        CONFIG --> |"KeyFile/x.509"| SHARD1[Shard 1]
        SHARD1 --> |"Replica Set Auth"| SHARD1_SEC[Shard 1 Secondary]
    end
    
    subgraph "Authorization (RBAC)"
        USER[User] --> ROLES[Assigned Roles]
        ROLES --> PRIVILEGES[Role Privileges]
        PRIVILEGES --> RESOURCES[Database/Collection]
        RESOURCES --> ACTIONS[Allowed Actions]
    end
    
    style CLIENT fill:#e3f2fd
    style AUTHDB fill:#fff3e0
    style ACTIONS fill:#e8f5e8
```

#### **Multi-Layer Security Architecture**

MongoDB sharded cluster s·ª≠ d·ª•ng m√¥ h√¨nh b·∫£o m·∫≠t ƒëa t·∫ßng:

**1. Network Security**
- Firewall configuration cho t·ª´ng port
- SSL/TLS encryption cho client connections
- Inter-cluster communication encryption

**2. Authentication (X√°c th·ª±c)**
- **Client Authentication**: SCRAM-SHA-256, x.509 certificates
- **Internal Authentication**: Shared keyFile ho·∫∑c x.509 certificates
- **Database Users**: Role-based access control

**3. Authorization (·ª¶y quy·ªÅn)**
- **Built-in Roles**: read, readWrite, dbAdmin, userAdmin, etc.
- **Custom Roles**: Fine-grained privileges
- **Resource-specific Permissions**: Database/collection level control

**4. Auditing** (Enterprise Only)
- Comprehensive audit trail
- Security event logging
- Compliance reporting

### **Ch∆∞∆°ng 5: Backup Strategy v√† Disaster Recovery**

```mermaid
flowchart TD
    subgraph "Backup Strategy"
        PROD[Production Data] --> FULL["Full Backup<br/>Daily via mongodump"]
        PROD --> OPLOG["Incremental Oplog<br/>Every 15 minutes"]
        PROD --> SNAPSHOT["Storage Snapshots<br/>LVM/Cloud snapshots"]
    end
    
    subgraph "Recovery Scenarios"
        DISASTER["Complete Disaster"] --> FULL_RESTORE["Full Restore<br/>+ Latest Oplog Replay"]
        CORRUPTION["Data Corruption"] --> PITR["Point-in-Time Recovery<br/>Oplog replay to timestamp"]
        ACCIDENT["Accidental Deletion"] --> SELECTIVE["Selective Restore<br/>Specific collections"]
    end
    
    subgraph "Recovery Validation"
        RESTORE[Restored Data] --> VERIFY["Data Integrity Check"]
        VERIFY --> INDEX["Rebuild Indexes"]
        INDEX --> TEST["Application Testing"]
        TEST --> PRODUCTION["Return to Production"]
    end
    
    style PROD fill:#e3f2fd
    style PITR fill:#fff3e0
    style PRODUCTION fill:#e8f5e8
```

#### **Comprehensive Backup Strategy**

**1. Full Backups**
- Complete database snapshots using `mongodump`
- Scheduled daily during low-traffic periods
- Stored in multiple locations (local + remote)
- Retention policy based on business requirements

**2. Incremental Backups**
- Oplog backup every 15-30 minutes
- Enables point-in-time recovery
- Smaller storage footprint
- Faster backup process

**3. Storage-Level Snapshots**
- Filesystem or volume snapshots
- Fastest backup and restore
- Requires storage-level consistency
- Ideal for large datasets

**4. Cross-Region Replication**
- Delayed replica sets for disaster recovery
- Geographic distribution of data
- Protection against regional disasters
- Network-level redundancy

---

## **Ki·∫øn Tr√∫c Tri·ªÉn Khai C·ª• Th·ªÉ**


```mermaid
graph TB
    subgraph "Client Applications"
        APP1[App 1]
        APP2[App 2]
    end
    
    subgraph "Query Router"
        MONGOS[Mongos<br/>Port 27020]
    end
    
    subgraph "Config Server Replica Set"
        CFG1[Config 1<br/>Port 27010]
        CFG2[Config 2<br/>Port 27010]
        CFG3[Config 3<br/>Port 27010]
    end
    
    subgraph "Shard 1 Replica Set"
        S1P[Shard1 Primary<br/>Port 27011]
        S1S1[Shard1 Secondary<br/>Port 27011]
        S1S2[Shard1 Secondary<br/>Port 27011]
    end
    
    subgraph "Shard 2 Replica Set"
        S2P[Shard2 Primary<br/>Port 27012]
        S2S1[Shard2 Secondary<br/>Port 27012]
        S2S2[Shard2 Secondary<br/>Port 27012]
    end
    
    subgraph "Shard 3 Replica Set"
        S3P[Shard3 Primary<br/>Port 27013]
        S3S1[Shard3 Secondary<br/>Port 27013]
        S3S2[Shard3 Secondary<br/>Port 27013]
    end
    
    APP1 --> MONGOS
    APP2 --> MONGOS
    MONGOS --> CFG1
    MONGOS --> CFG2
    MONGOS --> CFG3
    MONGOS --> S1P
    MONGOS --> S2P
    MONGOS --> S3P
    
    CFG1 --- CFG2
    CFG2 --- CFG3
    CFG3 --- CFG1
    
    S1P --- S1S1
    S1S1 --- S1S2
    S1S2 --- S1P
    
    S2P --- S2S1
    S2S1 --- S2S2
    S2S2 --- S2P
    
    S3P --- S3S1
    S3S1 --- S3S2
    S3S2 --- S3P

        %% ƒê·ªãnh nghƒ©a style cho c√°c th√†nh ph·∫ßn
    classDef clientApp fill:#E3F2FD,stroke:#1976D2,stroke-width:2px,color:#000
    classDef router fill:#FFF3E0,stroke:#F57C00,stroke-width:3px,color:#000
    classDef configServer fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px,color:#000
    classDef shardPrimary fill:#E8F5E8,stroke:#388E3C,stroke-width:3px,color:#000
    classDef shardSecondary fill:#F1F8E9,stroke:#689F38,stroke-width:2px,color:#000
    
    %% √Åp d·ª•ng style
    class APP1,APP2 clientApp
    class MONGOS router
    class CFG1,CFG2,CFG3 configServer
    class S1P,S2P,S3P shardPrimary
    class S1S1,S1S2,S2S1,S2S2,S3S1,S3S2 shardSecondary
```

B√†i h∆∞·ªõng d·∫´n n√†y s·∫Ω gi√∫p b·∫°n d·ª±ng m·ªôt c·ª•m MongoDB sharding ho√†n ch·ªânh, t·∫≠p trung v√†o vi·ªác gi·∫£i th√≠ch b·∫£n ch·∫•t v√† ch·ªâ ra nh·ªØng "b·∫´y" m√† ng∆∞·ªùi m·ªõi th∆∞·ªùng g·∫∑p.

**Ki·∫øn tr√∫c cu·ªëi c√πng:**
*   **1 C·ª•m Config Server Replica Set (3 members)**: "B·ªô n√£o" l∆∞u tr·ªØ metadata c·ªßa cluster.
*   **3 C·ª•m Shard Replica Set (m·ªói c·ª•m 3 members)**: N∆°i l∆∞u tr·ªØ v√† ph√¢n t√°n d·ªØ li·ªáu.
*   **1 Ti·∫øn tr√¨nh Mongos (Query Router)**: C·ªïng giao ti·∫øp duy nh·∫•t cho ·ª©ng d·ª•ng.

---

### **Giai ƒëo·∫°n 1: Chu·∫©n b·ªã M√¥i tr∆∞·ªùng (L√†m tr√™n C·∫¢ 3 M√ÅY)**

```mermaid
flowchart TD
    A["B·∫Øt ƒë·∫ßu thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng"] --> B["C·∫•u h√¨nh /etc/hosts"]
    B --> B1["Thi·∫øt l·∫≠p IP addresses:<br/>mongo-1: 192.168.0.38<br/>mongo-2: 192.168.0.241<br/>mongo-3: 192.168.0.215"]
    B1 --> C["ƒê·∫∑t hostname duy nh·∫•t"]
    C --> D["T·∫Øt Transparent Huge Pages"]
    D --> E["C·∫•u h√¨nh tham s·ªë sysctl"]
    E --> F["Thi·∫øt l·∫≠p gi√° tr·ªã ulimit"]
    F --> G["X·ª≠ l√Ω SELinux contexts"]
    G --> H["M√¥i tr∆∞·ªùng s·∫µn s√†ng"]
    
    %% ƒê·ªãnh nghƒ©a style classes
    classDef startNode fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    classDef configNode fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    classDef detailNode fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    classDef systemNode fill:#fff8e1,stroke:#ffa000,stroke-width:2px,color:#000
    classDef endNode fill:#e8f5e8,stroke:#388e3c,stroke-width:3px,color:#000
    
    %% √Åp d·ª•ng styles
    class A startNode
    class B,C configNode
    class B1 detailNode
    class D,E,F,G systemNode
    class H endNode
```

ƒê√¢y l√† b∆∞·ªõc n·ªÅn t·∫£ng quy·∫øt ƒë·ªãnh s·ª± ·ªïn ƒë·ªãnh c·ªßa c·∫£ h·ªá th·ªëng.

#### **1. C·∫•u h√¨nh File `/etc/hosts`**

*   **M·ª•c ƒë√≠ch c·ªët l√µi:** Vi·ªác s·ª≠ d·ª•ng c√°c hostname d·ªÖ nh·ªõ (v√≠ d·ª•: `mongo-1`) thay v√¨ ƒë·ªãa ch·ªâ IP tr·ª±c ti·∫øp (v√≠ d·ª•: `192.168.0.38`) mang l·∫°i nhi·ªÅu l·ª£i √≠ch quan tr·ªçng, ƒë·∫∑c bi·ªát trong m·ªôt m√¥i tr∆∞·ªùng ph√¢n t√°n nh∆∞ MongoDB sharded cluster:
    *   **D·ªÖ ƒë·ªçc v√† qu·∫£n l√Ω:** C·∫•u h√¨nh tr·ªü n√™n tr·ª±c quan h∆°n r·∫•t nhi·ªÅu. S·∫Ω d·ªÖ d√†ng h∆°n ƒë·ªÉ nh·ªõ v√† tham chi·∫øu ƒë·∫øn `mongo-1` trong c√°c file c·∫•u h√¨nh ho·∫∑c khi g√µ l·ªánh, thay v√¨ m·ªôt d√£y s·ªë IP.
    *   **T√≠nh nh·∫•t qu√°n trong giao ti·∫øp:** Trong c√°c h·ªá th·ªëng ph√¢n t√°n, c√°c th√†nh ph·∫ßn th∆∞·ªùng xuy√™n c·∫ßn giao ti·∫øp v·ªõi nhau b·∫±ng c√°ch g·ªçi t√™n. N·∫øu c√°c node MongoDB trong cluster s·ª≠ d·ª•ng hostname, ch√∫ng c√≥ th·ªÉ t·ª± nh·∫≠n di·ªán v√† t√¨m th·∫•y nhau m·ªôt c√°ch ƒë√°ng tin c·∫≠y.
    *   **Gi·∫£m thi·ªÉu l·ªói c·∫•u h√¨nh:** Khi ƒë·ªãa ch·ªâ IP thay ƒë·ªïi (m·∫∑c d√π kh√¥ng mong mu·ªën trong production, nh∆∞ng c√≥ th·ªÉ x·∫£y ra trong m√¥i tr∆∞·ªùng lab ho·∫∑c ph√°t tri·ªÉn), b·∫°n ch·ªâ c·∫ßn c·∫≠p nh·∫≠t m·ªôt l·∫ßn trong file `/etc/hosts` thay v√¨ ph·∫£i t√¨m ki·∫øm v√† s·ª≠a ƒë·ªïi nhi·ªÅu file c·∫•u h√¨nh c·ªßa MongoDB.
    *   **Tr√°nh "name resolution l·ªôn x·ªôn":** N·∫øu m·ªói m√°y c√≥ m·ªôt √°nh x·∫° IP-hostname kh√°c nhau ho·∫∑c kh√¥ng ƒë·∫ßy ƒë·ªß, c√°c node s·∫Ω kh√¥ng th·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c c√°c node kh√°c trong cluster. ƒêi·ªÅu n√†y d·∫´n ƒë·∫øn c√°c l·ªói kh√≥ g·ª° r·ªëi nh∆∞ "node kh√¥ng t√¨m th·∫•y", "replica set kh√¥ng th·ªÉ b·∫ßu ch·ªçn primary", ho·∫∑c "mongos kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn config server", g√¢y m·∫•t ·ªïn ƒë·ªãnh to√†n b·ªô cluster.

*   **Hostname c·ªßa h·ªá th·ªëng:** B√™n c·∫°nh vi·ªác √°nh x·∫° IP sang hostname trong `/etc/hosts`, m·ªói m√°y ch·ªß c≈©ng c·∫ßn c√≥ m·ªôt hostname *duy nh·∫•t* c·ªßa ri√™ng n√≥. Hostname n√†y l√† c√°ch m√† h·ªá ƒëi·ªÅu h√†nh v√† c√°c ·ª©ng d·ª•ng (bao g·ªìm MongoDB) t·ª± nh·∫≠n di·ªán m√¨nh trong m·∫°ng. Trong m·ªôt replica set ho·∫∑c sharded cluster, m·ªói th√†nh vi√™n ph·∫£i c√≥ m·ªôt ƒë·ªãnh danh duy nh·∫•t ƒë·ªÉ tr√°nh xung ƒë·ªôt v√† cho ph√©p c√°c thu·∫≠t to√°n b·∫ßu ch·ªçn ho·∫°t ƒë·ªông ch√≠nh x√°c.

‚ö†Ô∏è **B·∫™Y NG∆Ø·ªúI M·ªöI - Giai ƒëo·∫°n 1:**
-   **Hosts file kh√¥ng ƒë·ªìng nh·∫•t gi·ªØa c√°c m√°y:** ƒê√¢y l√† l·ªói ph·ªï bi·∫øn nh·∫•t. N·∫øu `mongo-1` bi·∫øt `mongo-2` l√† `192.168.0.241`, nh∆∞ng `mongo-2` l·∫°i nghƒ© `mongo-1` l√† m·ªôt IP kh√°c ho·∫∑c kh√¥ng t√¨m th·∫•y, ch√∫ng s·∫Ω kh√¥ng th·ªÉ thi·∫øt l·∫≠p k·∫øt n·ªëi n·ªôi b·ªô. K·∫øt qu·∫£ l√† "name resolution l·ªôn x·ªôn" v√† cluster kh√¥ng th·ªÉ kh·ªüi t·∫°o ho·∫∑c ho·∫°t ƒë·ªông ƒë√∫ng.
-   **Hostname tr√πng/ƒë·ªïi hostname nh∆∞ng kh√¥ng reboot:** Khi b·∫°n ƒë·∫∑t m·ªôt hostname m·ªõi cho m√°y b·∫±ng `hostnamectl`, m·ªôt s·ªë ·ª©ng d·ª•ng ho·∫∑c d·ªãch v·ª• (bao g·ªìm MongoDB) c√≥ th·ªÉ kh√¥ng nh·∫≠n ra s·ª± thay ƒë·ªïi ngay l·∫≠p t·ª©c m√† v·∫´n s·ª≠ d·ª•ng hostname c≈© cho ƒë·∫øn khi ch√∫ng ƒë∆∞·ª£c kh·ªüi ƒë·ªông l·∫°i ho·∫∑c h·ªá th·ªëng ƒë∆∞·ª£c reboot. N·∫øu hai m√°y trong cluster v√¥ t√¨nh c√≥ c√πng m·ªôt hostname (ho·∫∑c m·ªôt m√°y v·∫´n s·ª≠ d·ª•ng hostname c≈© tr√πng v·ªõi m√°y kh√°c), MongoDB s·∫Ω b·ªã nh·∫ßm l·∫´n v√† kh√¥ng th·ªÉ qu·∫£n l√Ω c√°c th√†nh vi√™n c·ªßa replica set.
-   **Qu√™n ki·ªÉm tra `/etc/hosts` tr√™n T·∫§T C·∫¢ m√°y:** Vi·ªác ch·ªâ ki·ªÉm tra tr√™n m·ªôt ho·∫∑c hai m√°y c√≥ th·ªÉ d·∫´n ƒë·∫øn m·ªôt m√°y b·ªã c√¥ l·∫≠p, kh√¥ng th·ªÉ resolve ƒë∆∞·ª£c c√°c m√°y kh√°c, g√¢y ra l·ªói k·∫øt n·ªëi v√† s·ª± c·ªë trong cluster.

*   **Th·ª±c hi·ªán ƒë√∫ng:**
    1.  **M·ªü file `/etc/hosts`:** S·ª≠ d·ª•ng `vi /etc/hosts` (ho·∫∑c tr√¨nh so·∫°n th·∫£o y√™u th√≠ch) ƒë·ªÉ ch·ªânh s·ª≠a file n√†y.
    2.  **Th√™m c√°c d√≤ng √°nh x·∫°:** Th√™m danh s√°ch c√°c c·∫∑p IP-hostname cho *t·∫•t c·∫£ c√°c node* trong cluster v√†o cu·ªëi file. **ƒêi·ªÉm m·∫•u ch·ªët l√† n·ªôi dung c·ªßa file `/etc/hosts` tr√™n C·∫¢ 3 M√ÅY PH·∫¢I GI·ªêNG H·ªÜT NHAU.** ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o m·ªói node ƒë·ªÅu c√≥ m·ªôt "b·∫£n ƒë·ªì" m·∫°ng nh·∫•t qu√°n v√† ch√≠nh x√°c v·ªÅ t·∫•t c·∫£ c√°c node kh√°c.
        ```
        # --- Mongo Cluster ---
        192.168.0.38   mongo-1
        192.168.0.241  mongo-2
        192.168.0.215  mongo-3
        ```
    3.  **ƒê·∫∑t hostname duy nh·∫•t cho t·ª´ng m√°y:** Tr√™n m·ªói m√°y, b·∫°n s·∫Ω ch·∫°y l·ªánh `hostnamectl set-hostname <t√™n-hostname>` t∆∞∆°ng ·ª©ng.
        *   `hostnamectl set-hostname mongo-1` (Tr√™n m√°y c√≥ IP 192.168.0.38)
        *   `hostnamectl set-hostname mongo-2` (Tr√™n m√°y c√≥ IP 192.168.0.241)
        *   `hostnamectl set-hostname mongo-3` (Tr√™n m√°y c√≥ IP 192.168.0.215)
        Thao t√°c n√†y ƒë·∫£m b·∫£o r·∫±ng m·ªói m√°y t·ª± nh·∫≠n di·ªán m√¨nh v·ªõi m·ªôt c√°i t√™n ri√™ng bi·ªát v√† nh·∫•t qu√°n v·ªõi nh·ªØng g√¨ ƒë√£ ƒë·ªãnh nghƒ©a trong `/etc/hosts`. Sau khi ƒë·∫∑t hostname, t·ªët nh·∫•t n√™n kh·ªüi ƒë·ªông l·∫°i ho·∫∑c √≠t nh·∫•t ƒëƒÉng xu·∫•t/ƒëƒÉng nh·∫≠p l·∫°i ƒë·ªÉ ƒë·∫£m b·∫£o t·∫•t c·∫£ c√°c d·ªãch v·ª• nh·∫≠n hostname m·ªõi.

* **Minh ho·∫°:**

```mermaid
flowchart TD
    A[B·∫Øt ƒë·∫ßu: C·∫•u h√¨nh /etc/hosts v√† Hostname] --> B{M·ª•c ƒë√≠ch:<br/>D√πng Hostname d·ªÖ nh·ªõ thay v√¨ IP<br/>Gi√∫p c·∫•u h√¨nh r√µ r√†ng, qu·∫£n l√Ω d·ªÖ d√†ng<br/>v√† giao ti·∫øp nh·∫•t qu√°n cho MongoDB Cluster};
    
    subgraph "Tr√™n T·∫§T C·∫¢ 3 M√ÅY"
        IP1(192.168.0.38)
        IP2(192.168.0.241)
        IP3(192.168.0.215)
        
        S1["M·ªü v√† S·ª≠a file /etc/hosts"]
        S1 --> S2["Th√™m √°nh x·∫° IP <-> Hostname:<br/>(N·ªôi dung file ph·∫£i GI·ªêNG H·ªÜT NHAU tr√™n C·∫¢ 3 M√ÅY)"];
        S2 --> HostEntries{<br/># --- Mongo Cluster ---<br/>192.168.0.38 mongo-1<br/>192.168.0.241 mongo-2<br/>192.168.0.215 mongo-3<br/>}
    end
    
    subgraph "Tr√™n T·ª™NG M√ÅY RI√äNG BI·ªÜT"
        M1["M√°y 1 (192.168.0.38):<br/>hostnamectl set-hostname mongo-1"]
        M2["M√°y 2 (192.168.0.241):<br/>hostnamectl set-hostname mongo-2"]
        M3["M√°y 3 (192.168.0.215):<br/>hostnamectl set-hostname mongo-3"]
    end
    
    B --> S1
    HostEntries --> M1
    HostEntries --> M2
    HostEntries --> M3
    
    subgraph "‚ö†Ô∏è B·∫™Y NG∆Ø·ªúI M·ªöI (C·∫ßn tr√°nh)"
        P1["Hosts file KH√îNG ƒê·ªíNG NH·∫§T"];
        P2["Hostname TR√ôNG/Kh√¥ng reboot sau ƒë·ªïi"];
        P3["Qu√™n ki·ªÉm tra tr√™n T·∫§T C·∫¢ m√°y"];
    end
    
    M1 --> F[Cluster s·∫µn s√†ng giao ti·∫øp b·∫±ng Hostname];
    M2 --> F;
    M3 --> F;
    
    %% ƒê·ªãnh nghƒ©a style classes
    classDef startNode fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    classDef purposeNode fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    classDef sharedConfig fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    classDef uniqueConfig fill:#e0f2f1,stroke:#00695c,stroke-width:2px,color:#000
    classDef resultNode fill:#e8f5e8,stroke:#388e3c,stroke-width:3px,color:#000
    classDef trapNode fill:#ffcdd2,stroke:#c62828,stroke-width:2px,color:#000
    
    %% √Åp d·ª•ng styles
    class A startNode
    class B purposeNode
    class S1,S2,HostEntries sharedConfig
    class M1,M2,M3 uniqueConfig
    class F resultNode
    class P1,P2,P3 trapNode
```

#### **2. T·∫Øt Transparent Huge Pages (THP)**

*   **M·ª•c ƒë√≠ch c·ªët l√µi:** THP g√¢y s·ª•t gi·∫£m hi·ªáu nƒÉng nghi√™m tr·ªçng cho MongoDB. Ph·∫£i t·∫Øt vƒ©nh vi·ªÖn ƒë·ªÉ ƒë·∫£m b·∫£o hi·ªáu su·∫•t ·ªïn ƒë·ªãnh v√† t·ªëi ∆∞u cho c∆° s·ªü d·ªØ li·ªáu.

*   **THP l√† g√¨ v√† t·∫°i sao n√≥ t·ªìn t·∫°i?**
    *   **Transparent Huge Pages (THP)** l√† m·ªôt t√≠nh nƒÉng c·ªßa kernel Linux, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ tƒÉng hi·ªáu nƒÉng b·∫±ng c√°ch cho ph√©p c√°c ·ª©ng d·ª•ng s·ª≠ d·ª•ng c√°c "trang b·ªô nh·ªõ l·ªõn" (huge pages, th∆∞·ªùng l√† 2MB thay v√¨ 4KB m·∫∑c ƒë·ªãnh) m·ªôt c√°ch t·ª± ƒë·ªông v√† minh b·∫°ch.
    *   M·ª•c ƒë√≠ch c·ªßa THP l√† gi·∫£m s·ªë l∆∞·ª£ng c√°c entry trong b·∫£ng chuy·ªÉn ƒë·ªïi ƒë·ªãa ch·ªâ (Translation Lookaside Buffer - TLB), t·ª´ ƒë√≥ tƒÉng t·ªëc ƒë·ªô truy c·∫≠p b·ªô nh·ªõ cho c√°c ·ª©ng d·ª•ng s·ª≠ d·ª•ng l∆∞·ª£ng l·ªõn b·ªô nh·ªõ m·ªôt c√°ch tu·∫ßn t·ª± ho·∫∑c c√≥ c·∫•u tr√∫c r·∫•t l·ªõn.

*   **T·∫°i sao THP l·∫°i g√¢y h·∫°i cho MongoDB?**
    *   **Xung ƒë·ªôt v·ªõi c√°ch qu·∫£n l√Ω b·ªô nh·ªõ c·ªßa MongoDB (WiredTiger):** MongoDB, ƒë·∫∑c bi·ªát l√† v·ªõi storage engine WiredTiger, c√≥ c∆° ch·∫ø qu·∫£n l√Ω b·ªô nh·ªõ c·ªßa ri√™ng n√≥ r·∫•t hi·ªáu qu·∫£. WiredTiger ch·ªß ƒë·ªông √°nh x·∫° (map) v√† gi·∫£i √°nh x·∫° (unmap) c√°c v√πng b·ªô nh·ªõ nh·ªè, ƒë·ªìng th·ªùi duy tr√¨ c√°c c·∫•u tr√∫c d·ªØ li·ªáu c·ªßa ri√™ng m√¨nh trong RAM (v√≠ d·ª•: WiredTiger cache).
    *   **Ph√¢n m·∫£nh b·ªô nh·ªõ v√† ƒë·ªô tr·ªÖ cao:** Khi THP ƒë∆∞·ª£c b·∫≠t, n√≥ s·∫Ω c·ªë g·∫Øng gom c√°c trang b·ªô nh·ªõ 4KB nh·ªè c·ªßa WiredTiger th√†nh c√°c trang 2MB l·ªõn. Qu√° tr√¨nh n√†y c√≥ th·ªÉ d·∫´n ƒë·∫øn c√°c v·∫•n ƒë·ªÅ nghi√™m tr·ªçng:
        *   **TƒÉng ƒë·ªô tr·ªÖ (Latency Spikes):** Vi·ªác c·∫•p ph√°t ho·∫∑c gi·∫£i ph√≥ng c√°c huge pages 2MB ƒë√≤i h·ªèi nhi·ªÅu t√†i nguy√™n h∆°n v√† c√≥ th·ªÉ b·ªã ƒë√¨nh tr·ªá. ƒêi·ªÅu n√†y g√¢y ra "stop-the-world" pauses (t·∫°m d·ª´ng to√†n b·ªô ho·∫°t ƒë·ªông) trong micro gi√¢y ho·∫∑c mili gi√¢y, g√¢y ra c√°c ƒë·ªânh ƒë·ªô tr·ªÖ ƒë·ªôt bi·∫øn m√† MongoDB r·∫•t nh·∫°y c·∫£m.
        *   **Hi·ªáu qu·∫£ cache k√©m:** C√°c ho·∫°t ƒë·ªông I/O ng·∫´u nhi√™n v√† nh·ªè c·ªßa MongoDB kh√¥ng ƒë∆∞·ª£c h∆∞·ªüng l·ª£i t·ª´ huge pages m√† th·∫≠m ch√≠ c√≤n b·ªã c·∫£n tr·ªü. Vi·ªác ghi ƒë√® l√™n c√°c trang b·ªô nh·ªõ l·ªõn c√≥ th·ªÉ l√†m gi·∫£m hi·ªáu qu·∫£ c·ªßa c·∫£ cache n·ªôi b·ªô c·ªßa WiredTiger v√† cache c·ªßa h·ªá ƒëi·ªÅu h√†nh.
        *   **Kh√≥ khƒÉn trong qu·∫£n l√Ω b·ªô nh·ªõ:** Khi kernel c·ªë g·∫Øng duy tr√¨ c√°c huge pages, n√≥ c√≥ th·ªÉ g·∫∑p kh√≥ khƒÉn trong vi·ªác t√¨m ki·∫øm c√°c kh·ªëi b·ªô nh·ªõ l·ªõn li√™n t·ª•c, d·∫´n ƒë·∫øn tƒÉng vi·ªác s·ª≠ d·ª•ng swap kh√¥ng c·∫ßn thi·∫øt ho·∫∑c g√¢y √°p l·ª±c l√™n b·ªô nh·ªõ.
    *   **T√≥m l·∫°i:** M·∫∑c d√π THP c√≥ l·ª£i cho m·ªôt s·ªë ·ª©ng d·ª•ng khoa h·ªçc ho·∫∑c t√≠nh to√°n hi·ªáu nƒÉng cao, nh∆∞ng ƒë·ªëi v·ªõi c√°c c∆° s·ªü d·ªØ li·ªáu nh∆∞ MongoDB, v·ªën c√≥ m√¥ h√¨nh truy c·∫≠p b·ªô nh·ªõ r·∫•t ƒë·∫∑c th√π v√† y√™u c·∫ßu ƒë·ªô tr·ªÖ th·∫•p, THP l·∫°i tr·ªü th√†nh m·ªôt t√°c nh√¢n g√¢y c·∫£n tr·ªü hi·ªáu nƒÉng nghi√™m tr·ªçng v√† kh√≥ l∆∞·ªùng.

*   **T·∫°i sao ph·∫£i t·∫Øt vƒ©nh vi·ªÖn?**
    *   N·∫øu ch·ªâ t·∫Øt THP th·ªß c√¥ng b·∫±ng c√°c l·ªánh `echo never` trong shell, n√≥ s·∫Ω ch·ªâ c√≥ hi·ªáu l·ª±c cho ƒë·∫øn khi h·ªá th·ªëng kh·ªüi ƒë·ªông l·∫°i.
    *   MongoDB c·∫ßn m√¥i tr∆∞·ªùng ·ªïn ƒë·ªãnh li√™n t·ª•c, do ƒë√≥, THP ph·∫£i ƒë∆∞·ª£c t·∫Øt m·ªôt c√°ch vƒ©nh vi·ªÖn v√† t·ª± ƒë·ªông sau m·ªói l·∫ßn kh·ªüi ƒë·ªông l·∫°i h·ªá th·ªëng, th∆∞·ªùng l√† th√¥ng qua m·ªôt `systemd service` ho·∫∑c c·∫•u h√¨nh `grub`. Ph∆∞∆°ng ph√°p `systemd service` ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t trong h∆∞·ªõng d·∫´n l√† c√°ch hi·ªáu qu·∫£ v√† ƒë√°ng tin c·∫≠y.

‚ö†Ô∏è **B·∫™Y NG∆Ø·ªúI M·ªöI - Giai ƒëo·∫°n 1:**
-   **T·∫Øt THP th·ªß c√¥ng, qu√™n daemonize** ‚Üí reboot xong THP b·∫≠t l·∫°i, c√°c v·∫•n ƒë·ªÅ hi·ªáu nƒÉng s·∫Ω quay tr·ªü l·∫°i.
-   **Service file sai c·∫•u h√¨nh Before/After** ‚Üí kh√¥ng ƒë·∫£m b·∫£o th·ª© t·ª± kh·ªüi ƒë·ªông. N·∫øu service t·∫Øt THP ch·∫°y sau `mongod`, th√¨ `mongod` c√≥ th·ªÉ ƒë√£ kh·ªüi ƒë·ªông v·ªõi THP b·∫≠t v√† b·ªã ·∫£nh h∆∞·ªüng.
-   **Kh√¥ng test l·∫°i sau reboot** ‚Üí t∆∞·ªüng ƒë√£ t·∫Øt nh∆∞ng th·ª±c t·∫ø v·∫´n b·∫≠t. Lu√¥n c·∫ßn ki·ªÉm tra `cat /sys/kernel/mm/transparent_hugepage/enabled` sau khi h·ªá th·ªëng kh·ªüi ƒë·ªông l·∫°i ƒë·ªÉ x√°c nh·∫≠n `[never]`.

üí° **M·∫∏O:** Sau khi t·∫°o service, lu√¥n reboot v√† ki·ªÉm tra `cat /sys/kernel/mm/transparent_hugepage/enabled` ph·∫£i c√≥ `[never]`.
*   **Th·ª±c hi·ªán ƒë√∫ng:**
    1.  T·∫°o file service: `vi /etc/systemd/system/disable-transparent-huge-pages.service`

    2.  D√°n n·ªôi dung ch√≠nh x√°c sau:
    
```bash
[Unit]
# M√¥ t·∫£ service
Description=Disable Transparent Huge Pages (THP)

# Kh√¥ng ph·ª• thu·ªôc m·∫∑c ƒë·ªãnh kh√°c, ƒë·ªÉ service ch·∫°y s·ªõm trong qu√° tr√¨nh boot
DefaultDependencies=no

# Ch·∫°y sau khi h·ªá th·ªëng kh·ªüi t·∫°o c∆° b·∫£n xong (sysinit + local fs)
After=sysinit.target local-fs.target

# ƒê·∫£m b·∫£o service n√†y ch·∫°y tr∆∞·ªõc khi mongod kh·ªüi ƒë·ªông
Before=mongod.service

[Service]
# Ch·∫°y m·ªôt l·∫ßn duy nh·∫•t r·ªìi tho√°t
Type=oneshot

# L·ªánh t·∫Øt THP (ch·ªâ disable "enabled")
# N·∫øu c·∫ßn t·∫Øt c·∫£ "defrag" th√¨ n√™n th√™m check file defrag v√† echo never
ExecStart=/bin/sh -c 'echo never | tee /sys/kernel/mm/transparent_hugepage/enabled > /dev/null'

[Install]
# Service s·∫Ω ƒë∆∞·ª£c k√©o v√†o basic.target (ch·∫°y r·∫•t s·ªõm khi boot)
# Th∆∞·ªùng production hay d√πng multi-user.target ƒë·ªÉ qu·∫£n l√Ω d·ªÖ h∆°n
WantedBy=basic.target
```

3.  K√≠ch ho·∫°t service:
```bash
# N·∫°p l·∫°i to√†n b·ªô unit files t·ª´ disk v√†o memory c·ªßa systemd
# B·∫Øt bu·ªôc khi b·∫°n v·ª´a t·∫°o m·ªõi ho·∫∑c s·ª≠a file .service
systemctl daemon-reload

# Kh·ªüi ƒë·ªông service ngay l·∫≠p t·ª©c (ch·ªâ ch·∫°y cho l·∫ßn boot hi·ªán t·∫°i)
systemctl start disable-transparent-huge-pages

# B·∫≠t service ƒë·ªÉ t·ª± ƒë·ªông ch·∫°y l·∫°i khi reboot
systemctl enable disable-transparent-huge-pages

# üëÜ N·∫øu mu·ªën g·ªçn, c√≥ th·ªÉ g·ªôp start + enable b·∫±ng:
# systemctl enable --now disable-transparent-huge-pages

```
4.  Ki·ªÉm tra: `cat /sys/kernel/mm/transparent_hugepage/enabled` ph·∫£i c√≥ `[never]`.

5.  (Tu·ª≥ ch·ªçn) Ki·ªÉm tra tr·∫°ng th√°i c·ªßa  disable-transparent-huge-pages ƒë·ªÉ ƒë·ªçc log kh·ªüi ch·∫°y
```bash
# Ki·ªÉm tra tr·∫°ng th√°i service disable-transparent-huge-pages
# - Cho bi·∫øt service ƒëang "active" (ƒëang ch·∫°y th√†nh c√¥ng) hay "failed"
# - Hi·ªÉn th·ªã log kh·ªüi ch·∫°y t·ª´ journalctl (gi√∫p debug khi l·ªói)
# - D√πng sau khi start/enable ƒë·ªÉ ch·∫Øc ch·∫Øn service ch·∫°y ƒë√∫ng
systemctl status disable-transparent-huge-pages
``` 

üìå Khi ch·∫°y b·∫°n s·∫Ω th·∫•y:

* `Active: active (exited)` ‚Üí nghƒ©a l√† service ch·∫°y 1 l·∫ßn th√†nh c√¥ng r·ªìi tho√°t (Type=oneshot).
* N·∫øu c√≥ l·ªói (v√≠ d·ª• file kh√¥ng t·ªìn t·∫°i) ‚Üí b·∫°n s·∫Ω th·∫•y `failed` v√† log l·ªói ngay d∆∞·ªõi.  
   
* **Minh ho·∫°**:

```mermaid
flowchart TD
    A["üöÄ B·∫Øt ƒë·∫ßu: T·∫Øt Transparent Huge Pages THP"] --> B{"üéØ M·ª•c ƒë√≠ch:<br/>Tr√°nh s·ª•t gi·∫£m hi·ªáu nƒÉng<br/>nghi√™m tr·ªçng cho MongoDB"}
    
    subgraph "üìã C√°c B∆∞·ªõc Th·ª±c Hi·ªán"
        B --> C["üìÑ B∆∞·ªõc 1: T·∫°o file service<br/>/etc/systemd/system/disable-transparent-huge-pages.service"]
        C --> D["‚úèÔ∏è B∆∞·ªõc 2: D√°n n·ªôi dung c·∫•u h√¨nh service<br/>ExecStart: echo never tee c√°c ƒë∆∞·ªùng d·∫´n THP"]
        D --> E["‚öôÔ∏è B∆∞·ªõc 3: K√≠ch ho·∫°t service"]
        E --> E1["üîÑ systemctl daemon-reload"]
        E1 --> E2["‚ñ∂Ô∏è systemctl start disable-transparent-huge-pages"]
        E2 --> E3["üîó systemctl enable disable-transparent-huge-pages"]
    end
    
    E3 --> F["üîç B∆∞·ªõc 4: Ki·ªÉm tra tr·∫°ng th√°i THP<br/>cat /sys/kernel/mm/transparent_hugepage/enabled"]
    F --> G{"‚úÖ K·∫øt qu·∫£ mong mu·ªën:<br/>always madvise [never]"}
    
    G -->|"Th√†nh c√¥ng"| H["üéâ THP ƒë√£ t·∫Øt vƒ©nh vi·ªÖn v√† ch√≠nh x√°c"]
    G -->|"Th·∫•t b·∫°i"| I["‚ùå C·∫ßn kh·∫Øc ph·ª•c l·ªói"]
    
    I --> J{"üö® C√°c l·ªói th∆∞·ªùng g·∫∑p"}
    
    subgraph "‚ö†Ô∏è B·∫´y Ng∆∞·ªùi M·ªõi - C·∫ßn Tr√°nh"
        J --> P1["üîß T·∫Øt THP th·ªß c√¥ng<br/>qu√™n daemonize"]
        J --> P2["üìù Service file sai c·∫•u h√¨nh<br/>Before/After dependencies"]
        J --> P3["üîÑ Kh√¥ng test l·∫°i<br/>sau reboot"]
    end
    
    P1 --> K["üîÑ Quay l·∫°i b∆∞·ªõc 2"]
    P2 --> K
    P3 --> K
    K --> D
    
    style A fill:#fff3e0,stroke:#f57c00,stroke-width:3px,color:#000
    style B fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style C fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    style E fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    style E1 fill:#e8eaf6,stroke:#5e35b1,stroke-width:2px,color:#000
    style E2 fill:#e8eaf6,stroke:#5e35b1,stroke-width:2px,color:#000
    style E3 fill:#e8eaf6,stroke:#5e35b1,stroke-width:2px,color:#000
    style F fill:#ffebee,stroke:#d32f2f,stroke-width:2px,color:#000
    style G fill:#e8f5e8,stroke:#388e3c,stroke-width:3px,color:#000
    style H fill:#c8e6c9,stroke:#2e7d32,stroke-width:4px,color:#000
    style I fill:#ffcdd2,stroke:#c62828,stroke-width:2px,color:#000
    style J fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style P1 fill:#ffcdd2,stroke:#c62828,stroke-width:2px,color:#000
    style P2 fill:#ffcdd2,stroke:#c62828,stroke-width:2px,color:#000
    style P3 fill:#ffcdd2,stroke:#c62828,stroke-width:2px,color:#000
    style K fill:#fff9c4,stroke:#f9a825,stroke-width:2px,color:#000
``` 

#### **3. Tinh ch·ªânh Kernel (`sysctl`) v√† Gi·ªõi h·∫°n (`ulimit`)**

*   **M·ª•c ƒë√≠ch c·ªët l√µi:** ƒê·∫£m b·∫£o h·ªá ƒëi·ªÅu h√†nh cung c·∫•p ƒë·ªß "s·ª©c m·∫°nh" v√† "kh√¥ng gian" cho MongoDB ho·∫°t ƒë·ªông m∆∞·ª£t m√†, ƒë·∫∑c bi·ªát khi h·ªá th·ªëng ph·∫£i x·ª≠ l√Ω l∆∞·ª£ng d·ªØ li·ªáu l·ªõn v√† nhi·ªÅu k·∫øt n·ªëi c√πng l√∫c. C√°c ƒëi·ªÅu ch·ªânh n√†y gi√∫p MongoDB tr√°nh kh·ªèi c√°c gi·ªõi h·∫°n ng·∫ßm c·ªßa h·ªá ƒëi·ªÅu h√†nh, ngƒÉn ng·ª´a c√°c l·ªói li√™n quan ƒë·∫øn t√†i nguy√™n nh∆∞ "qu√° nhi·ªÅu file ƒëang m·ªü" ho·∫∑c "h·∫øt b·ªô nh·ªõ ·∫£o".

*   **Kernel Parameters (qua `sysctl`):** ƒê√¢y l√† c√°c thi·∫øt l·∫≠p c·∫•p th·∫•p c·ªßa h·ªá ƒëi·ªÅu h√†nh, ·∫£nh h∆∞·ªüng ƒë·∫øn c√°ch kernel qu·∫£n l√Ω t√†i nguy√™n nh∆∞ b·ªô nh·ªõ, m·∫°ng, v√† ti·∫øn tr√¨nh. Vi·ªác tinh ch·ªânh c√°c tham s·ªë n√†y gi√∫p t·ªëi ∆∞u h√≥a c√°ch MongoDB t∆∞∆°ng t√°c v·ªõi nh√¢n Linux, v√≠ d·ª•:
    *   **Qu·∫£n l√Ω b·ªô nh·ªõ:** Gi·∫£m xu h∆∞·ªõng h·ªá ƒëi·ªÅu h√†nh s·ª≠ d·ª•ng swap (v√πng nh·ªõ tr√™n ƒëƒ©a), gi·ªØ d·ªØ li·ªáu quan tr·ªçng c·ªßa MongoDB trong RAM. TƒÉng gi·ªõi h·∫°n s·ªë l∆∞·ª£ng v√πng nh·ªõ ·∫£o m√† m·ªôt ti·∫øn tr√¨nh c√≥ th·ªÉ √°nh x·∫° (quan tr·ªçng cho WiredTiger Storage Engine).
    *   **T·ªëi ∆∞u m·∫°ng:** C·∫£i thi·ªán kh·∫£ nƒÉng qu·∫£n l√Ω k·∫øt n·ªëi m·∫°ng, ƒë·∫£m b·∫£o MongoDB c√≥ th·ªÉ m·ªü ƒë·ªß s·ªë l∆∞·ª£ng c·ªïng v√† duy tr√¨ k·∫øt n·ªëi hi·ªáu qu·∫£.
    *   **Gi·ªõi h·∫°n ti·∫øn tr√¨nh/file:** TƒÉng gi·ªõi h·∫°n t·ªïng s·ªë file h·ªá th·ªëng c√≥ th·ªÉ m·ªü, c≈©ng nh∆∞ s·ªë l∆∞·ª£ng PID v√† lu·ªìng c√≥ th·ªÉ ch·∫°y, ƒë·∫£m b·∫£o MongoDB c√≥ ƒë·ªß kh√¥ng gian cho c√°c ti·∫øn tr√¨nh v√† lu·ªìng c·∫ßn thi·∫øt.
    *   **T·ªëi ∆∞u NUMA:** Tr√™n c√°c h·ªá th·ªëng c√≥ ki·∫øn tr√∫c b·ªô nh·ªõ NUMA, vi·ªác ƒëi·ªÅu ch·ªânh gi√∫p gi·∫£m ƒë·ªô tr·ªÖ khi truy c·∫≠p b·ªô nh·ªõ.

*   **Gi·ªõi h·∫°n Ng∆∞·ªùi d√πng (qua `ulimit`):** ƒê√¢y l√† c√°c gi·ªõi h·∫°n √°p ƒë·∫∑t cho t·ª´ng ng∆∞·ªùi d√πng ho·∫∑c nh√≥m ng∆∞·ªùi d√πng v·ªÅ l∆∞·ª£ng t√†i nguy√™n m√† h·ªç c√≥ th·ªÉ s·ª≠ d·ª•ng (v√≠ d·ª•: s·ªë file t·ªëi ƒëa c√≥ th·ªÉ m·ªü, s·ªë ti·∫øn tr√¨nh t·ªëi ƒëa c√≥ th·ªÉ ch·∫°y). V·ªõi `mongod` th∆∞·ªùng ch·∫°y d∆∞·ªõi user `mongod`, vi·ªác tƒÉng c√°c gi·ªõi h·∫°n n√†y l√† r·∫•t quan tr·ªçng ƒë·ªÉ tr√°nh t√¨nh tr·∫°ng "h·∫øt t√†i nguy√™n" khi t·∫£i cao.

‚ö†Ô∏è **B·∫™Y NG∆Ø·ªúI M·ªöI - Giai ƒëo·∫°n 1:**
-   **`ulimit` ch·ªânh trong shell:** C√°c l·ªánh `ulimit` ch·∫°y tr·ª±c ti·∫øp trong terminal ch·ªâ c√≥ hi·ªáu l·ª±c cho session hi·ªán t·∫°i v√† s·∫Ω m·∫•t khi b·∫°n ƒë√≥ng terminal ho·∫∑c kh·ªüi ƒë·ªông l·∫°i m√°y. **Ph·∫£i c·∫•u h√¨nh vƒ©nh vi·ªÖn qua `/etc/security/limits.d/`**.
-   **Kh√¥ng √°p d·ª•ng ngay b·∫±ng `sysctl -p`:** Sau khi s·ª≠a `sysctl.conf`, c√°c thay ƒë·ªïi s·∫Ω ch·ªâ c√≥ hi·ªáu l·ª±c sau khi reboot ho·∫∑c khi ƒë∆∞·ª£c √°p d·ª•ng th·ªß c√¥ng b·∫±ng `sysctl -p`.
-   **Qu√™n th√™m NUMA parameter:** Tr√™n c√°c m√°y ch·ªß c√≥ ki·∫øn tr√∫c NUMA, vi·ªác thi·∫øu c·∫•u h√¨nh t·ªëi ∆∞u c√≥ th·ªÉ d·∫´n ƒë·∫øn hi·ªáu nƒÉng k√©m do kernel c·ªë g·∫Øng ∆∞u ti√™n b·ªô nh·ªõ c·ª•c b·ªô qu√° m·ª©c, g√¢y ra ƒë·ªô tr·ªÖ cao.

**L∆∞u √Ω quan tr·ªçng: T·∫°i sao t·∫°o file trong `/etc/sysctl.d/` m√† kh√¥ng s·ª≠a `/etc/sysctl.conf`?**
*   **Th·ª±c h√†nh t·ªët nh·∫•t (Best Practice)**: Trong c√°c h·ªá th·ªëng Linux hi·ªán ƒë·∫°i (nh∆∞ CentOS/RHEL 8), vi·ªác t·∫°o c√°c file c·∫•u h√¨nh ri√™ng bi·ªát trong th∆∞ m·ª•c `/etc/sysctl.d/` l√† ph∆∞∆°ng ph√°p ƒë∆∞·ª£c khuy·∫øn ngh·ªã. ƒêi·ªÅu n√†y gi√∫p:
    *   **D·ªÖ qu·∫£n l√Ω**: M·ªói ·ª©ng d·ª•ng ho·∫∑c m·ª•c ƒë√≠ch tinh ch·ªânh c√≥ file ri√™ng, gi√∫p h·ªá th·ªëng g·ªçn g√†ng, d·ªÖ theo d√µi v√† b·∫£o tr√¨ h∆°n.
    *   **Tr√°nh xung ƒë·ªôt**: B·∫°n kh√¥ng l√†m thay ƒë·ªïi c√°c c·∫•u h√¨nh m·∫∑c ƒë·ªãnh c·ªßa h·ªá th·ªëng trong `/etc/sysctl.conf`, tr√°nh ƒë∆∞·ª£c c√°c l·ªói kh√¥ng mong mu·ªën ho·∫∑c xung ƒë·ªôt v·ªõi c√°c c√†i ƒë·∫∑t c·ªßa g√≥i ph·∫ßn m·ªÅm kh√°c.
    *   **D·ªÖ g·ª° b·ªè**: Khi kh√¥ng c√≤n c·∫ßn MongoDB, b·∫°n ch·ªâ c·∫ßn x√≥a file c·∫•u h√¨nh n√†y m√† kh√¥ng c·∫ßn d√≤ t√¨m v√† s·ª≠a ƒë·ªïi m·ªôt file l·ªõn.
*   **C√°ch ho·∫°t ƒë·ªông**: Khi h·ªá th·ªëng kh·ªüi ƒë·ªông ho·∫∑c ch·∫°y `sysctl --system`, n√≥ s·∫Ω ƒë·ªçc `/etc/sysctl.conf` tr∆∞·ªõc, sau ƒë√≥ l√† t·∫•t c·∫£ c√°c file `.conf` trong `/etc/sysctl.d/` theo th·ª© t·ª± b·∫£ng ch·ªØ c√°i. N·∫øu c√≥ tham s·ªë tr√πng l·∫∑p, gi√° tr·ªã trong file ƒë∆∞·ª£c ƒë·ªçc sau c√πng s·∫Ω ƒë∆∞·ª£c √°p d·ª•ng.


*   **Th·ª±c hi·ªán ƒë√∫ng:**
    1.  T·∫°o m·ªôt file c·∫•u h√¨nh m·ªõi cho MongoDB:
    Ch√∫ng ta s·∫Ω t·∫°o m·ªôt file c√≥ t√™n `99-mongodb.conf` trong th∆∞ m·ª•c `/etc/sysctl.d/` `(vi /etc/sysctl.d/99-mongodb.conf)`. S·ªë `99` ƒë·∫£m b·∫£o file n√†y ƒë∆∞·ª£c ƒë·ªçc sau c√πng (theo th·ª© t·ª± b·∫£ng ch·ªØ c√°i) ƒë·ªÉ c√°c tinh ch·ªânh c·ªßa MongoDB s·∫Ω ghi ƒë√® l√™n b·∫•t k·ª≥ c√†i ƒë·∫∑t n√†o kh√°c n·∫øu c√≥ xung ƒë·ªôt. 

```bash
    # Gi·∫£m s·ª≠ d·ª•ng swap t·ªëi ƒëa (MongoDB kh√¥ng th√≠ch swap v√¨ tƒÉng latency)
    vm.swappiness = 1

    # T·ªëi ∆∞u NUMA - V√¥ hi·ªáu h√≥a zone reclaim mode ƒë·ªÉ tr√°nh ƒë·ªô tr·ªÖ NUMA
    vm.zone_reclaim_mode = 0

    # M·ªü r·ªông d·∫£i port ephemeral (outbound TCP connection) t·ª´ 1024 ‚Üí 65530
    # Gi√∫p h·ªó tr·ª£ nhi·ªÅu k·∫øt n·ªëi ƒë·ªìng th·ªùi khi c√≥ nhi·ªÅu client/app
    net.ipv4.ip_local_port_range = 1024 65530

    # TƒÉng s·ªë l∆∞·ª£ng memory map t·ªëi ƒëa cho 1 process (MongoDB d√πng nhi·ªÅu mmap cho index/collection)
    # M·∫∑c ƒë·ªãnh 65530 l√† qu√° th·∫•p, tƒÉng l√™n ƒë·ªÉ tr√°nh l·ªói "out of memory maps"
    vm.max_map_count = 9999999

    # TƒÉng s·ªë l∆∞·ª£ng file descriptors to√†n h·ªá th·ªëng
    # ƒê·∫£m b·∫£o MongoDB c√≥ th·ªÉ m·ªü nhi·ªÅu file d·ªØ li·ªáu, log, connection socket
    fs.file-max = 6815744
```
2.  √Åp d·ª•ng ngay: `sysctl --system`  ƒë·ªÉ load t·∫•t c·∫£ file trong `/etc/sysctl.d/, /run/sysctl.d/, /usr/lib/sysctl.d/ + /etc/sysctl.conf`. N√≥ m√¥ ph·ªèng ƒë√∫ng h√†nh vi khi reboot.

3.  T·∫°o file c·∫•u h√¨nh `/etc/security/limits.d/99-mongodb.conf` vƒ©nh vi·ªÖn cho user `mongod` :
```bash
# /etc/security/limits.d/99-mongodb.conf
# File n√†y ƒë·∫∑t gi·ªõi h·∫°n (ulimit) vƒ©nh vi·ªÖn cho user mongod.
# √Åp d·ª•ng khi mongod login ho·∫∑c khi service mongod kh·ªüi ƒë·ªông l·∫°i.

# S·ªë file descriptors (ulimit -n), MongoDB c·∫ßn nhi·ªÅu FD cho connections v√† file data
mongod soft nofile 64000
mongod hard nofile 64000

# S·ªë process/threads (ulimit -u), ƒë·∫£m b·∫£o MongoDB c√≥ th·ªÉ t·∫°o nhi·ªÅu worker threads
mongod soft nproc 64000
mongod hard nproc 64000

# Memory lock (ulimit -l), cho ph√©p mongod lock memory (th∆∞·ªùng d√πng ƒë·ªÉ tr√°nh swap key pages, TLS‚Ä¶)
mongod soft memlock unlimited
mongod hard memlock unlimited

# File size (ulimit -f), gi·ªõi h·∫°n k√≠ch th∆∞·ªõc file m√† process t·∫°o ra ‚Üí unlimited ƒë·ªÉ kh√¥ng ch·∫∑n write
mongod soft fsize unlimited
mongod hard fsize unlimited

# CPU time (ulimit -t), gi·ªõi h·∫°n t·ªïng th·ªùi gian CPU m√† process d√πng ‚Üí unlimited
mongod soft cpu unlimited
mongod hard cpu unlimited

# Virtual memory (ulimit -v), gi·ªõi h·∫°n address space process ‚Üí unlimited ƒë·ªÉ MongoDB kh√¥ng b·ªã gi·ªõi h·∫°n RAM ·∫£o
mongod soft as unlimited
mongod hard as unlimited

# Resident memory (ulimit -m), th∆∞·ªùng Linux hi·ªán ƒë·∫°i b·ªè qua, nh∆∞ng c√≥ th·ªÉ set b·∫±ng rss
# Optional: c√≥ th·ªÉ b·ªè n·∫øu kernel > 2.4.30 v√¨ ignore
mongod soft rss unlimited
mongod hard rss unlimited

```

* Sau khi s·ª≠a file `/etc/security/limits.d/99-mongodb.conf`, b·∫°n ch·ªâ c·∫ßn **restart mongod** ƒë·ªÉ n√≥ nh·∫≠n limit m·ªõi:

```bash
systemctl restart mongod
```
* Mu·ªën ch·∫Øc ch·∫Øn, ki·ªÉm tra:

```bash
pid=$(pgrep -xo mongod)
cat /proc/$pid/limits | egrep 'Max open files|Max processes|Max locked memory'
```

* **Minh ho·∫°**:

```mermaid 
flowchart TD
    A[B·∫Øt ƒë·∫ßu: Tinh ch·ªânh Kernel v√† Ulimit] --> B{M·ª•c ƒë√≠ch:<br/>Cung c·∫•p ƒê·ª¶ T√ÄI NGUY√äN H·ªÜ TH·ªêNG<br/>cho MongoDB ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh};
    
    subgraph "1. Tinh ch·ªânh Kernel (sysctl)"
        C1["S·ª≠a /etc/sysctl.conf"] --> C2["Th√™m c√°c tham s·ªë t·ªëi ∆∞u<br/>(B·ªô nh·ªõ, M·∫°ng, Gi·ªõi h·∫°n File/Process, NUMA)"];
        C2 --> C3["√Åp d·ª•ng ngay:<br/>sysctl -p"];
    end
    
    subgraph "2. Thi·∫øt l·∫≠p Gi·ªõi h·∫°n Ng∆∞·ªùi d√πng (ulimit)"
        D1["T·∫°o file /etc/security/limits.d/99-mongodb-limits.conf"] --> D2["C·∫•u h√¨nh gi·ªõi h·∫°n vƒ©nh vi·ªÖn<br/>cho user mongod v√† root<br/>(S·ªë file m·ªü, s·ªë ti·∫øn tr√¨nh/lu·ªìng)"];
    end
    
    B --> C1;
    B --> D1;
    
    subgraph "‚ö†Ô∏è B·∫™Y NG∆Ø·ªúI M·ªöI (C·∫ßn tr√°nh)"
        P1["Ch·ªânh ulimit t·∫°m th·ªùi trong shell"];
        P2["Kh√¥ng √°p d·ª•ng sysctl ngay l·∫≠p t·ª©c"];
        P3["Qu√™n t·ªëi ∆∞u NUMA tr√™n server ph√π h·ª£p"];
    end
    
    C3 --> E[H·ªá th·ªëng s·∫µn s√†ng v·ªõi t√†i nguy√™n t·ªëi ∆∞u];
    D2 --> E;
    
    E --> F[MongoDB ho·∫°t ƒë·ªông M·∫†NH M·∫º v√† ·ªîN ƒê·ªäNH];
    
    %% ƒê·ªãnh nghƒ©a style classes
    classDef startNode fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    classDef purposeNode fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    classDef configStep fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    classDef applyStep fill:#c8e6c9,stroke:#388e3c,stroke-width:2px,color:#000
    classDef endNode fill:#e8f5e8,stroke:#388e3c,stroke-width:3px,color:#000
    classDef trapNode fill:#ffcdd2,stroke:#c62828,stroke-width:2px,color:#000
    
    %% √Åp d·ª•ng styles
    class A startNode
    class B purposeNode
    class C1,D1 configStep
    class C2,D3 applyStep
    class C3,D2 applyStep
    class E,F endNode
    class P1,P2,P3 trapNode
``` 

### **Giai ƒëo·∫°n 2: C√†i ƒë·∫∑t v√† Chu·∫©n b·ªã T√†i nguy√™n**

```mermaid
flowchart TD
    subgraph "Network Topology & Port Configuration"
        subgraph "mongo-1 (192.168.0.38)"
            M1C[Config Server<br/>Port 27010]
            M1S1[Shard1 RS<br/>Port 27011]
            M1S2[Shard2 RS<br/>Port 27012] 
            M1S3[Shard3 RS<br/>Port 27013]
            M1MOS[Mongos Router<br/>Port 27020]
        end
        
        subgraph "mongo-2 (192.168.0.241)"
            M2C[Config Server<br/>Port 27010]
            M2S1[Shard1 RS<br/>Port 27011]
            M2S2[Shard2 RS<br/>Port 27012]
            M2S3[Shard3 RS<br/>Port 27013]
        end
        
        subgraph "mongo-3 (192.168.0.215)"
            M3C[Config Server<br/>Port 27010]
            M3S1[Shard1 RS<br/>Port 27011]
            M3S2[Shard2 RS<br/>Port 27012]
            M3S3[Shard3 RS<br/>Port 27013]
        end
    end
    
    subgraph "Security & Resource Setup"
        A[Install MongoDB] --> B[Create KeyFile]
        B --> C["Generate with openssl<br/>Base64 756 chars"]
        C --> D["Set permissions 400<br/>Owner: mongod:mongod"]
        D --> E["Copy to all nodes<br/>Identical keyfile"]
        E --> F["Create data directories<br/>/data/config, /data/shard1-3"]
        F --> G["Configure firewall<br/>Ports 27010-27020"]
        G --> H["Resources Ready"]
    end
    
    subgraph "Inter-node Communication"
        M1C -.->|"Replica Set"| M2C
        M2C -.->|"Replica Set"| M3C
        M3C -.->|"Replica Set"| M1C
        
        M1S1 -.->|"Shard01 RS"| M2S1
        M2S1 -.->|"Shard01 RS"| M3S1
        M3S1 -.->|"Shard01 RS"| M1S1
    end
    
    style M1MOS fill:#fff3e0
    style H fill:#e8f5e8
    style C fill:#ffebee
```

#### **1. C√†i ƒë·∫∑t MongoDB**

*   **Th·ª±c hi·ªán ƒë√∫ng (n·∫øu c√†i l·∫°i t·ª´ ƒë·∫ßu):**
    ```bash
    yum remove mongodb* -y
    rm -rf /var/log/mongodb /var/lib/mongo /tmp/*.sock
    yum install mongodb-org -y
    rpm -qa | grep mongodb-org # X√°c nh·∫≠n phi√™n b·∫£n 7.0+
    ```

#### **2. T·∫°o KeyFile (X√°c th·ª±c n·ªôi b·ªô)**

*   **M·ª•c ƒë√≠ch:** M·∫≠t kh·∫©u chung ƒë·ªÉ c√°c th√†nh vi√™n trong cluster (mongod, mongos) tin t∆∞·ªüng v√† giao ti·∫øp v·ªõi nhau.

‚ö†Ô∏è **B·∫™Y NG∆Ø·ªúI M·ªöI - Giai ƒëo·∫°n 2:**
- **Keyfile kh√°c nhau gi·ªØa c√°c m√°y** ‚Üí n·ªôi b·ªô t·ª´ ch·ªëi b·∫Øt tay
- **Qu√™n `chmod 400`** ‚Üí MongoDB t·ª´ ch·ªëi kh·ªüi ƒë·ªông v√¨ keyfile kh√¥ng an to√†n
- **T·∫°o th∆∞ m·ª•c b·∫±ng `root` r·ªìi qu√™n `chown mongod:mongod`** ‚Üí "Permission denied"

*   **Th·ª±c hi·ªán ƒë√∫ng (L√†m tr√™n `mongo-1`, sau ƒë√≥ copy ƒëi):**
    1.  T·∫°o th∆∞ m·ª•c v√† file key:
        ```bash
        mkdir -p /data
        openssl rand -base64 756 | tee /data/mongo-keyfile >/dev/null
        ```
    2.  **C·ª±c k·ª≥ quan tr·ªçng:** ƒê·∫∑t ƒë√∫ng ch·ªß s·ªü h·ªØu v√† quy·ªÅn:
        ```bash
        chown mongod:mongod /data/mongo-keyfile
        chmod 400 /data/mongo-keyfile
        ```
    3.  Copy keyfile sang 2 m√°y c√≤n l·∫°i v√† **set l·∫°i quy·ªÅn tr√™n t·ª´ng m√°y ƒë√≥**:

        Tr∆∞·ªõc ti√™n, h√£y th·ª≠ copy tr·ª±c ti·∫øp ƒë·∫øn t√†i kho·∫£n `root` tr√™n c√°c m√°y ƒë√≠ch:
        ```bash
        # Tr√™n m√°y mongo-1 (n∆°i c√≥ keyfile g·ªëc)
        scp /data/mongo-keyfile root@mongo-2:/data/
        scp /data/mongo-keyfile root@mongo-3:/data/
        ```

        **üí° X·ª≠ l√Ω t√¨nh hu·ªëng: Kh√¥ng th·ªÉ `scp` tr·ª±c ti·∫øp ƒë·∫øn t√†i kho·∫£n `root`**

        Trong nhi·ªÅu m√¥i tr∆∞·ªùng production ho·∫∑c c√†i ƒë·∫∑t b·∫£o m·∫≠t cao, vi·ªác ƒëƒÉng nh·∫≠p tr·ª±c ti·∫øp b·∫±ng `root` qua SSH (bao g·ªìm c·∫£ `scp` d∆∞·ªõi quy·ªÅn `root`) th∆∞·ªùng b·ªã v√¥ hi·ªáu h√≥a. Khi c·ªë g·∫Øng ch·∫°y c√°c l·ªánh `scp` ·ªü tr√™n, b·∫°n c√≥ th·ªÉ nh·∫≠n ƒë∆∞·ª£c c√°c th√¥ng b√°o l·ªói nh∆∞:
        *   `Permission denied (publickey,password).`
        *   `Authentication failed.`
        *   `ssh: connect to host mongo-2 port 22: Permission denied` (n·∫øu SSH qua root b·ªã ch·∫∑n ho√†n to√†n)

        N·∫øu g·∫∑p tr∆∞·ªùng h·ª£p n√†y, b·∫°n s·∫Ω c·∫ßn th·ª±c hi·ªán c√°c b∆∞·ªõc sau:

        *   **B∆∞·ªõc 1: `scp` ƒë·∫øn m·ªôt t√†i kho·∫£n ng∆∞·ªùi d√πng c√≥ quy·ªÅn SSH tr√™n m√°y ƒë√≠ch.**
            Gi·∫£ s·ª≠ b·∫°n c√≥ m·ªôt t√†i kho·∫£n ng∆∞·ªùi d√πng th√¥ng th∆∞·ªùng (v√≠ d·ª•: `youruser`) tr√™n `mongo-2` v√† `mongo-3`, v√† t√†i kho·∫£n n√†y c√≥ th·ªÉ SSH v√†o. B·∫°n c√≥ th·ªÉ copy keyfile ƒë·∫øn th∆∞ m·ª•c `/home/youruser/` ho·∫∑c `/tmp/` c·ªßa t√†i kho·∫£n ƒë√≥.
            
            **Quan tr·ªçng:** ƒê·∫£m b·∫£o t√†i kho·∫£n `youruser` c√≥ quy·ªÅn ghi v√†o th∆∞ m·ª•c ƒë√≠ch t·∫°m th·ªùi n√†y. Th√¥ng th∆∞·ªùng, th∆∞ m·ª•c `/home/youruser/` v√† `/tmp/` ƒë·ªÅu cho ph√©p ng∆∞·ªùi d√πng s·ªü h·ªØu ghi v√†o. B·∫°n c√≥ th·ªÉ ki·ªÉm tra b·∫±ng l·ªánh `ls -ld /home/youruser` ho·∫∑c `ls -ld /tmp` sau khi SSH v√†o m√°y ƒë√≠ch. N·∫øu c·ªôt quy·ªÅn c√≥ k√Ω t·ª± `w` (write) cho `owner`, b·∫°n c√≥ th·ªÉ ghi v√†o ƒë√≥.

            ```bash
            # Tr√™n m√°y mongo-1 (n∆°i c√≥ keyfile g·ªëc)
            # Thay 'youruser' b·∫±ng t√™n user th·ª±c t·∫ø c·ªßa b·∫°n tr√™n m√°y ƒë√≠ch
            scp /data/mongo-keyfile youruser@mongo-2:/home/youruser/mongo-keyfile
            scp /data/mongo-keyfile youruser@mongo-3:/home/youruser/mongo-keyfile
            ```

        *   **B∆∞·ªõc 2: SSH v√†o t·ª´ng m√°y ƒë√≠ch v√† di chuy·ªÉn file, sau ƒë√≥ ƒë·∫∑t l·∫°i quy·ªÅn.**
            Sau khi `scp` th√†nh c√¥ng, b·∫°n c·∫ßn ƒëƒÉng nh·∫≠p v√†o t·ª´ng m√°y ƒë√≠ch (v√≠ d·ª•: `mongo-2`) ƒë·ªÉ di chuy·ªÉn file `mongo-keyfile` v·ªÅ ƒë√∫ng v·ªã tr√≠ `/data/` v√† ƒë·∫∑t l·∫°i quy·ªÅn.

            ```bash
            # Tr√™n m√°y mongo-2:
            ssh youruser@mongo-2
            
            # Sau khi SSH th√†nh c√¥ng, ch·∫°y c√°c l·ªánh sau (s·ª≠ d·ª•ng ƒë·ªÉ c√≥ quy·ªÅn root):
            mv /home/youruser/mongo-keyfile /data/
            chown mongod:mongod /data/mongo-keyfile
            chmod 400 /data/mongo-keyfile
            exit # Tho√°t kh·ªèi phi√™n SSH
            ```

            Th·ª±c hi·ªán t∆∞∆°ng t·ª± cho `mongo-3`:

            ```bash
            # Tr√™n m√°y mongo-3:
            ssh youruser@mongo-3
            
            # Sau khi SSH th√†nh c√¥ng, ch·∫°y c√°c l·ªánh sau:
            mv /home/youruser/mongo-keyfile /data/
            chown mongod:mongod /data/mongo-keyfile
            chmod 400 /data/mongo-keyfile
            exit # Tho√°t kh·ªèi phi√™n SSH
            ```

        *   **B∆∞·ªõc 3: X√°c nh·∫≠n quy·ªÅn ƒë√£ ƒë√∫ng tr√™n T·∫§T C·∫¢ c√°c m√°y.**
            Sau khi ho√†n th√†nh c√°c b∆∞·ªõc tr√™n cho c·∫£ 3 m√°y (`mongo-1`, `mongo-2`, `mongo-3`), h√£y ki·ªÉm tra l·∫°i quy·ªÅn c·ªßa keyfile tr√™n m·ªói m√°y ƒë·ªÉ ƒë·∫£m b·∫£o m·ªçi th·ª© ch√≠nh x√°c:

            ```bash
            # Ch·∫°y l·ªánh n√†y tr√™n t·ª´ng m√°y: mongo-1, mongo-2, mongo-3
            ls -l /data/mongo-keyfile
            
            # K·∫øt qu·∫£ mong mu·ªën s·∫Ω gi·ªëng nh∆∞ sau (h√£y ch√∫ √Ω c·ªôt quy·ªÅn `-r--------` v√† ch·ªß s·ªü h·ªØu `mongod mongod`):
            
            -r--------. 1 mongod mongod 1024 Aug 30 08:30 /data/mongo-keyfile
            ```


#### **3. T·∫°o Th∆∞ m·ª•c D·ªØ li·ªáu v√† Log**

*   **B·∫´y ng∆∞·ªùi m·ªõi:** T·∫°o th∆∞ m·ª•c b·∫±ng `root` v√† qu√™n `chown`, d·∫´n ƒë·∫øn l·ªói "Permission denied".
*   **Th·ª±c hi·ªán ƒë√∫ng (Tr√™n C·∫¢ 3 M√ÅY):**
    ```bash
    mkdir -p /data/config /data/shard1 /data/shard2 /data/shard3
    chown -R mongod:mongod /data
    ```

#### **4. M·ªü Firewall**

*   **B·∫´y ng∆∞·ªùi m·ªõi:** Th√™m rule `--permanent` nh∆∞ng qu√™n `--reload`.
*   **Th·ª±c hi·ªán ƒë√∫ng (Tr√™n C·∫¢ 3 M√ÅY):**
    ```bash
    firewall-cmd --add-port=27010-27020/tcp --permanent
    firewall-cmd --reload
    # N·∫øu kh√¥ng th·∫•y port, ki·ªÉm tra firewall: firewall-cmd --list-all
    ```

---

### **Giai ƒëo·∫°n 3: D·ª±ng C·ª•m Config Server**

```mermaid
sequenceDiagram
    participant Admin as Administrator
    participant CFG1 as Config Server 1
    participant CFG2 as Config Server 2
    participant CFG3 as Config Server 3
    
    Admin->>CFG1: Create config file
    Admin->>CFG2: Create config file
    Admin->>CFG3: Create config file
    
    Admin->>CFG1: Start mongod --config
    Admin->>CFG2: Start mongod --config
    Admin->>CFG3: Start mongod --config
    
    Admin->>CFG1: Connect and rs.initiate()
    CFG1->>CFG2: Replica Set sync
    CFG1->>CFG3: Replica Set sync
    
    CFG1->>Admin: PRIMARY elected
    Admin->>CFG1: Create admin user
    Admin->>CFG1: Enable authorization
    
    Note over CFG1,CFG3: Config Server Replica Set Ready
```

#### **1. T·∫°o File C·∫•u h√¨nh (Tr√™n C·∫¢ 3 M√ÅY)**

*   **File `/etc/mongod-config.conf`:**
```yaml
systemLog:
  destination: file
  logAppend: true
  path: /data/config.log
 
storage:
  dbPath: /data/config
#  journal:
#    enabled: true
 
processManagement:
#  fork: true  # fork and run in background
#  pidFilePath: /data/mongod-config.pid  # location of pidfile
  timeZoneInfo: /usr/share/zoneinfo
 
net:
  port: 27010
  bindIp: 0.0.0.0  # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting.

security:
#  authorization: enabled
  keyFile: /data/mongo-keyfile 
replication:
   replSetName: "Rep1"
sharding:
   clusterRole: configsvr
```
*   **B·∫´y Ng∆∞·ªùi M·ªõi:** V·ªôi v√†ng b·∫≠t `authorization: enabled`. ƒêi·ªÅu n√†y s·∫Ω ch·∫∑n b·∫°n kh·ªüi t·∫°o replica set v√† t·∫°o user admin ƒë·∫ßu ti√™n (v·∫•n ƒë·ªÅ "con g√† qu·∫£ tr·ª©ng"). Quy tr√¨nh ƒë√∫ng l√† gi·ªØ `keyFile` (x√°c th·ª±c n·ªôi b·ªô) nh∆∞ng t·∫°m t·∫Øt `authorization` (x√°c th·ª±c client).

    **Gi·∫£i th√≠ch chi ti·∫øt v·ªÅ B·∫´y Ng∆∞·ªùi M·ªõi n√†y:**

    `keyFile` v√† `authorization: enabled` ph·ª•c v·ª• hai m·ª•c ƒë√≠ch b·∫£o m·∫≠t kh√°c nhau:
    *   **`keyFile` (Internal Authentication):** ƒê√¢y l√† "m·∫≠t kh·∫©u chung" ƒë·ªÉ c√°c ti·∫øn tr√¨nh MongoDB trong cluster (Config Server, Shard, Mongos) tin t∆∞·ªüng v√† giao ti·∫øp an to√†n v·ªõi nhau. Khi `keyFile` ƒë∆∞·ª£c c·∫•u h√¨nh, c√°c node c√≥ th·ªÉ t·ª± nh·∫≠n di·ªán v√† x√¢y d·ª±ng c√°c Replica Set ho·∫∑c k·∫øt n·ªëi v·ªõi nhau trong cluster. N√≥ ho·∫°t ƒë·ªông ƒë·ªôc l·∫≠p v·ªõi vi·ªác x√°c th·ª±c ng∆∞·ªùi d√πng cu·ªëi.
    *   **`authorization: enabled` (Client Authentication):** Khi tham s·ªë n√†y ƒë∆∞·ª£c b·∫≠t, MongoDB s·∫Ω y√™u c·∫ßu B·∫§T K·ª≤ k·∫øt n·ªëi t·ª´ b√™n ngo√†i (v√≠ d·ª•: c√¥ng c·ª• `mongosh` c·ªßa b·∫°n, ·ª©ng d·ª•ng client) ph·∫£i cung c·∫•p t√™n ng∆∞·ªùi d√πng v√† m·∫≠t kh·∫©u h·ª£p l·ªá tr∆∞·ªõc khi ƒë∆∞·ª£c ph√©p th·ª±c hi·ªán c√°c thao t√°c.

    **V·∫•n ƒë·ªÅ "Con g√† v√† Qu·∫£ tr·ª©ng" x·∫£y ra khi b·∫°n b·∫≠t `authorization: enabled` qu√° s·ªõm:**
    1.  ·ªû giai ƒëo·∫°n n√†y, b·∫°n ƒëang c·ªë g·∫Øng kh·ªüi t·∫°o m·ªôt Config Server Replica Set l·∫ßn ƒë·∫ßu ti√™n b·∫±ng l·ªánh `rs.initiate()` th√¥ng qua `mongosh`.
    2.  N·∫øu `authorization: enabled` ƒë√£ ƒë∆∞·ª£c b·∫≠t trong file c·∫•u h√¨nh, th√¨ ngay c·∫£ khi `mongosh` k·∫øt n·ªëi t·ª´ c√πng m·ªôt m√°y ch·ªß (localhost), n√≥ v·∫´n s·∫Ω b·ªã coi l√† m·ªôt client "ch∆∞a ƒë∆∞·ª£c x√°c th·ª±c".
    3.  MongoDB s·∫Ω **t·ª´ ch·ªëi** th·ª±c hi·ªán l·ªánh `rs.initiate()` v√¨ b·∫°n kh√¥ng c√≥ quy·ªÅn. B·∫°n s·∫Ω th·∫•y l·ªói nh∆∞ `Not authorized to run command 'replSetInitiate'` ho·∫∑c t∆∞∆°ng t·ª±.
    4.  ƒêi·ªÅu tr·ªõ tr√™u l√†, ƒë·ªÉ c√≥ quy·ªÅn, b·∫°n c·∫ßn ph·∫£i c√≥ m·ªôt user admin. Nh∆∞ng user admin l·∫°i ch·ªâ c√≥ th·ªÉ ƒë∆∞·ª£c t·∫°o *sau khi* Replica Set ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng v√† c√≥ m·ªôt node `PRIMARY` (n∆°i c√°c thao t√°c ghi d·ªØ li·ªáu, bao g·ªìm t·∫°o user, c√≥ th·ªÉ di·ªÖn ra).
    5.  B·∫°n b·ªã m·∫Øc k·∫πt: kh√¥ng th·ªÉ kh·ªüi t·∫°o Replica Set v√¨ thi·∫øu user, nh∆∞ng kh√¥ng th·ªÉ t·∫°o user v√¨ Replica Set ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. ƒê√¢y ch√≠nh l√† v·∫•n ƒë·ªÅ "con g√† v√† qu·∫£ tr·ª©ng".

    **Quy tr√¨nh ƒë√∫ng ƒë·∫Øn ƒë·ªÉ tr√°nh l·ªói n√†y:**
    *   T·∫°m th·ªùi **COMMENT** ho·∫∑c SET `authorization: false` trong file c·∫•u h√¨nh `mongod-config.conf` khi kh·ªüi ƒë·ªông Config Server l·∫ßn ƒë·∫ßu.
    *   Sau khi c√°c Config Server ƒë√£ kh·ªüi ƒë·ªông, k·∫øt n·ªëi b·∫±ng `mongosh` (l√∫c n√†y kh√¥ng c·∫ßn x√°c th·ª±c) v√† ch·∫°y `rs.initiate()` ƒë·ªÉ thi·∫øt l·∫≠p Replica Set.
    *   ƒê·ª£i cho ƒë·∫øn khi m·ªôt node ƒë∆∞·ª£c b·∫ßu l√†m `PRIMARY`.
    *   **Tr√™n node `PRIMARY` ƒë√≥**, t·∫°o user admin ƒë·∫ßu ti√™n b·∫±ng l·ªánh `db.createUser()`.
    *   Sau khi user admin ƒë√£ t·ªìn t·∫°i, b·∫°n m·ªõi n√™n **B·ªé COMMENT** d√≤ng `authorization: enabled` trong file c·∫•u h√¨nh tr√™n **T·∫§T C·∫¢** c√°c Config Server v√† **kh·ªüi ƒë·ªông l·∫°i an to√†n** c√°c ti·∫øn tr√¨nh `mongod` ƒë·ªÉ k√≠ch ho·∫°t b·∫£o m·∫≠t. T·ª´ l√∫c n√†y, m·ªçi k·∫øt n·ªëi t·ª´ client s·∫Ω y√™u c·∫ßu x√°c th·ª±c.

#### **2. Kh·ªüi ƒë·ªông Config Server**
*   **Th·ª±c hi·ªán ƒë√∫ng (Tr√™n C·∫¢ 3 M√ÅY):**
    ```bash
    sudo -u mongod /usr/bin/mongod --config /etc/mongod-config.conf &
    tail -f /data/config.log # Theo d√µi log ƒë·ªÉ t√¨m "waiting for connections"
    ```
*   **L∆∞u √Ω:** ` &` ph√π h·ª£p cho lab. M√¥i tr∆∞·ªùng production n√™n t·∫°o file unit systemd ƒë·ªÉ qu·∫£n l√Ω d·ªãch v·ª• chuy√™n nghi·ªáp h∆°n.

#### **3. Kh·ªüi t·∫°o Replica Set v√† T·∫°o User Admin**

*   **B·∫´y ng∆∞·ªùi m·ªõi:** T·∫°o user tr∆∞·ªõc khi `initiate`; b·ªëi r·ªëi v√¨ prompt m·∫∑c ƒë·ªãnh l√† `test>`.
*   **Th·ª±c hi·ªán ƒë√∫ng (Ch·ªâ l√†m tr√™n 1 m√°y):**
    1.  K·∫øt n·ªëi: `mongosh localhost:27010`
    2.  Kh·ªüi t·∫°o replica set:
        ```javascript
        rs.initiate({
          _id: "Rep1", configsvr: true,
          members: [
            { _id: 0, host: "mongo-1:27010" },
            { _id: 1, host: "mongo-2:27010" },
            { _id: 2, host: "mongo-3:27010" }
          ]
        })
        ```
    3.  **ƒê·ª£i node l√™n PRIMARY** (prompt chuy·ªÉn th√†nh `Rep1 [primary]>`):
        ```javascript
        // L·ªánh ƒë·ªÉ ch·ªù t·ª± ƒë·ªông
        while (!db.hello().isWritablePrimary) { sleep(1000); print("...waiting for PRIMARY"); }
        ```
    4.  **Khi ƒë√£ c√≥ PRIMARY**, t·∫°o ngay user admin ƒë·∫ßu ti√™n:
        
‚ö†Ô∏è **B·∫™Y B·∫¢O M·∫¨T QUAN TR·ªåNG:**
- **D√πng m·∫≠t kh·∫©u text trong script** ‚Üí r√≤ r·ªâ qua shell history
- **LU√îN d√πng `passwordPrompt()` thay v√¨ hard-code m·∫≠t kh·∫©u**

        ```javascript
        use admin
        db.createUser({
          user: "mongodba", 
          pwd: passwordPrompt(), // <-- Nh·∫≠p an to√†n thay v√¨ hard-code
          roles: [{role: "root", db: "admin"}]
        })
        ```
    1.  *(T√πy ch·ªçn)*: N·∫øu mu·ªën m·ªôt node m·∫°nh h∆°n lu√¥n ƒë∆∞·ª£c ∆∞u ti√™n l√†m PRIMARY, b·∫°n c√≥ th·ªÉ ch·ªânh `priority`. M·∫∑c ƒë·ªãnh kh√¥ng c·∫ßn thi·∫øt.
        ```javascript
        cfg = rs.conf()
        cfg.members[0].priority = 3 // Node mongo-1 ∆∞u ti√™n cao nh·∫•t
        rs.reconfig(cfg)
        ```
    2.  Tho√°t kh·ªèi mongosh: `exit`

#### **4. B·∫≠t X√°c th·ª±c v√† Kh·ªüi ƒë·ªông l·∫°i**

*   **Th·ª±c hi·ªán (Tr√™n C·∫¢ 3 M√ÅY):**
    1.  S·ª≠a file `/etc/mongod-config.conf`, **b·ªè comment** d√≤ng `authorization: enabled`.
    2.  Kh·ªüi ƒë·ªông l·∫°i ti·∫øn tr√¨nh m·ªôt c√°ch an to√†n:
        ```bash
        # G·ª≠i t√≠n hi·ªáu SIGTERM (15) ƒë·ªÉ shutdown an to√†n, tr√°nh kill -9
        pkill -15 -f "mongod-config.conf"
        sudo -u mongod /usr/bin/mongod --config /etc/mongod-config.conf &
        ```
    3.  Ki·ªÉm tra ƒëƒÉng nh·∫≠p b·∫±ng t√†i kho·∫£n admin:
        `mongosh --port 27010 sudo -u mongodba --authenticationDatabase admin`
        (S·∫Ω prompt nh·∫≠p password an to√†n)

---
**üí° X·ª¨ L√ù L·ªñI PH·ªî BI·∫æN: L·ª† B·∫¨T `authorization: enabled` QU√Å S·ªöM HO·∫∂C QU√äN T·∫†O USER ADMIN NGAY L·∫¨P T·ª®C**

N·∫øu b·∫°n ƒë√£ l·ª° b·ªè comment d√≤ng `authorization: enabled` trong file c·∫•u h√¨nh `/etc/mongod-config.conf` (ho·∫∑c kh·ªüi ƒë·ªông l·∫°i Config Server v·ªõi `authorization` b·∫≠t) **tr∆∞·ªõc khi t·∫°o user admin** (`mongodba`), b·∫°n s·∫Ω g·∫∑p l·ªói `MongoServerError[Unauthorized]` khi c·ªë g·∫Øng th·ª±c hi·ªán b·∫•t k·ª≥ l·ªánh qu·∫£n tr·ªã n√†o (v√≠ d·ª•: `rs.initiate()`, `rs.conf()`, `db.createUser()`).

**C√°ch kh·∫Øc ph·ª•c t√¨nh hu·ªëng n√†y ƒë·ªÉ ti·∫øp t·ª•c thi·∫øt l·∫≠p Config Server:**

**M·ª•c ti√™u:** T·∫°m th·ªùi t·∫Øt `authorization` ƒë·ªÉ c√≥ th·ªÉ k·∫øt n·ªëi `mongosh` m√† kh√¥ng c·∫ßn x√°c th·ª±c, t·ª´ ƒë√≥ t·∫°o ƒë∆∞·ª£c user admin, sau ƒë√≥ m·ªõi b·∫≠t l·∫°i b·∫£o m·∫≠t.

**Th·ª±c hi·ªán c√°c b∆∞·ªõc sau tr√™n C·∫¢ 3 M√ÅY CONFIG SERVER (`mongo-1`, `mongo-2`, `mongo-3`):**

1.  **D·ª´ng ti·∫øn tr√¨nh `mongod` c·ªßa Config Server ƒëang ch·∫°y:**
    ```bash
    pkill -15 -f "mongod --config /etc/mongod-config.conf"
    sleep 5 # Ch·ªù 5 gi√¢y ƒë·ªÉ ti·∫øn tr√¨nh d·ª´ng h·∫≥n
    ```
    *   **Gi·∫£i th√≠ch:** B∆∞·ªõc n√†y ƒë·∫£m b·∫£o ti·∫øn tr√¨nh MongoDB ƒëang ch·∫°y v·ªõi c·∫•u h√¨nh `authorization` b·∫≠t b·ªã t·∫Øt ho√†n to√†n.

2.  **S·ª≠a file c·∫•u h√¨nh `/etc/mongod-config.conf` ƒë·ªÉ t·∫Øt `authorization` t·∫°m th·ªùi:**
    ```bash
    vi /etc/mongod-config.conf
    ```
    T√¨m d√≤ng `authorization: enabled` v√† **COMMENT** n√≥ l·∫°i b·∫±ng c√°ch th√™m d·∫•u `#` v√†o ƒë·∫ßu d√≤ng:
    ```yaml
    security:
      keyFile: /data/mongo-keyfile
      # authorization: enabled  # <-- ƒê·∫£m b·∫£o d√≤ng n√†y c√≥ d·∫•u # ·ªü ƒë·∫ßu
    ```    L∆∞u v√† ƒë√≥ng file (`:wq`).
    *   **Gi·∫£i th√≠ch:** Vi·ªác n√†y cho ph√©p MongoDB kh·ªüi ƒë·ªông m√† kh√¥ng y√™u c·∫ßu x√°c th·ª±c ng∆∞·ªùi d√πng t·ª´ client.

3.  **Kh·ªüi ƒë·ªông l·∫°i ti·∫øn tr√¨nh `mongod` c·ªßa Config Server:**
    ```bash
    sudo -u mongod /usr/bin/mongod --config /etc/mongod-config.conf &
    tail -f /data/config.log # Ki·ªÉm tra log ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng c√≥ l·ªói x√°c th·ª±c
    ```
    *   **Gi·∫£i th√≠ch:** Ti·∫øn tr√¨nh `mongod` gi·ªù s·∫Ω kh·ªüi ƒë·ªông v·ªõi `authorization` ƒë√£ t·∫Øt.

**Sau khi ho√†n th√†nh 3 b∆∞·ªõc kh·∫Øc ph·ª•c tr√™n c·∫£ 3 m√°y, b·∫°n ƒë√£ c√≥ th·ªÉ ti·∫øp t·ª•c v·ªõi c√°c b∆∞·ªõc thi·∫øt l·∫≠p Config Server:**

*   **N·∫øu b·∫°n ch∆∞a t·ª´ng ch·∫°y `rs.initiate()` th√†nh c√¥ng (v√≠ d·ª•: b·ªã l·ªói `Unauthorized` ngay t·ª´ ƒë·∫ßu):**
    Quay l·∫°i **m·ª•c "3. Kh·ªüi t·∫°o Replica Set v√† T·∫°o User Admin"** ·ªü tr√™n v√† th·ª±c hi·ªán l·∫°i **t·ª´ b∆∞·ªõc 1 ("K·∫øt n·ªëi: `mongosh localhost:27010`")**. L·∫ßn n√†y, m·ªçi l·ªánh s·∫Ω ch·∫°y th√†nh c√¥ng v√¨ `authorization` ƒë√£ t·∫Øt.

*   **N·∫øu b·∫°n ƒë√£ ch·∫°y `rs.initiate({})` nh∆∞ng qu√™n th√™m c√°c member ho·∫∑c qu√™n t·∫°o user admin:**
    B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng `rs.reconfig()` ƒë·ªÉ th√™m c√°c th√†nh vi√™n c√≤n l·∫°i v√† sau ƒë√≥ t·∫°o user admin (nh∆∞ ƒë√£ h∆∞·ªõng d·∫´n trong ph·∫ßn "B·∫´y Ng∆∞·ªùi M·ªõi" c·ªßa m·ª•c n√†y).

    *   **K·∫øt n·ªëi `mongosh` tr√™n m√°y PRIMARY (v√≠ d·ª• `mongo-1`):**
        ```bash
        mongosh --port 27010
        ```
    *   **L·∫•y c·∫•u h√¨nh hi·ªán t·∫°i v√† th√™m c√°c th√†nh vi√™n kh√°c:**
        ```javascript
        cfg = rs.conf()
        cfg.members = [
          { _id: 0, host: "mongo-1:27010" },
          { _id: 1, host: "mongo-2:27010" },
          { _id: 2, host: "mongo-3:27010" }
        ];
        cfg.configsvr = true;
        rs.reconfig(cfg, { force: true });
        ```
    *   **Ch·ªù PRIMARY v√† t·∫°o user admin:**
        ```javascript
        while (!db.hello().isWritablePrimary) { sleep(1000); print("...waiting for PRIMARY"); }
        use admin
        db.createUser({user: "mongodba", pwd: passwordPrompt(), roles:[{role: "root", db: "admin"}]})
        exit
        ```

---

#### **4. B·∫≠t X√°c th·ª±c v√† Kh·ªüi ƒë·ªông l·∫°i**

*   **Th·ª±c hi·ªán (Tr√™n C·∫¢ 3 M√ÅY):**
    1.  S·ª≠a file `/etc/mongod-config.conf`, **b·ªè comment** d√≤ng `authorization: enabled`.
    2.  Kh·ªüi ƒë·ªông l·∫°i ti·∫øn tr√¨nh m·ªôt c√°ch an to√†n:
        ```bash
        # G·ª≠i t√≠n hi·ªáu SIGTERM (15) ƒë·ªÉ shutdown an to√†n, tr√°nh kill -9
        pkill -15 -f "mongod --config /etc/mongod-config.conf"
        sudo -u mongod /usr/bin/mongod --config /etc/mongod-config.conf &
        ```
    3.  Ki·ªÉm tra ƒëƒÉng nh·∫≠p b·∫±ng t√†i kho·∫£n admin:
        `mongosh --port 27010 sudo -u mongodba --authenticationDatabase admin`
        (S·∫Ω prompt nh·∫≠p password an to√†n)


---

### **Giai ƒëo·∫°n 4: D·ª±ng c√°c C·ª•m Shard**

```mermaid
graph TD
    subgraph "Shard Creation Process"
        A[Create Shard Config Files] --> B[Start Shard Processes]
        B --> C[Initialize Replica Sets]
        C --> D[Verify Shard Status]
    end
    
    subgraph "Shard 1 - Port 27011"
        S1A[mongo-1:27011]
        S1B[mongo-2:27011]
        S1C[mongo-3:27011]
        S1A --- S1B
        S1B --- S1C
        S1C --- S1A
    end
    
    subgraph "Shard 2 - Port 27012"
        S2A[mongo-1:27012]
        S2B[mongo-2:27012]
        S2C[mongo-3:27012]
        S2A --- S2B
        S2B --- S2C
        S2C --- S2A
    end
    
    subgraph "Shard 3 - Port 27013"
        S3A[mongo-1:27013]
        S3B[mongo-2:27013]
        S3C[mongo-3:27013]
        S3A --- S3B
        S3B --- S3C
        S3C --- S3A
    end
    
    C --> S1A
    C --> S2A
    C --> S3A
```

#### **1. T·∫°o File C·∫•u h√¨nh (Tr√™n C·∫¢ 3 M√ÅY)**

*   **File `/etc/mongod-shard1.conf` (T∆∞∆°ng t·ª± cho shard2, shard3):**
```yaml
systemLog:
  destination: file
  logAppend: true
  logRotate: reopen
  path: /data/shard1.log
 
storage:
  dbPath: /data/shard1
#  journal:
#   enabled: true
 
processManagement:
# fork: true  # fork and run in background
#  pidFilePath: /data/mongod-shard1.pid  # location of pidfile
  timeZoneInfo: /usr/share/zoneinfo
 
net:
  port: 27011
  bindIp: 0.0.0.0  # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting.
 
security:
  authorization: enabled
  keyFile: /data/mongo-keyfile 
replication:
   replSetName: "shard01" 
sharding:
   clusterRole: shardsvr
```
---
*   **File `/etc/mongod-shard2.conf`**
```yaml
systemLog:
  destination: file
  logAppend: true
  logRotate: reopen
  path: /data/shard2.log
 
storage:
  dbPath: /data/shard2
#  journal:
#   enabled: true
 
processManagement:
# fork: true  # fork and run in background
#  pidFilePath: /data/mongod-shard2.pid  # location of pidfile
  timeZoneInfo: /usr/share/zoneinfo
 
net:
  port: 27012
  bindIp: 0.0.0.0  # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting.
 
security:
  authorization: enabled
  keyFile: /data/mongo-keyfile 
replication:
   replSetName: "shard02" 
sharding:
   clusterRole: shardsvr
``` 
---
*   **File `/etc/mongod-shard3.conf`**
```yaml
systemLog:
  destination: file
  logAppend: true
  logRotate: reopen
  path: /data/shard3.log
 
storage:
  dbPath: /data/shard3
#  journal:
#   enabled: true
 
processManagement:
# fork: true  # fork and run in background
#  pidFilePath: /data/mongod-shard3.pid  # location of pidfile
  timeZoneInfo: /usr/share/zoneinfo
 
net:
  port: 27013
  bindIp: 0.0.0.0  # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting.
 
security:
  authorization: enabled
  keyFile: /data/mongo-keyfile 
replication:
   replSetName: "shard03" 
sharding:
   clusterRole: shardsvr
``` 
*   **Gi·∫£i th√≠ch quan tr·ªçng:** ƒê·ªëi v·ªõi shard, b·∫°n c√≥ th·ªÉ b·∫≠t `authorization: enabled` ngay t·ª´ ƒë·∫ßu v√¨ ch√∫ng ta **KH√îNG C·∫¶N T·∫†O USER LOCAL TR√äN SHARD**. Vi·ªác x√°c th·ª±c gi·ªØa c√°c node ƒë√£ c√≥ `keyFile` lo, c√≤n x√°c th·ª±c client s·∫Ω do `mongos` v√† `config server` x·ª≠ l√Ω.

#### **2. Kh·ªüi ƒë·ªông v√† Kh·ªüi t·∫°o Replica Set cho t·ª´ng Shard**

*   **Th·ª±c hi·ªán (Tr√™n C·∫¢ 3 M√ÅY):**
    ```bash
    sudo -u mongod /usr/bin/mongod --config /etc/mongod-shard1.conf &
    sudo -u mongod /usr/bin/mongod --config /etc/mongod-shard2.conf &
    sudo -u mongod /usr/bin/mongod --config /etc/mongod-shard3.conf &
    # Ki·ªÉm tra: ps -ef | grep mongo ph·∫£i th·∫•y 4 ti·∫øn tr√¨nh tr√™n m·ªói node
    ```

*   **Kh·ªüi t·∫°o t√†i kho·∫£n qu·∫£n tr·ªã cho t·ª´ng shard**
Khi b·∫°n kh·ªüi t·∫°o sharding, b·∫°n n√™n t·∫°o t√†i kho·∫£n qu·∫£n tr·ªã cho t·ª´ng shard ƒë·ªÉ qu·∫£n l√Ω ri√™ng bi·ªát. D∆∞·ªõi ƒë√¢y l√† c√°c b∆∞·ªõc chi ti·∫øt ƒë·ªÉ th·ª±c hi·ªán.

B·∫°n ph·∫£i k·∫øt n·ªëi tr·ª±c ti·∫øp ƒë·∫øn t·ª´ng phi√™n b·∫£n mongod c·ªßa t·ª´ng shard ƒë·ªÉ t·∫°o t√†i kho·∫£n.

B·∫°n c·∫ßn k·∫øt n·ªëi t·ªõi Shard 1 b·∫±ng giao di·ªán d√≤ng l·ªánh mongosh. V√¨ b·∫°n ƒë√£ c·∫•u h√¨nh Shard 1 ch·∫°y tr√™n c·ªïng 27011, b·∫°n s·∫Ω k·∫øt n·ªëi t·ªõi c·ªïng ƒë√≥:

```bash
mongosh --port 27011
```

Khi ƒë√£ ·ªü trong mongosh, b·∫°n chuy·ªÉn sang database admin v√† t·∫°o t√†i kho·∫£n qu·∫£n tr·ªã. T√™n ng∆∞·ªùi d√πng v√† m·∫≠t kh·∫©u c√≥ th·ªÉ ƒë·∫∑t t√πy √Ω, nh∆∞ng n√™n theo m·ªôt quy ∆∞·ªõc th·ªëng nh·∫•t ƒë·ªÉ d·ªÖ qu·∫£n l√Ω (v√≠ d·ª•: s1adm cho Shard 1).

```javascript
use admin
db.createUser({
  user: "s1adm",
  pwd: passwordPrompt(),
  roles: [ { role: "root", db: "admin" } ]
})
```

**Gi·∫£i th√≠ch c√°c tham s·ªë:**
* `use admin`: Chuy·ªÉn sang database admin. Quy·ªÅn qu·∫£n tr·ªã h·ªá th·ªëng ch·ªâ c√≥ th·ªÉ ƒë∆∞·ª£c t·∫°o trong database n√†y.
* `user`: T√™n ng∆∞·ªùi d√πng m√† b·∫°n mu·ªën t·∫°o.
* `pwd`: M·∫≠t kh·∫©u c·ªßa ng∆∞·ªùi d√πng. S·ª≠ d·ª•ng `passwordPrompt()` ƒë·ªÉ nh·∫≠p m·∫≠t kh·∫©u an to√†n.
* `roles`: G√°n vai tr√≤ cho ng∆∞·ªùi d√πng. Vai tr√≤ root cung c·∫•p to√†n quy·ªÅn qu·∫£n l√Ω h·ªá th·ªëng, bao g·ªìm c·∫£ quy·ªÅn truy c·∫≠p v√†o c√°c shard.

Sau khi t·∫°o, b·∫°n c√≥ th·ªÉ tho√°t kh·ªèi mongosh v√† l·∫∑p l·∫°i c√°c b∆∞·ªõc t∆∞∆°ng t·ª± cho Shard 2 v√† Shard 3.

L√†m t∆∞∆°ng t·ª± cho Shard 2 (c·ªïng 27012) v√† Shard 3 (c·ªïng 27013).

**K·∫øt n·ªëi t·ªõi Shard 2:**
```bash
mongosh --port 27012
```

**T·∫°o t√†i kho·∫£n:**
```javascript
use admin
db.createUser({
  user: "s2adm",
  pwd: passwordPrompt(),
  roles: [ { role: "root", db: "admin" } ]
})
```

**K·∫øt n·ªëi t·ªõi Shard 3:**
```bash
mongosh --port 27013
```

**T·∫°o t√†i kho·∫£n:**
```javascript
use admin
db.createUser({
  user: "s3adm",
  pwd: passwordPrompt(),
  roles: [ { role: "root", db: "admin" } ]
})
```

Sau khi ho√†n t·∫•t, b·∫°n ƒë√£ c√≥ m·ªôt t√†i kho·∫£n qu·∫£n tr·ªã ri√™ng cho m·ªói shard v√† c√≥ th·ªÉ s·ª≠ d·ª•ng ch√∫ng ƒë·ªÉ k·∫øt n·ªëi v√† qu·∫£n l√Ω t·ª´ng shard b·∫±ng Mongo Compass ho·∫∑c c√°c c√¥ng c·ª• qu·∫£n l√Ω kh√°c.

*   **C·∫•u h√¨nh Replica Set cho c√°c Shard**

Trong m·ªói **replica set**, MongoDB s·∫Ω b·∫ßu ch·ªçn m·ªôt node l√†m **Primary** ƒë·ªÉ nh·∫≠n **read/write**.
N·∫øu kh√¥ng c·∫•u h√¨nh g√¨, MongoDB s·∫Ω ch·ªçn ng·∫´u nhi√™n b·∫•t k·ª≥ node n√†o (c√≥ d·ªØ li·ªáu m·ªõi nh·∫•t v√† k·∫øt n·ªëi ·ªïn ƒë·ªãnh). ƒêi·ªÅu n√†y c√≥ th·ªÉ d·∫´n ƒë·∫øn t√¨nh tr·∫°ng **nhi·ªÅu shard ƒë·ªÅu ch·ªçn c√πng m·ªôt server l√†m Primary**, g√¢y **d·ªìn t·∫£i** v√† kh√¥ng khai th√°c h·∫øt t√†i nguy√™n c·ªßa c√°c server c√≤n l·∫°i.

üëâ V√¨ v·∫≠y, ch√∫ng ta thi·∫øt l·∫≠p **priority** kh√°c nhau cho c√°c node, nh·∫±m **ch·ªâ ƒë·ªãnh node n√†o c√≥ kh·∫£ nƒÉng ƒë∆∞·ª£c b·∫ßu Primary cao h∆°n**. B·∫±ng c√°ch n√†y, m·ªói shard s·∫Ω ∆∞u ti√™n Primary ·ªü m·ªôt server kh√°c nhau ‚Üí h·ªá th·ªëng ƒë·∫°t **c√¢n b·∫±ng t·∫£i**.

### **C·∫•u h√¨nh Replica Set cho Shard1**

**1. Kh·ªüi t·∫°o replica set `shard01` tr√™n c·ªïng 27011**

```bash
mongosh --host localhost --port 27011

use admin

rs.initiate(
  {
    _id: "shard01",
    members: [
      { _id : 0, host : "mongo-1:27011", priority: 3 },
      { _id : 1, host : "mongo-2:27011", priority: 2 },
      { _id : 2, host : "mongo-3:27011", priority: 1 }
    ]
  }
)
```

### **C·∫•u h√¨nh Replica Set cho Shard2**

**2. Kh·ªüi t·∫°o replica set `shard02` tr√™n c·ªïng 27012**

```bash
mongosh --host localhost --port 27012

rs.initiate(
  {
    _id: "shard02",
    members: [
      { _id : 0, host : "mongo-1:27012", priority: 1 },
      { _id : 1, host : "mongo-2:27012", priority: 3 },
      { _id : 2, host : "mongo-3:27012", priority: 2 }
    ]
  }
)
```


### **C·∫•u h√¨nh Replica Set cho Shard3**

**3. Kh·ªüi t·∫°o replica set `shard03` tr√™n c·ªïng 27013**

```bash
mongosh --host localhost --port 27013

rs.initiate(
  {
    _id: "shard03",
    members: [
      { _id : 0, host : "mongo-1:27013", priority: 2 },
      { _id : 1, host : "mongo-2:27013", priority: 1 },
      { _id : 2, host : "mongo-3:27013", priority: 3 }
    ]
  }
)
```

üëâ V·ªõi c·∫•u h√¨nh n√†y:

* **Shard01** s·∫Ω ∆∞u ti√™n `mongo-1` l√†m Primary.
* **Shard02** s·∫Ω ∆∞u ti√™n `mongo-2` l√†m Primary.
* **Shard03** s·∫Ω ∆∞u ti√™n `mongo-3` l√†m Primary.

Nh∆∞ v·∫≠y, **Primary ƒë∆∞·ª£c ph√¢n b·ªï ƒë·ªÅu tr√™n ba server**, ƒë·∫£m b·∫£o t√†i nguy√™n ƒë∆∞·ª£c s·ª≠ d·ª•ng t·ªëi ∆∞u v√† h·ªá th·ªëng **c√¢n b·∫±ng t·∫£i t·ªët h∆°n**.
---

### **Giai ƒëo·∫°n 5: D·ª±ng Mongos v√† Ho√†n thi·ªán Cluster**

```mermaid
flowchart TD
    A[Create Mongos Config] --> B[Start Mongos Process]
    B --> C[Connect to Config Servers]
    C --> D[Add Shard 1]
    D --> E[Add Shard 2]
    E --> F[Add Shard 3]
    F --> G[Enable Sharding on Database]
    G --> H[Shard Collections]
    H --> I[Test Data Distribution]
    I --> J[Cluster Complete]
    
    style A fill:#fff3e0
    style J fill:#e8f5e8
    
    subgraph "Mongos Configuration"
        M1["Port: 27020<br/>ConfigDB: Rep1/mongo-1:27010,mongo-2:27010,mongo-3:27010"]
    end
    
    B --> M1
```

#### **1. T·∫°o File C·∫•u h√¨nh Mongos (Tr√™n 1 m√°y)**

*   **File `/etc/mongos.conf`:**
```yaml
systemLog:
  destination: file
  logAppend: true
  path: /data/mongos.log
 
processManagement:
#  fork: true  # fork and run in background
#  pidFilePath: /data/mongod-mongos.pid  # location of pidfile
  timeZoneInfo: /usr/share/zoneinfo
 
net:
  port: 27020
  bindIp: 0.0.0.0  # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting.
security:
  keyFile: /data/mongo-keyfile 
sharding:
  configDB: "Rep1/mongo-1:27010,mongo-2:27010,mongo-3:27010"
```

#### **2. Kh·ªüi ƒë·ªông Mongos**

```bash
sudo -u mongod /usr/bin/mongos --config /etc/mongos.conf &
tail -f /data/mongos.log # Theo d√µi log ƒë·∫øn khi th·∫•y "connected to config replica set"
```

#### **3. Th√™m c√°c Shard v√†o Cluster**

‚ö†Ô∏è **B·∫™Y NG∆Ø·ªúI M·ªöI - Giai ƒëo·∫°n 5:**
- **`configDB` sai `replSetName`** ho·∫∑c **nh·∫ßm th·ª© t·ª± host** ‚Üí mongos kh√¥ng k·∫øt n·ªëi n·ªïi
- **Ch·ªâ ch·∫°y m·ªôt `mongos`** trong production ‚Üí SPOF v·ªÅ truy v·∫•n (n√™n c√≥ nhi·ªÅu `mongos`)
- **D√πng m·∫≠t kh·∫©u hard-code trong l·ªánh** ‚Üí r√≤ r·ªâ credential

*   **Th·ª±c hi·ªán (K·∫øt n·ªëi v√†o Mongos):**
    ```bash
    mongosh --port 27020 sudo -u mongodba --authenticationDatabase admin
    # S·∫Ω prompt nh·∫≠p password an to√†n
    ```
    B√™n trong mongosh:
    ```javascript
    // D√πng ƒë·ªãnh d·∫°ng replica set / seed list, hi·ªáu qu·∫£ h∆°n
    sh.addShard("shard01/mongo-1:27011,mongo-2:27011,mongo-3:27011")
    sh.addShard("shard02/mongo-1:27012,mongo-2:27012,mongo-3:27012")
    sh.addShard("shard03/mongo-1:27013,mongo-2:27013,mongo-3:27013")
    ```

#### **4. K√≠ch ho·∫°t Sharding v√† Test**

1.  **Ki·ªÉm tra tr·∫°ng th√°i:** `sh.status()` s·∫Ω hi·ªÉn th·ªã c√°c shard ƒë√£ ƒë∆∞·ª£c th√™m.
2.  **B·∫≠t sharding cho database:** `sh.enableSharding("testDB")`
3.  **Shard collection v·ªõi `hashed` key ƒë·ªÉ ph√¢n ph·ªëi ƒë·ªÅu:**
    ```javascript
    use testDB
    sh.shardCollection("testDB.myCollection", { "_id": "hashed" } )
    ```
4.  **Insert d·ªØ li·ªáu ƒë·ªÉ ki·ªÉm tra:**
    ```javascript
    for (var i = 1; i <= 100000; i++) {
      db.myCollection.insertOne({ name: "test_data_" + i });
    }
    db.myCollection.getShardDistribution() // Xem d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ph√¢n ph·ªëi ƒë·ªÅu ch∆∞a
    ```

---

### **Giai ƒëo·∫°n 6: Debug, Ki·ªÉm tra v√† L∆∞u √Ω Production**

```mermaid
flowchart LR
    A[Check Processes] --> B[Verify Shard Status]
    B --> C[Review Logs]
    C --> D[Test Failover]
    D --> E[Monitor Performance]
    E --> F[Production Readiness]
    
    subgraph "Health Checks"
        H1["ps -ef | grep mongo<br/>4 mongod + 1 mongos"]
        H2["sh.status()<br/>All shards active"]
        H3["tail -f /data/*.log<br/>No ERROR/WARNING"]
    end
    
    subgraph "Production Considerations"
        P1["Replace keyFile with x.509 certificates"]
        P2["Regular config server backups"]
        P3["Monitoring with Atlas/Ops Manager"]
        P4["Multiple mongos instances"]
    end
    
    A --> H1
    B --> H2
    C --> H3
    F --> P1
    F --> P2
    F --> P3
    F --> P4
    
    style F fill:#e8f5e8
```

*   **Ki·ªÉm tra t·ªïng th·ªÉ:**
    *   `ps -ef | grep mongo`: Ph·∫£i c√≥ 4 ti·∫øn tr√¨nh `mongod` v√† 1 ti·∫øn tr√¨nh `mongos` (tr√™n node ch·∫°y mongos).
    *   `sh.status()`: C√°c shard ph·∫£i ·ªü tr·∫°ng th√°i `active`.
*   **Xem Logs:** `tail -n 100 /data/*.log` ƒë·ªÉ t√¨m l·ªói `ERROR` ho·∫∑c `WARNING`.
*   **Test Failover:** Th·ª≠ kill ti·∫øn tr√¨nh PRIMARY c·ªßa m·ªôt shard (`pkill -15 -f shard01.conf`) v√† d√πng `rs.status()` tr√™n port c·ªßa shard ƒë√≥ ƒë·ªÉ xem m·ªôt node SECONDARY c√≥ ƒë∆∞·ª£c b·∫ßu l√™n l√†m PRIMARY hay kh√¥ng.
*   **L∆∞u √Ω Production:**
    *   **B·∫£o m·∫≠t:** Thay th·∫ø `keyFile` b·∫±ng ch·ª©ng ch·ªâ **x.509** ƒë·ªÉ m√£ h√≥a v√† x√°c th·ª±c m·∫°nh h∆°n.
    *   **Backup:** Th∆∞·ªùng xuy√™n sao l∆∞u `config server` v√¨ n√≥ ch·ª©a to√†n b·ªô metadata c·ªßa cluster.
    *   **Gi√°m s√°t:** S·ª≠ d·ª•ng c√°c c√¥ng c·ª• nh∆∞ MongoDB Atlas, Ops Manager, ho·∫∑c Prometheus ƒë·ªÉ theo d√µi s·ª©c kh·ªèe h·ªá th·ªëng.
    *   **M·ªü r·ªông:** C√≥ th·ªÉ th√™m c√°c instance `mongos` tr√™n c√°c m√°y kh√°c ƒë·ªÉ c√¢n b·∫±ng t·∫£i truy v·∫•n.
    *   **systemd Unit:** Khuy·∫øn ngh·ªã t·∫°o unit file cho `mongod`/`mongos` thay v√¨ d√πng ` &` trong production.

üí° **M·∫´u systemd Unit cho Production:**
```ini
# /etc/systemd/system/mongod-shard01.service
[Unit]
Description=MongoDB Shard01
After=network.target disable-transparent-huge-pages.service

[Service]
User=mongod
Group=mongod
ExecStart=/usr/bin/mongod --config /etc/mongod-shard1.conf
ExecReload=/bin/kill -HUP $MAINPID
Restart=on-failure
LimitNOFILE=64000
LimitNPROC=64000

[Install]
WantedBy=multi-user.target
```
K√≠ch ho·∫°t: `systemctl daemon-reload && systemctl enable --now mongod-shard01`

---

### **Giai ƒëo·∫°n 7: Thao t√°c v√† Truy v·∫•n D·ªØ li·ªáu (Aggregation Framework)**

```mermaid
graph TD
    A[Raw Data in Collections] --> B{Aggregation Pipeline};
    B --> C[Stage 1: $match<br/>Filter documents];
    C --> D[Stage 2: $group<br/>Aggregate values];
    D --> E[Stage 3: $sort<br/>Order results];
    E --> F[Stage 4: $project<br/>Reshape output];
    F --> G[Final Result Set];

    style A fill:#e3f2fd
    style G fill:#e8f5e8
```

Sau khi ƒë√£ c√≥ m·ªôt cluster ho√†n ch·ªânh, b∆∞·ªõc ti·∫øp theo l√† khai th√°c s·ª©c m·∫°nh c·ªßa d·ªØ li·ªáu. Aggregation Framework l√† m·ªôt c√¥ng c·ª• c·ª±c k·ª≥ m·∫°nh m·∫Ω ƒë·ªÉ th·ª±c hi·ªán c√°c ph√©p bi·∫øn ƒë·ªïi v√† t√≠nh to√°n ph·ª©c t·∫°p ngay tr√™n server.

*   **M·ª•c ƒë√≠ch:** Thay v√¨ k√©o h√†ng t·∫•n d·ªØ li·ªáu th√¥ v·ªÅ ·ª©ng d·ª•ng r·ªìi m·ªõi x·ª≠ l√Ω, ch√∫ng ta s·∫Ω ƒë·∫©y logic t√≠nh to√°n v·ªÅ ph√≠a MongoDB, gi√∫p gi·∫£m t·∫£i bƒÉng th√¥ng m·∫°ng v√† t·∫≠n d·ª•ng t√†i nguy√™n c·ªßa database.
*   **B·∫´y ng∆∞·ªùi m·ªõi:** Th·ª±c hi·ªán c√°c logic n·ªëi (join), l·ªçc, nh√≥m (group by) ph·ª©c t·∫°p ·ªü t·∫ßng ·ª©ng d·ª•ng (application layer). ƒêi·ªÅu n√†y c·ª±c k·ª≥ thi·∫øu hi·ªáu qu·∫£, l√†m ch·∫≠m ·ª©ng d·ª•ng v√† kh√¥ng t·∫≠n d·ª•ng ƒë∆∞·ª£c s·ª©c m·∫°nh c·ªßa MongoDB.
*   **Th·ª±c hi·ªán ƒë√∫ng:** X√¢y d·ª±ng m·ªôt "ƒë∆∞·ªùng ·ªëng" (pipeline) g·ªìm nhi·ªÅu "giai ƒëo·∫°n" (stages), m·ªói giai ƒëo·∫°n s·∫Ω x·ª≠ l√Ω ƒë·∫ßu v√†o t·ª´ giai ƒëo·∫°n tr∆∞·ªõc v√† ƒë∆∞a k·∫øt qu·∫£ cho giai ƒëo·∫°n ti·∫øp theo.

#### **1. B√†i to√°n 1: L·ªçc, S·∫Øp x·∫øp v√† ƒê·ªãnh h√¨nh D·ªØ li·ªáu**

*   **Chu·∫©n b·ªã d·ªØ li·ªáu:**
    ```javascript
    use testDB // S·ª≠ d·ª•ng l·∫°i database t·ª´ Giai ƒëo·∫°n 4
    db.persons.insertMany([
      { "person_id": "6392529400", "firstname": "Elise", "lastname": "Smith", "dateofbirth": ISODate("1972-01-13T09:32:07Z"), "vocation": "ENGINEER", "address": { "number": 5625, "street": "Tipa Circle", "city": "Wojzinmoj" } },
      { "person_id": "1723338115", "firstname": "Olive", "lastname": "Ranieri", "dateofbirth": ISODate("1985-05-12T23:14:30Z"), "gender": "FEMALE", "vocation": "ENGINEER", "address": { "number": 9303, "street": "Mele Circle", "city": "Tobihbo" } },
      { "person_id": "8732762874", "firstname": "Toni", "lastname": "Jones", "dateofbirth": ISODate("1991-11-23T16:53:56Z"), "vocation": "POLITICIAN", "address": { "number": 1, "street": "High Street", "city": "Upper Abbeywoodington" } },
      { "person_id": "7363629563", "firstname": "Bert", "lastname": "Gooding", "dateofbirth": ISODate("1941-04-07T22:11:52Z"), "vocation": "FLORIST", "address": { "number": 13, "street": "Upper Bold Road", "city": "Redringtonville" } },
      { "person_id": "1029648329", "firstname": "Sophie", "lastname": "Celements", "dateofbirth": ISODate("1959-07-06T17:35:45Z"), "vocation": "ENGINEER", "address": { "number": 5, "street": "Innings Close", "city": "Basilbridge" } },
      { "person_id": "7363626383", "firstname": "Carl", "lastname": "Simmons", "dateofbirth": ISODate("1998-12-26T13:13:55Z"), "vocation": "ENGINEER", "address": { "number": 187, "street": "Hillside Road", "city": "Kenningford" } }
    ]);
    ```
*   **Y√™u c·∫ßu:** Tr·∫£ v·ªÅ 3 ng∆∞·ªùi k·ªπ s∆∞ (ENGINEER) tr·∫ª nh·∫•t, ch·ªâ hi·ªÉn th·ªã `firstname`, `lastname`, `dateofbirth`.
*   **L·ªùi gi·∫£i:**
    ```javascript
    db.persons.aggregate([
      // Giai ƒëo·∫°n 1: L·ªçc ra nh·ªØng ng∆∞·ªùi l√† ENGINEER
      { $match: { vocation: "ENGINEER" } },
      // Giai ƒëo·∫°n 2: S·∫Øp x·∫øp theo ng√†y sinh gi·∫£m d·∫ßn (ng√†y sinh l·ªõn h∆°n l√† ng∆∞·ªùi tr·∫ª h∆°n)
      { $sort: { dateofbirth: -1 } },
      // Giai ƒëo·∫°n 3: Gi·ªõi h·∫°n k·∫øt qu·∫£ ch·ªâ l·∫•y 3 ng∆∞·ªùi ƒë·∫ßu ti√™n
      { $limit: 3 },
      // Giai ƒëo·∫°n 4: ƒê·ªãnh h√¨nh l·∫°i output, ·∫©n _id v√† c√°c tr∆∞·ªùng kh√¥ng c·∫ßn thi·∫øt
      { $project: {
          _id: 0,
          firstname: 1,
          lastname: 1,
          dateofbirth: 1
      }}
    ])
    ```

#### **2. B√†i to√°n 2: Th·ªëng k√™ v√† Nh√≥m D·ªØ li·ªáu**

*   **Chu·∫©n b·ªã d·ªØ li·ªáu:**
    ```javascript
    db.orders.insertMany([
      { "customer_id": "elise_smith@myemail.com", "orderdate": ISODate("2020-05-30T08:35:52Z"), "value": NumberDecimal("231.43")},
      { "customer_id": "elise_smith@myemail.com", "orderdate": ISODate("2020-01-13T09:32:07Z"), "value": NumberDecimal("99.99")},
      { "customer_id": "oranieri@warmmail.com", "orderdate": ISODate("2020-01-01T08:25:37Z"), "value": NumberDecimal("63.13")},
      { "customer_id": "tj@wheresmyemail.com", "orderdate": ISODate("2019-05-28T19:13:32Z"), "value": NumberDecimal("2.01")},
      { "customer_id": "tj@wheresmyemail.com", "orderdate": ISODate("2020-11-23T22:56:53Z"), "value": NumberDecimal("187.99")},
      { "customer_id": "elise_smith@myemail.com", "orderdate": ISODate("2020-12-26T08:55:46Z"), "value": NumberDecimal("48.50")}
    ]);
    ```
*   **Y√™u c·∫ßu:** Th·ªëng k√™ d·ªØ li·ªáu kh√°ch h√†ng trong nƒÉm 2020, th·ªÉ hi·ªán: ng√†y mua h√†ng ƒë·∫ßu ti√™n, t·ªïng gi√° tr·ªã ƒë∆°n h√†ng, v√† s·ªë l·∫ßn mua.
*   **L·ªùi gi·∫£i:**
    ```javascript
    db.orders.aggregate([
      // Giai ƒëo·∫°n 1: L·ªçc c√°c ƒë∆°n h√†ng trong nƒÉm 2020
      { $match: {
          orderdate: {
            $gte: ISODate("2020-01-01T00:00:00Z"),
            $lt: ISODate("2021-01-01T00:00:00Z")
          }
      }},
      // Giai ƒëo·∫°n 2: Nh√≥m theo customer_id v√† t√≠nh to√°n
      { $group: {
          _id: "$customer_id",
          first_purchase_date: { $min: "$orderdate" }, // L·∫•y ng√†y mua nh·ªè nh·∫•t
          total_value: { $sum: "$value" },            // T√≠nh t·ªïng gi√° tr·ªã
          purchase_count: { $sum: 1 }                 // ƒê·∫øm s·ªë l∆∞·ª£ng document trong nh√≥m
      }}
    ])
    ```

#### **3. B√†i to√°n 3: Join D·ªØ li·ªáu gi·ªØa c√°c Collection**

*   **Chu·∫©n b·ªã d·ªØ li·ªáu:**
    ```javascript
    db.products.insertMany([
      { "id": "a1b2c3d4", "name": "Asus Laptop", "category": "ELECTRONICS" },
      { "id": "z9y8x7w6", "name": "The Day Of The Triffids", "category": "BOOKS" },
      { "id": "ff11gg22hh33", "name": "Morphy Richards Food Mixer", "category": "KITCHENWARE" }
    ]);
    // Gi·∫£ s·ª≠ collection 'orders' ƒë√£ c√≥ t·ª´ b√†i 2
    ```
*   **Y√™u c·∫ßu:** L·∫•y d·ªØ li·ªáu ƒë∆°n h√†ng trong nƒÉm 2020, nh∆∞ng thay v√¨ hi·ªÉn th·ªã `product_id`, h√£y tra c·ª©u v√† hi·ªÉn th·ªã `product_name` v√† `product_category`.
*   **L·ªùi gi·∫£i:**
    ```javascript
    db.orders.aggregate([
      // Giai ƒëo·∫°n 1: L·ªçc ƒë∆°n h√†ng trong nƒÉm 2020
      { $match: {
          orderdate: { $gte: ISODate("2020-01-01T00:00:00Z"), $lt: ISODate("2021-01-01T00:00:00Z") }
      }},
      // Giai ƒëo·∫°n 2: Join v·ªõi collection 'products'
      { $lookup: {
          from: "products",           // Collection ƒë·ªÉ join
          localField: "product_id",   // Tr∆∞·ªùng trong collection 'orders'
          foreignField: "id",       // Tr∆∞·ªùng trong collection 'products'
          as: "product_details"     // T√™n m·∫£ng ch·ª©a k·∫øt qu·∫£ join
      }},
      // Giai ƒëo·∫°n 3: "L√†m ph·∫≥ng" m·∫£ng product_details v√† ƒë·ªãnh h√¨nh l·∫°i output
      { $project: {
          _id: 0,
          customer_id: 1,
          orderdate: 1,
          value: 1,
          product_name: { $arrayElemAt: ["$product_details.name", 0] },
          product_category: { $arrayElemAt: ["$product_details.category", 0] }
      }}
    ])
    ```

---

### **Giai ƒëo·∫°n 8: Qu·∫£n tr·ªã B·∫£o m·∫≠t v√† Ng∆∞·ªùi d√πng**

```mermaid
flowchart TD
    subgraph "Authentication Flow in Sharded Cluster"
        CLIENT[Client Application] --> MONGOS[Mongos Router]
        MONGOS --> |"Authenticates with"| CONFIGDB[Config Server]
        CONFIGDB --> |"User credentials stored"| USERDB[(User Database)]
        MONGOS --> |"Forwards authenticated requests"| SHARD1[Shard 1]
        MONGOS --> |"Forwards authenticated requests"| SHARD2[Shard 2]
        MONGOS --> |"Forwards authenticated requests"| SHARD3[Shard 3]
    end
    
    subgraph "Internal Authentication"
        KEYFILE[KeyFile/x.509] --> |"Secures communication"| INTERNAL[Internal Cluster Communication]
        INTERNAL --> CONFIGDB
        INTERNAL --> SHARD1
        INTERNAL --> SHARD2
        INTERNAL --> SHARD3
    end
    
    subgraph "Authorization (RBAC)"
        USERDB --> ROLES[User Roles]
        ROLES --> PRIVILEGES[Specific Privileges]
        PRIVILEGES --> RESOURCES[Database/Collection Resources]
        RESOURCES --> ACTIONS[Allowed Actions]
    end
    
    style CLIENT fill:#e3f2fd
    style MONGOS fill:#fff3e0
    style KEYFILE fill:#ffebee
    style ACTIONS fill:#e8f5e8
```

M·ªôt cluster kh√¥ng ƒë∆∞·ª£c b·∫£o m·∫≠t l√† m·ªôt th·∫£m h·ªça. MongoDB cung c·∫•p h·ªá th·ªëng Role-Based Access Control (RBAC) m·∫°nh m·∫Ω ƒë·ªÉ ƒë·∫£m b·∫£o "ƒë√∫ng ng∆∞·ªùi, ƒë√∫ng vi·ªác".

*   **M·ª•c ƒë√≠ch:** Ki·ªÉm so√°t ch·∫∑t ch·∫Ω ai ƒë∆∞·ª£c ph√©p l√†m g√¨ tr√™n nh·ªØng d·ªØ li·ªáu n√†o. X√°c th·ª±c (b·∫°n l√† ai?) v√† ·ª¶y quy·ªÅn (b·∫°n ƒë∆∞·ª£c l√†m g√¨?).

‚ö†Ô∏è **B·∫™Y NG∆Ø·ªúI M·ªöI - Giai ƒëo·∫°n 8:**
- **Ch·∫°y cluster m√† kh√¥ng b·∫≠t `authorization`** ‚Üí ai c≈©ng c√≥ th·ªÉ truy c·∫≠p
- **D√πng user `root` cho ·ª©ng d·ª•ng** ‚Üí r·ªßi ro l·ªõn khi b·ªã hack
- **B·∫≠t `auditLog` tr√™n Community** ‚Üí mongod kh√¥ng kh·ªüi ƒë·ªông (ch·ªâ Enterprise/Atlas)
- **Kh√¥ng √°p d·ª•ng Least Privilege** ‚Üí user c√≥ quy·ªÅn qu√° r·ªông kh√¥ng c·∫ßn thi·∫øt

üí° **NGUY√äN T·∫ÆC:** M·ªói user/·ª©ng d·ª•ng ch·ªâ n√™n c√≥ nh·ªØng quy·ªÅn h·∫°n th·ª±c s·ª± c·∫ßn thi·∫øt.

#### **1. T·∫°o User v√† G√°n Role c√≥ s·∫µn**

1.  **K·∫øt n·ªëi v·ªõi quy·ªÅn admin:** (Nh∆∞ ƒë√£ l√†m ·ªü Giai ƒëo·∫°n 3)
    `mongosh --port 27020 sudo -u mongodba --authenticationDatabase admin`
    # S·∫Ω prompt nh·∫≠p password an to√†n
2.  **T·∫°o user cho ·ª©ng d·ª•ng:**
    ```javascript
    use reporting // Chuy·ªÉn sang DB m√† user s·∫Ω thao t√°c
    db.createUser({
      user: "reportUser",
      pwd: passwordPrompt(), // S·∫Ω h·ªèi ƒë·ªÉ nh·∫≠p m·∫≠t kh·∫©u an to√†n
      roles: [
        { role: "read", db: "reporting" } // Ch·ªâ cho ph√©p ƒë·ªçc tr√™n DB 'reporting'
      ]
    })
    
    use testDB
    db.createUser({
      user: "appUser",
      pwd: passwordPrompt(),
      roles: [
        { role: "readWrite", db: "testDB" } // Cho ph√©p ƒë·ªçc v√† ghi tr√™n DB 'testDB'
      ]
    })
    ```

#### **2. T·∫°o Role T√πy ch·ªânh (Custom Role)**

ƒê√¥i khi c√°c role c√≥ s·∫µn (`read`, `readWrite`, `dbAdmin`...) qu√° r·ªông. Ta c√≥ th·ªÉ t·ª± t·∫°o role chi ti·∫øt h∆°n.

*   **Y√™u c·∫ßu:** T·∫°o m·ªôt role `inventoryManager` ch·ªâ ƒë∆∞·ª£c ph√©p `find`, `update`, `insert` tr√™n collection `inventory` v√† ch·ªâ `find` tr√™n collection `orders` trong database `products`.
*   **Th·ª±c hi·ªán:**
    ```javascript
    use products
    db.createRole({
      role: "inventoryManager",
      privileges: [
        {
          resource: { db: "products", collection: "inventory" },
          actions: [ "find", "update", "insert" ]
        },
        {
          resource: { db: "products", collection: "orders" },
          actions: [ "find" ]
        }
      ],
      roles: [] // C√≥ th·ªÉ k·∫ø th·ª´a t·ª´ c√°c role kh√°c n·∫øu mu·ªën
    })
    
    // Sau khi t·∫°o role, g√°n n√≥ cho user
    db.createUser({
      user: "manager01",
      pwd: passwordPrompt(),
      roles: [ { role: "inventoryManager", db: "products" } ]
    })
    ```

#### **3. C·∫•u h√¨nh Audit Log (Ghi l·∫°i ho·∫°t ƒë·ªông)**

‚ö†Ô∏è **C·∫¢NH B√ÅO MONGODB COMMUNITY EDITION:**
- **Audit Log ch·ªâ kh·∫£ d·ª•ng trong MongoDB Enterprise/Atlas**
- **MongoDB Community KH√îNG h·ªó tr·ª£ c·∫•u h√¨nh `auditLog`**
- **N·∫øu ƒëang d√πng Community, b·ªè qua ph·∫ßn n√†y ƒë·ªÉ tr√°nh l·ªói c·∫•u h√¨nh**

*   **M·ª•c ƒë√≠ch:** Ghi l·∫°i c√°c s·ª± ki·ªán quan tr·ªçng (ƒëƒÉng nh·∫≠p, thay ƒë·ªïi schema, t·∫°o user...) ra m·ªôt file log ri√™ng ƒë·ªÉ ph·ª•c v·ª• cho vi·ªác ƒëi·ªÅu tra an ninh.
*   **Th·ª±c hi·ªán ƒë√∫ng (CH·ªà D√ÄNH CHO MONGODB ENTERPRISE/ATLAS):**
    1.  T·∫°o th∆∞ m·ª•c cho audit log tr√™n **C·∫¢ 3 M√ÅY**:
        ```bash
        mkdir /data/audit
        chown mongod:mongod /data/audit
        ```
    2.  Th√™m c·∫•u h√¨nh `auditLog` v√†o **t·∫•t c·∫£ c√°c file config** (`mongod-config.conf`, `mongod-shard1.conf`...):
        ```yaml
        security:
          authorization: enabled
          keyFile: /data/mongo-keyfile
        
        # --- CH·ªà TH√äM ƒêO·∫†N N√ÄY N·∫æU D√ôNG ENTERPRISE/ATLAS ---
        auditLog:
          destination: file
          format: JSON
          path: /data/audit/audit.log
        ```
    3.  Kh·ªüi ƒë·ªông l·∫°i t·∫•t c·∫£ c√°c ti·∫øn tr√¨nh `mongod`. Gi·ªù ƒë√¢y, m·ªçi h√†nh ƒë·ªông quan tr·ªçng s·∫Ω ƒë∆∞·ª£c ghi l·∫°i trong file `/data/audit/audit.log`.

---

### **Giai ƒëo·∫°n 9: Qu·∫£n tr·ªã N√¢ng cao v√† V·∫≠n h√†nh Replica Set**

```mermaid
sequenceDiagram
    participant User
    participant PRIMARY
    participant Secondary1
    participant Secondary2
    
    User->>PRIMARY: Write Operation
    PRIMARY->>Secondary1: Replicate Oplog
    PRIMARY->>Secondary2: Replicate Oplog
    
    Note right of PRIMARY: PRIMARY fails!
    
    Secondary1->>Secondary2: Request Vote
    Secondary2-->>Secondary1: Vote Granted
    Secondary1->>Secondary1: Becomes New PRIMARY
    
    User->>Secondary1: Write Operation (Success)
```

D·ª±ng replica set ch·ªâ l√† b∆∞·ªõc ƒë·∫ßu. V·∫≠n h√†nh n√≥ trong th·ª±c t·∫ø ƒë√≤i h·ªèi s·ª± hi·ªÉu bi·∫øt v·ªÅ c∆° ch·∫ø b·∫ßu c·ª≠, failover v√† c√°c c·∫•u h√¨nh ƒë·∫∑c bi·ªát.

#### **1. ƒêi·ªÅu ch·ªânh Primary (Election)**

*   **M·ª•c ƒë√≠ch:** ƒê·∫£m b·∫£o node m√°y ch·ªß m·∫°nh nh·∫•t, c√≥ ƒë·ªô tr·ªÖ m·∫°ng th·∫•p nh·∫•t s·∫Ω ƒë∆∞·ª£c ∆∞u ti√™n l√†m `PRIMARY` ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng ghi.
*   **B·∫´y ng∆∞·ªùi m·ªõi:** ƒê·ªÉ t·∫•t c·∫£ c√°c node c√≥ priority b·∫±ng nhau, d·∫´n ƒë·∫øn vi·ªác m·ªôt node y·∫øu c√≥ th·ªÉ ƒë∆∞·ª£c b·∫ßu l√†m `PRIMARY`, ·∫£nh h∆∞·ªüng ƒë·∫øn to√†n b·ªô replica set.
*   **Th·ª±c hi·ªán ƒë√∫ng:** K·∫øt n·ªëi v√†o replica set (v√≠ d·ª• shard01) v√† ƒëi·ªÅu ch·ªânh `priority`.
    ```bash
    # K·∫øt n·ªëi v√†o m·ªôt member b·∫•t k·ª≥ c·ªßa shard01
    mongosh --port 27011
    
    # L·∫•y c·∫•u h√¨nh hi·ªán t·∫°i
    cfg = rs.conf()
    
    # Gi·∫£ s·ª≠ mongo-1 l√† m√°y m·∫°nh nh·∫•t
    cfg.members[0].priority = 3 // host: "mongo-1:27011"
    cfg.members[1].priority = 2 // host: "mongo-2:27011"
    cfg.members[2].priority = 1 // host: "mongo-3:27011"
    
    # √Åp d·ª•ng l·∫°i c·∫•u h√¨nh
    rs.reconfig(cfg)
    ```    Node c√≥ `priority` cao nh·∫•t s·∫Ω ƒë∆∞·ª£c ∆∞u ti√™n trong c√°c cu·ªôc b·∫ßu c·ª≠. Node c√≥ `priority: 0` s·∫Ω kh√¥ng bao gi·ªù tr·ªü th√†nh `PRIMARY`.

#### **2. C·∫•u h√¨nh Hidden Node**

*   **M·ª•c ƒë√≠ch:** T·∫°o m·ªôt member ·∫©n, kh√¥ng ƒë∆∞·ª£c ·ª©ng d·ª•ng nh√¨n th·∫•y v√† kh√¥ng th·ªÉ tr·ªü th√†nh `PRIMARY`. N√≥ chuy√™n d√πng cho c√°c t√°c v·ª• nh∆∞ backup, ph√¢n t√≠ch d·ªØ li·ªáu m√† kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn t·∫£i c·ªßa c√°c node ch√≠nh.
*   **Th·ª±c hi·ªán ƒë√∫ng:**
    ```javascript
    cfg = rs.conf()
    // Gi·∫£ s·ª≠ mu·ªën ·∫©n node mongo-3
    cfg.members[2].priority = 0
    cfg.members[2].hidden = true
    rs.reconfig(cfg)
    ```

#### **3. ƒêi·ªÅu ch·ªânh K√≠ch th∆∞·ªõc Oplog**

*   **M·ª•c ƒë√≠ch:** Oplog (operations log) l√† m·ªôt collection ƒë·∫∑c bi·ªát l∆∞u l·∫°i t·∫•t c·∫£ c√°c thao t√°c ghi. K√≠ch th∆∞·ªõc oplog quy·∫øt ƒë·ªãnh "c·ª≠a s·ªï th·ªùi gian" m√† m·ªôt node `SECONDARY` c√≥ th·ªÉ offline m√† kh√¥ng c·∫ßn ph·∫£i resync to√†n b·ªô d·ªØ li·ªáu.
*   **B·∫´y ng∆∞·ªùi m·ªõi:** ƒê·ªÉ k√≠ch th∆∞·ªõc oplog m·∫∑c ƒë·ªãnh. V·ªõi h·ªá th·ªëng ghi nhi·ªÅu, oplog s·∫Ω b·ªã ghi ƒë√® r·∫•t nhanh, khi·∫øn node `SECONDARY` b·ªã l·ªói v√† ph·∫£i resync, g√¢y t·ªën t√†i nguy√™n.
*   **Th·ª±c hi·ªán ƒë√∫ng:** (L√†m tr√™n `PRIMARY` c·ªßa replica set)
    ```javascript
    // Ki·ªÉm tra k√≠ch th∆∞·ªõc hi·ªán t·∫°i (bytes)
    use local
    db.oplog.rs.stats().maxSize
    
    // Thay ƒë·ªïi k√≠ch th∆∞·ªõc oplog th√†nh 20GB (20000 MB)
    db.adminCommand({ replSetResizeOplog: 1, size: 20000 })
    ```

---

### **Giai ƒëo·∫°n 10: Sao l∆∞u, Ph·ª•c h·ªìi v√† Gi√°m s√°t**

```mermaid
flowchart LR
    subgraph "Backup Strategy"
        A[Production Database] --> B[Full Backup<br/>Daily/Weekly]
        A --> C[Incremental Oplog<br/>Every 15 mins]
        A --> D[Snapshot Backup<br/>Storage Level]
    end
    
    subgraph "Recovery Scenarios"
        E[Complete Disaster] --> F[Full Restore<br/>+ Latest Oplog]
        G[Data Corruption] --> H[Point-in-Time Recovery<br/>PITR]
        I[Accidental Deletion] --> J[Selective Restore<br/>+ Oplog Replay]
    end
    
    subgraph "Monitoring Tools"
        K[mongostat] --> L["Real-time Operations<br/>Insert/Query/Update/Delete"]
        M[mongotop] --> N["Collection-level<br/>Read/Write Times"]
        O[Database Profiler] --> P["Slow Query Analysis<br/>Performance Tuning"]
        Q[currentOp()] --> R["Active Operations<br/>Long-running Queries"]
    end
    
    subgraph "Health Checks"
        S[Process Status] --> T["4 mongod + 1 mongos<br/>per node"]
        U[Replica Set Status] --> V["PRIMARY/SECONDARY<br/>Election Health"]
        W[Shard Status] --> X["Active Shards<br/>Balanced Distribution"]
        Y[Log Analysis] --> Z["ERROR/WARNING<br/>Pattern Detection"]
    end
    
    B --> F
    C --> H
    C --> J
    D --> F
    
    style A fill:#e3f2fd
    style F fill:#e8f5e8
    style H fill:#fff3e0
    style R fill:#ffebee
```

D·ªØ li·ªáu l√† t√†i s·∫£n qu√Ω gi√° nh·∫•t. M·ªôt chi·∫øn l∆∞·ª£c sao l∆∞u v√† gi√°m s√°t hi·ªáu qu·∫£ l√† b·∫Øt bu·ªôc.

#### **1. Sao l∆∞u v√† Ph·ª•c h·ªìi (`mongodump` / `mongorestore`)**

*   **M·ª•c ƒë√≠ch:** T·∫°o b·∫£n sao l∆∞u logic c·ªßa database ƒë·ªÉ ph√≤ng tr∆∞·ªùng h·ª£p x·∫£y ra s·ª± c·ªë.
*   **Th·ª±c hi·ªán ƒë√∫ng:**
    *   **Backup to√†n b·ªô database `testDB` (ch·∫°y t·ª´ m·ªôt m√°y client c√≥ c√†i mongo tools):**
        ```bash
        mongodump --host=mongo-1 --port=27020 \
                  sudo -u mongodba --authenticationDatabase admin \
                  --db=testDB --out=/backup/testDB_`date +%F`
        # S·∫Ω prompt nh·∫≠p password an to√†n
        ```
    *   **Restore database `testDB`:**
        ```bash
        mongorestore --host=mongo-1 --port=27020 \
                     sudo -u mongodba --authenticationDatabase admin \
                     --db=testDB /backup/testDB_YYYY-MM-DD
        # S·∫Ω prompt nh·∫≠p password an to√†n
        ```

#### **2. Ph·ª•c h·ªìi t·∫°i m·ªôt th·ªùi ƒëi·ªÉm (Point-in-Time Recovery)**

*   **M·ª•c ƒë√≠ch:** C·ª©u d·ªØ li·ªáu khi c√≥ ng∆∞·ªùi l·ª° tay `DELETE` ho·∫∑c `UPDATE` sai. K·ªπ thu·∫≠t n√†y cho ph√©p kh√¥i ph·ª•c l·∫°i tr·∫°ng th√°i c·ªßa database *ngay tr∆∞·ªõc* khi s·ª± c·ªë x·∫£y ra.
*   **B·∫´y ng∆∞·ªùi m·ªõi:** Ch·ªâ c√≥ backup h√†ng ƒë√™m. N·∫øu sai s√≥t x·∫£y ra l√∫c 9 gi·ªù s√°ng, b·∫°n s·∫Ω m·∫•t to√†n b·ªô d·ªØ li·ªáu t·ª´ ƒë√™m h√¥m tr∆∞·ªõc.
*   **Th·ª±c hi·ªán ƒë√∫ng (Quy tr√¨nh):**
    1.  **Lu√¥n c√≥ m·ªôt b·∫£n backup Oplog g·∫ßn nh·∫•t:**
        ```bash
        # L·ªánh n√†y n√™n ƒë∆∞·ª£c ch·∫°y ƒë·ªãnh k·ª≥ (v√≠ d·ª• m·ªói gi·ªù)
        mongodump --host=mongo-1 --port=27011 \
                  -d local -c oplog.rs --out /backup/oplogs
        ```    2.  **Khi c√≥ s·ª± c·ªë (v√≠ d·ª•: x√≥a nh·∫ßm l√∫c 10:30:00 AM):**
        *   T√¨m `timestamp` c·ªßa th·ªùi ƒëi·ªÉm ngay tr∆∞·ªõc khi x√≥a trong b·∫£n backup oplog.
    3.  **Restore:**
        *   Kh√¥i ph·ª•c t·ª´ b·∫£n backup ƒë·∫ßy ƒë·ªß g·∫ßn nh·∫•t.
        *   D√πng `mongorestore` v·ªõi c·ªù `--oplogReplay` v√† `--oplogLimit` ƒë·ªÉ √°p d·ª•ng l·∫°i c√°c thay ƒë·ªïi t·ª´ oplog cho ƒë·∫øn th·ªùi ƒëi·ªÉm mong mu·ªën.
        ```bash
        # V√≠ d·ª• restore t·ªõi timestamp 1729073314:3
        mongorestore --port 27017 --oplogReplay \
                     --oplogLimit=1729073314:3 \
                     /backup/mongo/local/oplog.rs.bson
        ```

#### **3. Gi√°m s√°t Hi·ªáu nƒÉng**

*   **M·ª•c ƒë√≠ch:** Theo d√µi s·ª©c kh·ªèe h·ªá th·ªëng, ph√°t hi·ªán c√°c "ƒëi·ªÉm n√≥ng" v√† truy v·∫•n ch·∫≠m.
*   **C√¥ng c·ª• d√≤ng l·ªánh:**
    *   `mongostat`: Cung c·∫•p c√°i nh√¨n t·ªïng quan theo th·ªùi gian th·ª±c v·ªÅ c√°c ho·∫°t ƒë·ªông (inserts, queries, updates, deletes...), l·ªói, v√† h√†ng ƒë·ª£i.
        ```bash
        mongostat --host mongo-1 --port 27020 sudo -u mongodba --authenticationDatabase admin
        # S·∫Ω prompt nh·∫≠p password an to√†n
        ```
    *   `mongotop`: Hi·ªÉn th·ªã th·ªùi gian ƒë·ªçc/ghi tr√™n t·ª´ng collection, gi√∫p b·∫°n bi·∫øt collection n√†o ƒëang ho·∫°t ƒë·ªông nhi·ªÅu nh·∫•t.
        ```bash
        mongotop --host mongo-1 --port 27020 sudo -u mongodba --authenticationDatabase admin
        # S·∫Ω prompt nh·∫≠p password an to√†n
        ```
*   **Database Profiler (T√¨m truy v·∫•n ch·∫≠m):**
    1.  **B·∫≠t profiler:** Ghi l·∫°i c√°c truy v·∫•n ch·∫°y ch·∫≠m h∆°n 100ms.
        ```javascript
        use testDB
        db.setProfilingLevel(1, { slowms: 100 })
        ```
    2.  **Xem c√°c truy v·∫•n ch·∫≠m:**
        ```javascript
        db.system.profile.find().pretty()
        ```
    3.  **T·∫Øt profiler:** `db.setProfilingLevel(0)`

---

### **Giai ƒëo·∫°n 11: T·ªëi ∆∞u Hi·ªáu nƒÉng Truy v·∫•n v·ªõi Index**

```mermaid
graph TD
    subgraph NoIndex ["üîç Truy v·∫•n KH√îNG c√≥ Index"]
        Q1["üìù Truy v·∫•n"] --> P1{"üß† Query Planner"}
        P1 --> S1["üìö Collection Scan<br/>üíî ƒê·ªçc TO√ÄN B·ªò collection<br/>‚è±Ô∏è Ch·∫≠m v√† t·ªën t√†i nguy√™n"]
        S1 --> R1["üêå K·∫øt qu·∫£ ch·∫≠m"]
    end
    
    subgraph WithIndex ["‚ö° Truy v·∫•n C√ì Index"]
        Q2["üìù Truy v·∫•n"] --> P2{"üß† Query Planner"}
        P2 --> S2["üéØ Index Scan<br/>‚ú® Tra c·ª©u v√† nh·∫£y th·∫≥ng ƒë·∫øn d·ªØ li·ªáu<br/>üöÄ Nhanh v√† hi·ªáu qu·∫£"]
        S2 --> R2["‚ö° K·∫øt qu·∫£ nhanh"]
    end
    
    %% So s√°nh tr·ª±c ti·∫øp
    Q1 -.->|"So s√°nh hi·ªáu su·∫•t"| Q2
    R1 -.->|"Ch√™nh l·ªách t·ªëc ƒë·ªô"| R2
    
    %% Styling cho nodes
    style Q1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Q2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style P1 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style P2 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style S1 fill:#ffebee,stroke:#d32f2f,stroke-width:3px
    style S2 fill:#e8f5e8,stroke:#388e3c,stroke-width:3px
    style R1 fill:#ffcdd2,stroke:#c62828,stroke-width:2px
    style R2 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px
    
    %% Styling cho subgraphs
    style NoIndex fill:#fce4ec,stroke:#ad1457,stroke-width:2px
    style WithIndex fill:#e0f2f1,stroke:#00695c,stroke-width:2px
```

N·∫øu Sharding l√† gi·∫£i ph√°p cho b√†i to√°n *dung l∆∞·ª£ng* (scale-out), th√¨ Index (ch·ªâ m·ª•c) l√† gi·∫£i ph√°p cho b√†i to√°n *t·ªëc ƒë·ªô* truy v·∫•n. M·ªôt truy v·∫•n kh√¥ng c√≥ index s·∫Ω ph·∫£i qu√©t to√†n b·ªô collection (Full Collection Scan), c·ª±c k·ª≥ ch·∫≠m v√† t·ªën t√†i nguy√™n.

*   **M·ª•c ƒë√≠ch:** T·∫°o ra c√°c c·∫•u tr√∫c d·ªØ li·ªáu ƒë·∫∑c bi·ªát (th∆∞·ªùng l√† B-Tree) gi√∫p MongoDB nhanh ch√≥ng ƒë·ªãnh v·ªã c√°c document c·∫ßn thi·∫øt m√† kh√¥ng c·∫ßn ph·∫£i ƒë·ªçc qua t·ª´ng document m·ªôt. T∆∞∆°ng t·ª± nh∆∞ m·ª•c l·ª•c c·ªßa m·ªôt cu·ªën s√°ch.
*   **B·∫´y ng∆∞·ªùi m·ªõi:**
    *   B·ªè qua vi·ªác t·∫°o index, d·∫´n ƒë·∫øn hi·ªáu nƒÉng th·∫£m h·ªça khi d·ªØ li·ªáu l·ªõn d·∫ßn.
    *   T·∫°o index m·ªôt c√°ch b·ª´a b√£i tr√™n m·ªçi tr∆∞·ªùng. M·ªói index ƒë·ªÅu t·ªën RAM v√† l√†m ch·∫≠m c√°c thao t√°c ghi (insert, update, delete).
*   **Th·ª±c hi·ªán ƒë√∫ng:** Ph√¢n t√≠ch c√°c truy v·∫•n th∆∞·ªùng xuy√™n c·ªßa ·ª©ng d·ª•ng v√† ch·ªâ t·∫°o index ƒë·ªÉ ph·ª•c v·ª• cho c√°c truy v·∫•n ƒë√≥.

#### **1. C√°c lo·∫°i Index c∆° b·∫£n v√† c√°ch t·∫°o**

*   **K·∫øt n·ªëi v√†o Mongos ƒë·ªÉ th·ª±c hi·ªán:**
    ```bash
    mongosh --port 27020 sudo -u mongodba --authenticationDatabase admin
    # S·∫Ω prompt nh·∫≠p password an to√†n
    use testDB
    ```

*   **Single Field Index (Ch·ªâ m·ª•c tr√™n m·ªôt tr∆∞·ªùng):**
    ```javascript
    // T·∫°o index tr√™n tr∆∞·ªùng 'vocation' c·ªßa collection 'persons'
    // 1: s·∫Øp x·∫øp tƒÉng d·∫ßn, -1: s·∫Øp x·∫øp gi·∫£m d·∫ßn
    db.persons.createIndex({ "vocation": 1 })
    ```
    *Ph·ª•c v·ª• cho c√°c truy v·∫•n nh∆∞:* `db.persons.find({ vocation: "ENGINEER" })`

*   **Compound Index (Ch·ªâ m·ª•c ph·ª©c h·ª£p tr√™n nhi·ªÅu tr∆∞·ªùng):**
    ```javascript
    // T·∫°o index tr√™n 'vocation' v√† 'lastname'
    db.persons.createIndex({ "vocation": 1, "lastname": 1 })
    ```
    *Quan tr·ªçng:* Th·ª© t·ª± c√°c tr∆∞·ªùng trong index r·∫•t quan tr·ªçng. Index n√†y s·∫Ω ph·ª•c v·ª• t·ªët cho:
    1.  `db.persons.find({ vocation: "ENGINEER" })`
    2.  `db.persons.find({ vocation: "ENGINEER", lastname: "Smith" })`
    *Nh∆∞ng s·∫Ω **kh√¥ng** ph·ª•c v·ª• t·ªët cho:* `db.persons.find({ lastname: "Smith" })`

*   **Text Index (Ch·ªâ m·ª•c vƒÉn b·∫£n):** D√πng cho t√¨m ki·∫øm to√†n vƒÉn b·∫£n (full-text search).
    ```javascript
    // Chu·∫©n b·ªã d·ªØ li·ªáu
    db.articles.insertOne({ title: "MongoDB Performance Tuning", content: "Indexing is a key concept for tuning databases." })
    db.articles.insertOne({ title: "Sharding Guide", content: "A guide to horizontal scaling with MongoDB." })
    
    // T·∫°o text index tr√™n tr∆∞·ªùng 'content'
    db.articles.createIndex({ "content": "text" })
    
    // T√¨m ki·∫øm
    db.articles.find({ $text: { $search: "tuning scaling" } }) // S·∫Ω t√¨m c√°c document ch·ª©a 'tuning' ho·∫∑c 'scaling'
    ```

#### **2. Ph√¢n t√≠ch K·∫ø ho·∫°ch Th·ª±c thi (Execution Plan)**

L√†m sao ƒë·ªÉ bi·∫øt m·ªôt truy v·∫•n c√≥ ƒëang s·ª≠ d·ª•ng index hay kh√¥ng? H√£y d√πng l·ªánh `explain()`.

*   **Th·ª±c hi·ªán:**
    ```javascript
    db.persons.find({ vocation: "ENGINEER", lastname: "Smith" }).explain("executionStats")
    ```*   **Ph√¢n t√≠ch k·∫øt qu·∫£:**
    B·∫°n c·∫ßn t√¨m ƒë·∫øn m·ª•c `executionStats.winningPlan`.
    *   **T·ªêT (`IXSCAN`):** N·∫øu `stage` l√† `IXSCAN` (Index Scan), nghƒ©a l√† truy v·∫•n c·ªßa b·∫°n ƒë√£ s·ª≠ d·ª•ng index.
        ```json
        "winningPlan": {
          "stage": "FETCH",
          "inputStage": {
            "stage": "IXSCAN", // <-- Tuy·ªát v·ªùi!
            "indexName": "vocation_1_lastname_1",
            // ...
          }
        }
        ```
    *   **T·ªÜ (`COLLSCAN`):** N·∫øu `stage` l√† `COLLSCAN` (Collection Scan), nghƒ©a l√† MongoDB ƒë√£ ph·∫£i ƒë·ªçc to√†n b·ªô collection. B·∫°n c·∫ßn ph·∫£i xem l·∫°i v√† t·∫°o index ph√π h·ª£p.
        ```json
        "winningPlan": {
          "stage": "COLLSCAN", // <-- C·∫£nh b√°o hi·ªáu nƒÉng!
          "filter": {
             // ...
          }
        }
        ```

---

### **Giai ƒëo·∫°n 12: Chi·∫øn l∆∞·ª£c Sharding v√† Ph√¢n ph·ªëi D·ªØ li·ªáu**

```mermaid
flowchart TD
    subgraph "Data Distribution Process"
        A[New Document] --> B{"Shard Key Analysis"}
        B --> C["Calculate Target Chunk"]
        C --> D["Route to Appropriate Shard"]
        D --> E["Document Stored"]
    end
    
    subgraph "Chunk Management"
        F["Chunk Size Monitor"] --> G{"Chunk > 64MB?"}
        G -->|Yes| H["Split Chunk"]
        G -->|No| I["Continue Monitoring"]
        H --> J["Create New Chunk"]
        J --> K["Update Config Server"]
    end
    
    subgraph "Balancer Process"
        L["Balancer Service"] --> M{"Check Shard Distribution"}
        M --> N{"Imbalanced?"}
        N -->|Yes| O["Select Chunks to Move"]
        N -->|No| P["Wait Next Cycle"]
        O --> Q["Migrate Chunks"]
        Q --> R["Update Metadata"]
        R --> S["Balance Restored"]
    end
    
    subgraph "Shard Key Strategies"
        T["Hashed Sharding"] --> U["Even Distribution<br/>Random Access"]
        V["Ranged Sharding"] --> W["Targeted Queries<br/>Risk of Hotspots"]
    end
    
    E --> F
    K --> L
    S --> P
    
    style A fill:#e3f2fd
    style E fill:#e8f5e8
    style O fill:#fff3e0
    style S fill:#c8e6c9
    style U fill:#e1f5fe
    style W fill:#fff8e1
```

Ch√∫ng ta ƒë√£ d·ª±ng cluster sharding, nh∆∞ng vi·ªác ph√¢n chia d·ªØ li·ªáu di·ªÖn ra nh∆∞ th·∫ø n√†o? "B·ªô n√£o" c·ªßa qu√° tr√¨nh n√†y n·∫±m ·ªü **Shard Key** v√† ti·∫øn tr√¨nh **Balancer**.

*   **M·ª•c ƒë√≠ch:** Ch·ªçn m·ªôt "kh√≥a ph√¢n m·∫£nh" (Shard Key) t·ªët ƒë·ªÉ d·ªØ li·ªáu ƒë∆∞·ª£c ph√¢n ph·ªëi ƒë·ªÅu tr√™n c√°c Shard, tr√°nh t√¨nh tr·∫°ng "shard n√≥ng, shard l·∫°nh" (hotspot), v√† t·ªëi ∆∞u h√≥a c·∫£ vi·ªác ghi v√† ƒë·ªçc.
*   **C√°c kh√°i ni·ªám c·ªët l√µi:**
    *   **Shard Key:** M·ªôt ho·∫∑c nhi·ªÅu tr∆∞·ªùng trong document ƒë∆∞·ª£c d√πng ƒë·ªÉ quy·∫øt ƒë·ªãnh document ƒë√≥ s·∫Ω thu·ªôc v·ªÅ "v√πng" d·ªØ li·ªáu n√†o. **M·ªôt khi ƒë√£ ch·ªçn, Shard Key kh√¥ng th·ªÉ thay ƒë·ªïi.**
    *   **Chunk:** M·ªôt d·∫£i li√™n ti·∫øp c√°c gi√° tr·ªã c·ªßa Shard Key. MongoDB s·∫Ω t·ª± ƒë·ªông chia d·ªØ li·ªáu th√†nh c√°c chunk (m·∫∑c ƒë·ªãnh 64MB).
    *   **Balancer:** M·ªôt ti·∫øn tr√¨nh ch·∫°y ng·∫ßm, theo d√µi s·ª± ph√¢n b·ªë c·ªßa c√°c chunk tr√™n c√°c shard. N·∫øu m·ªôt shard c√≥ qu√° nhi·ªÅu chunk so v·ªõi c√°c shard kh√°c, Balancer s·∫Ω t·ª± ƒë·ªông di chuy·ªÉn (migrate) chunk ƒë·ªÉ c√¢n b·∫±ng l·∫°i.

#### **1. L·ª±a ch·ªçn Chi·∫øn l∆∞·ª£c Shard Key**

ƒê√¢y l√† quy·∫øt ƒë·ªãnh quan tr·ªçng nh·∫•t khi thi·∫øt k·∫ø m·ªôt h·ªá th·ªëng sharding.

*   **Hashed Sharding (Ph√¢n m·∫£nh BƒÉm):**
    *   **C√°ch ho·∫°t ƒë·ªông:** MongoDB t√≠nh to√°n m·ªôt gi√° tr·ªã bƒÉm (hash) c·ªßa Shard Key v√† d√πng gi√° tr·ªã n√†y ƒë·ªÉ ph√¢n chia d·ªØ li·ªáu.
    *   **V√≠ d·ª•:** `sh.shardCollection("testDB.myCollection", { "_id": "hashed" } )` (Nh∆∞ ƒë√£ l√†m ·ªü Giai ƒëo·∫°n 4)
    *   **∆Øu ƒëi·ªÉm:** ƒê·∫£m b·∫£o d·ªØ li·ªáu ghi ƒë∆∞·ª£c ph√¢n ph·ªëi **c·ª±c k·ª≥ ƒë·ªÅu** tr√™n t·∫•t c·∫£ c√°c shard. R·∫•t t·ªët cho c√°c workload ghi n·∫∑ng (heavy write).
    *   **Nh∆∞·ª£c ƒëi·ªÉm:** C√°c truy v·∫•n theo d·∫£i (range query) s·∫Ω kh√¥ng hi·ªáu qu·∫£, v√¨ c√°c document c√≥ gi√° tr·ªã `_id` g·∫ßn nhau l·∫°i n·∫±m tr√™n c√°c shard kh√°c nhau. `mongos` s·∫Ω ph·∫£i h·ªèi t·∫•t c·∫£ c√°c shard.

*   **Ranged Sharding (Ph√¢n m·∫£nh theo D·∫£i):**
    *   **C√°ch ho·∫°t ƒë·ªông:** MongoDB chia d·ªØ li·ªáu d·ª±a tr√™n gi√° tr·ªã th·ª±c c·ªßa Shard Key. C√°c document c√≥ gi√° tr·ªã key g·∫ßn nhau s·∫Ω n·∫±m chung m·ªôt chunk v√† tr√™n c√πng m·ªôt shard.
    *   **V√≠ d·ª•:** `sh.shardCollection("events.logs", { "timestamp": 1 } )`
    *   **∆Øu ƒëi·ªÉm:** R·∫•t hi·ªáu qu·∫£ cho c√°c truy v·∫•n theo d·∫£i. V√≠ d·ª•: "l·∫•y t·∫•t c·∫£ log trong 1 gi·ªù qua" s·∫Ω ch·ªâ c·∫ßn h·ªèi m·ªôt ho·∫∑c hai shard.
    *   **Nh∆∞·ª£c ƒëi·ªÉm:** **R·ªßi ro t·∫°o ra Hotspot.** N·∫øu Shard Key l√† m·ªôt tr∆∞·ªùng tƒÉng ƒë∆°n ƒëi·ªáu (nh∆∞ `timestamp` ho·∫∑c `_id` m·∫∑c ƒë·ªãnh), t·∫•t c·∫£ c√°c l∆∞·ª£t ghi m·ªõi s·∫Ω lu√¥n ƒëi v√†o chunk cu·ªëi c√πng tr√™n m·ªôt shard duy nh·∫•t, g√¢y qu√° t·∫£i cho shard ƒë√≥.

#### **2. B·∫´y ng∆∞·ªùi m·ªõi khi ch·ªçn Shard Key**

‚ö†Ô∏è **B·∫™Y NG∆Ø·ªúI M·ªöI - Giai ƒëo·∫°n 12:**
- **Ch·ªçn `_id` m·∫∑c ƒë·ªãnh v·ªõi Ranged Sharding** ‚Üí hot shard (ƒë√¢y l√† l·ªói kinh ƒëi·ªÉn)
- **Ch·ªçn key cardinality th·∫•p** (v√≠ d·ª•: `country` khi 90% l√† Vi·ªát Nam) ‚Üí jumbo chunk
- **Kh·∫≥ng ƒë·ªãnh chunk size c·ª©ng 64MB** ‚Üí kh√°c theo version
- **Qu√™n r·∫±ng Shard Key l√† b·∫•t bi·∫øn** ‚Üí kh√¥ng th·ªÉ thay ƒë·ªïi sau khi sharding

üí° **M·∫∏O:** Ki·ªÉm tra `maxChunkSizeBytes` ho·∫∑c t√†i li·ªáu version ƒëang ch·∫°y thay v√¨ gi·∫£ ƒë·ªãnh.

*   **Ch·ªçn `_id` m·∫∑c ƒë·ªãnh v·ªõi Ranged Sharding:** ƒê√¢y l√† l·ªói kinh ƒëi·ªÉn. `_id` c·ªßa MongoDB c√≥ ch·ª©a timestamp v√† lu√¥n tƒÉng. K·∫øt qu·∫£ l√† t·∫°o ra m·ªôt "hot shard" h·ª©ng ch·ªãu to√†n b·ªô l∆∞u l∆∞·ª£ng ghi.
*   **Ch·ªçn m·ªôt key c√≥ s·ªë l∆∞·ª£ng gi√° tr·ªã th·∫•p (Low Cardinality):** V√≠ d·ª•, sharding collection ng∆∞·ªùi d√πng theo tr∆∞·ªùng `country` trong khi 90% ng∆∞·ªùi d√πng ƒë·∫øn t·ª´ "Vi·ªát Nam". ƒêi·ªÅu n√†y s·∫Ω t·∫°o ra m·ªôt chunk kh·ªïng l·ªì kh√¥ng th·ªÉ chia t√°ch (jumbo chunk) v√† kh√¥ng th·ªÉ c√¢n b·∫±ng.
*   **Qu√™n r·∫±ng Shard Key l√† b·∫•t bi·∫øn:** Kh√¥ng th·ªÉ thay ƒë·ªïi Shard Key c·ªßa m·ªôt collection sau khi ƒë√£ sharding. N·∫øu ch·ªçn sai, c√°ch duy nh·∫•t ƒë·ªÉ s·ª≠a l√† t·∫°o m·ªôt collection m·ªõi, sharding l·∫°i v·ªõi key ƒë√∫ng, v√† di chuy·ªÉn to√†n b·ªô d·ªØ li·ªáu sang.

#### **3. Ki·ªÉm tra Ph√¢n ph·ªëi D·ªØ li·ªáu**

*   **K·∫øt n·ªëi v√†o `mongos` v√† ch·∫°y c√°c l·ªánh sau:**
    ```javascript
    use testDB
    
    // Xem th·ªëng k√™ ph√¢n ph·ªëi c·ªßa collection
    db.myCollection.getShardDistribution()
    
    // Xem tr·∫°ng th√°i t·ªïng quan c·ªßa cluster, bao g·ªìm c√°c chunk v√† balancer
    sh.status()
    ```
    H√£y ch√∫ √Ω ƒë·∫øn s·ªë l∆∞·ª£ng chunk tr√™n m·ªói shard trong k·∫øt qu·∫£ c·ªßa `sh.status()`. N·∫øu ch√∫ng ch√™nh l·ªách qu√° nhi·ªÅu, c√≥ th·ªÉ Shard Key c·ªßa b·∫°n ch∆∞a t·ªëi ∆∞u.

---

### **Giai ƒëo·∫°n 13: Gi√°m s√°t N√¢ng cao v√† T·ª± ƒë·ªông h√≥a V·∫≠n h√†nh**

```mermaid
flowchart TD
    A["üë®‚Äçüíº Admin<br/>üîß Qu·∫£n tr·ªã vi√™n h·ªá th·ªëng"] -->|"‚ö° Ch·∫°y script gi√°m s√°t"| B{"üìä db.currentOp()<br/>üîç Ki·ªÉm tra t√°c v·ª• hi·ªán t·∫°i"}
    
    B --> C{"üßê Ph√¢n t√≠ch t√°c v·ª•<br/>‚è±Ô∏è ƒê√°nh gi√° th·ªùi gian th·ª±c thi"}
    
    C -->|"‚úÖ T√°c v·ª• b√¨nh th∆∞·ªùng < 60s"| D["‚ú® Tr·∫°ng th√°i OK<br/>üìù Ghi log b√¨nh th∆∞·ªùng"]
    
    C -->|"‚ö†Ô∏è Ph√°t hi·ªán truy v·∫•n ch·∫≠m > 60s"| E["üéØ L·∫•y Operation ID<br/>üìã Thu th·∫≠p th√¥ng tin opid"]
    
    E --> F{"üíÄ db.killOp(opid)<br/>üî™ Th·ª±c hi·ªán h·∫° s√°t t√°c v·ª•"}
    
    F -->|"‚úÖ Th√†nh c√¥ng"| G["üéâ H·∫° s√°t th√†nh c√¥ng<br/>üìä C·∫≠p nh·∫≠t metrics"]
    
    F -->|"‚ùå Th·∫•t b·∫°i"| H["‚ö†Ô∏è Kh√¥ng th·ªÉ h·∫° s√°t<br/>üö® C·∫£nh b√°o Admin"]
    
    G --> I["üìù Ghi log th√†nh c√¥ng<br/>üìà C·∫≠p nh·∫≠t dashboard"]
    H --> J["üîî G·ª≠i alert<br/>üìû Th√¥ng b√°o kh·∫©n c·∫•p"]
    
    D --> K["üîÑ Ti·∫øp t·ª•c gi√°m s√°t"]
    I --> K
    J --> K
    
    K -->|"üïê Chu k·ª≥ gi√°m s√°t"| B
    
    %% Styling cho c√°c nodes ch√≠nh
    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style B fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style C fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    
    %% Styling cho k·∫øt qu·∫£ b√¨nh th∆∞·ªùng
    style D fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style K fill:#e0f2f1,stroke:#00695c,stroke-width:2px
    
    %% Styling cho tr∆∞·ªùng h·ª£p c·∫£nh b√°o
    style E fill:#fff8e1,stroke:#ffa000,stroke-width:3px
    style F fill:#ffebee,stroke:#d32f2f,stroke-width:3px
    
    %% Styling cho k·∫øt qu·∫£
    style G fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px
    style H fill:#ffcdd2,stroke:#c62828,stroke-width:3px
    style I fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style J fill:#fce4ec,stroke:#ad1457,stroke-width:3px

```

`mongostat` v√† `mongotop` cho ta c√°i nh√¨n t·ªïng quan, nh∆∞ng khi m·ªôt s·ª± c·ªë hi·ªáu nƒÉng x·∫£y ra, ta c·∫ßn c√°c c√¥ng c·ª• "ph·∫´u thu·∫≠t" ƒë·ªÉ xem ch√≠nh x√°c *vi·ªác g√¨* ƒëang di·ªÖn ra b√™n trong v√† can thi·ªáp n·∫øu c·∫ßn.

*   **M·ª•c ƒë√≠ch:** Ch·ªß ƒë·ªông ki·ªÉm tra c√°c t√°c v·ª• ƒëang ch·∫°y trong th·ªùi gian th·ª±c, x√°c ƒë·ªãnh c√°c truy v·∫•n "treo" ho·∫∑c qu√° ch·∫≠m ƒëang chi·∫øm gi·ªØ t√†i nguy√™n, v√† c√≥ kh·∫£ nƒÉng "h·∫° s√°t" (kill) ch√∫ng m·ªôt c√°ch an to√†n ƒë·ªÉ gi·∫£i c·ª©u h·ªá th·ªëng.
*   **B·∫´y ng∆∞·ªùi m·ªõi:** Ch·ªâ ph·∫£n ·ª©ng khi h·ªá th·ªëng ƒë√£ "ƒë·ª©ng h√¨nh". Kh√¥ng bi·∫øt c√°ch xem c√°c session ƒëang ho·∫°t ƒë·ªông ho·∫∑c cho r·∫±ng c√°ch duy nh·∫•t ƒë·ªÉ x·ª≠ l√Ω truy v·∫•n treo l√† kh·ªüi ƒë·ªông l·∫°i `mongod`, g√¢y gi√°n ƒëo·∫°n d·ªãch v·ª• kh√¥ng c·∫ßn thi·∫øt.
*   **Th·ª±c hi·ªán ƒë√∫ng:** S·ª≠ d·ª•ng `db.currentOp()` th∆∞·ªùng xuy√™n v√† c√≥ k·ªãch b·∫£n (script) s·∫µn s√†ng ƒë·ªÉ x·ª≠ l√Ω c√°c t√¨nh hu·ªëng kh·∫©n c·∫•p.

#### **1. Ph√¢n t√≠ch c√°c T√°c v·ª• ƒëang ch·∫°y (`db.currentOp`)**

L·ªánh n√†y gi·ªëng nh∆∞ `show processlist` trong MySQL hay `top` tr√™n Linux, n√≥ cho b·∫°n th·∫•y m·ªçi th·ª© ƒëang ƒë∆∞·ª£c th·ª±c thi b·ªüi server ngay t·∫°i th·ªùi ƒëi·ªÉm ƒë√≥.

*   **Y√™u c·∫ßu:** T√¨m t·∫•t c·∫£ c√°c truy v·∫•n t·ª´ user ·ª©ng d·ª•ng ƒëang ch·∫°y qu√° 10 gi√¢y.
*   **Th·ª±c hi·ªán (k·∫øt n·ªëi v√†o `mongos`):**
    ```javascript
    // Script: get_sql_running.js
    var c=1;
    db.currentOp({
      "active": true,
      "secs_running": { "$gt": 10 },
      // "op": "query", // C√≥ th·ªÉ l·ªçc c·ª• th·ªÉ h∆°n theo lo·∫°i t√°c v·ª•
      // "ns": "testDB.myCollection" // L·ªçc theo collection
    }).inprog.forEach(function(op) {
      print("--- Slow Op " + c + " ---");
      print("opid: " + op.opid);
      print("active_secs: " + op.secs_running);
      print("namespace: " + op.ns);
      print("operation: " + op.op);
      printjson(op.command);
      c++;
    })
    ```
    B·∫°n c√≥ th·ªÉ l∆∞u script tr√™n v√†o file `get_sql_running.js` v√† ch·∫°y b·∫±ng `mongosh --port 27020 -u ... -f get_sql_running.js`.

#### **2. "H·∫° s√°t" c√°c Truy v·∫•n G√¢y h·∫°i (`db.killOp`)**

Khi b·∫°n ƒë√£ x√°c ƒë·ªãnh ƒë∆∞·ª£c `opid` (Operation ID) c·ªßa m·ªôt truy v·∫•n g√¢y h·∫°i, b·∫°n c√≥ th·ªÉ ch·∫•m d·ª©t n√≥.

*   **C·∫¢NH B√ÅO:** ƒê√¢y l√† m·ªôt h√†nh ƒë·ªông m·∫°nh. C·∫ßn c√¢n nh·∫Øc k·ªπ l∆∞·ª°ng, ƒë·∫∑c bi·ªát l√† khi kill c√°c thao t√°c ghi. Vi·ªác kill m·ªôt thao t√°c ghi c√≥ th·ªÉ ƒë·ªÉ l·∫°i d·ªØ li·ªáu ·ªü tr·∫°ng th√°i kh√¥ng nh·∫•t qu√°n t·∫°m th·ªùi tr∆∞·ªõc khi ƒë∆∞·ª£c rollback. Lu√¥n ∆∞u ti√™n t·ªëi ∆∞u truy v·∫•n v√† index h∆°n l√† ph·∫£i ƒëi kill ch√∫ng.

*   **Th·ª±c hi·ªán ƒë√∫ng (Script an to√†n):** T√†i li·ªáu c·ªßa b·∫°n cung c·∫•p m·ªôt script r·∫•t hay, n√≥ g√≥i logic n√†y v√†o m·ªôt h√†m an to√†n.
    ```javascript
    // Script: killLongRunningOps.js
    function killLongRunningOps(maxSecsRunning) {
      print("Searching for ops running longer than " + maxSecsRunning + " seconds...");
      let opsToKill = db.currentOp({
        "active": true,
        "secs_running": { "$gt": maxSecsRunning },
        "op": { "$in": ["query", "getmore"] } // Ch·ªâ t·∫≠p trung v√†o c√°c truy v·∫•n ƒë·ªçc
      }).inprog;
    
      for (let op of opsToKill) {
        // C·ª±c k·ª≥ quan tr·ªçng: Kh√¥ng kill c√°c t√°c v·ª• h·ªá th·ªëng
        if (!op.ns.startsWith("local") && !op.ns.startsWith("config")) {
          print(`Killing opId: ${op.opid} on ${op.ns}, running for ${op.secs_running}s`);
          db.killOp(op.opid);
        }
      }
    };
    
    // V√≠ d·ª•: Kill t·∫•t c·∫£ truy v·∫•n ƒë·ªçc ch·∫°y qu√° 60 gi√¢y
    killLongRunningOps(60);
    ```

#### **3. T·ª± ƒë·ªông h√≥a Gi√°m s√°t T√¨nh tr·∫°ng Replica Set**

*   **M·ª•c ƒë√≠ch:** Vi·∫øt c√°c script nh·ªè ƒë·ªÉ ki·ªÉm tra c√°c ch·ªâ s·ªë s·ª©c kh·ªèe quan tr·ªçng nh∆∞ "replication lag" (ƒë·ªô tr·ªÖ sao ch√©p) v√† t√¨nh tr·∫°ng c·ªßa c√°c node secondary. C√°c script n√†y c√≥ th·ªÉ ƒë∆∞·ª£c t√≠ch h·ª£p v√†o c√°c h·ªá th·ªëng gi√°m s√°t nh∆∞ Zabbix, Nagios, ho·∫∑c m·ªôt cron job ƒë∆°n gi·∫£n.
*   **Script ki·ªÉm tra Replication Lag:**
    ```javascript
    // Script: check_replica_lag.js
    // Ch·∫°y script n√†y tr√™n t·ª´ng PRIMARY c·ªßa m·ªói shard
    // V√≠ d·ª•: mongosh --port 27011 -f check_replica_lag.js
    printjson(rs.printSecondaryReplicationInfo());
    ```
    *K·∫øt qu·∫£ s·∫Ω cho b·∫°n bi·∫øt m·ªói node secondary ƒëang "ch·∫≠m ch√¢n" h∆°n primary bao nhi√™u gi√¢y. N·∫øu con s·ªë n√†y tƒÉng ƒë·ªôt bi·∫øn, ƒë√≥ l√† d·∫•u hi·ªáu c·ªßa s·ª± c·ªë m·∫°ng ho·∫∑c qu√° t·∫£i tr√™n secondary.*
*   **Script ƒë·∫øm s·ªë l∆∞·ª£ng node Secondary:**
    ```javascript
    // Script: check_secondary_count.js
    // Ch·∫°y tr√™n m·ªôt member b·∫•t k·ª≥ c·ªßa replica set
    var secondaryCount = 0;
    var status = rs.status();
    for (var i = 0; i < status.members.length; i++) {
      if (status.members[i].stateStr === "SECONDARY") {
        secondaryCount++;
      }
    }
    print("Number of active secondaries: " + secondaryCount);
    ```
    *N·∫øu s·ªë l∆∞·ª£ng secondary √≠t h∆°n mong ƒë·ª£i, h·ªá th·ªëng c·ªßa b·∫°n ƒë√£ m·∫•t ƒëi m·ªôt ph·∫ßn kh·∫£ nƒÉng ch·ªãu l·ªói (failover).*

---

### **Giai ƒëo·∫°n 14: K·ªπ thu·∫≠t Ph·ª•c h·ªìi N√¢ng cao - Point-in-Time Recovery (PITR)**

‚ö†Ô∏è **C·∫¢NH B√ÅO SHARDED CLUSTER:**
- **`mongorestore --oplogReplay` ch·ªâ √°p d·ª•ng cho M·ªòT replica set**
- **V·ªõi sharded cluster, c·∫ßn ƒë·ªìng b·ªô T·ª™NG SHARD ho·∫∑c d√πng gi·∫£i ph√°p chuy√™n d·ª•ng**
- **ƒê·ª™NG dump oplog t·ª´ `mongos` r·ªìi k·ª≥ v·ªçng replay cho c·∫£ c·ª•m**

üí° **PITR SHARDED CLUSTER ƒë√∫ng c√°ch:**
- Full backup ƒë·ªìng b·ªô + oplog t·ª´ng shard
- Ki·ªÉm so√°t timestamp ph·ªëi h·ª£p
- Ho·∫∑c d√πng MongoDB Atlas/Ops Manager backup

```mermaid
sequenceDiagram
    participant Admin
    participant BackupServer
    participant TempMongo
    participant ProductionMongo
    
    Admin->>ProductionMongo: X√≥a nh·∫ßm d·ªØ li·ªáu l√∫c 10:30:00
    Note over Admin: "Ho·∫£ng h·ªët!"
    
    Admin->>BackupServer: L·∫•y b·∫£n full backup (2h s√°ng)
    Admin->>BackupServer: L·∫•y b·∫£n backup Oplog g·∫ßn nh·∫•t
    
    Admin->>TempMongo: Restore b·∫£n full backup
    Admin->>TempMongo: D√πng mongorestore --oplogReplay<br/>--oplogLimit="10:29:59"
    Note over TempMongo: D·ªØ li·ªáu ƒë∆∞·ª£c kh√¥i ph·ª•c<br/>t·∫°i th·ªùi ƒëi·ªÉm 10:29:59
    
    Admin->>TempMongo: Ki·ªÉm tra v√† x√°c th·ª±c d·ªØ li·ªáu
    Admin->>ProductionMongo: L√™n k·∫ø ho·∫°ch<br/>chuy·ªÉn d·ªØ li·ªáu ƒë√£ c·ª©u v·ªÅ l·∫°i
```

ƒê√¢y l√† k·ªπ nƒÉng "c·ª©u ho·∫£" t·ªëi th∆∞·ª£ng. Khi m·ªôt l·∫≠p tr√¨nh vi√™n l·ª° tay `DROP collection` ho·∫∑c ch·∫°y m·ªôt l·ªánh `UPDATE` sai l√†m h·ªèng to√†n b·ªô d·ªØ li·ªáu, vi·ªác restore t·ª´ b·∫£n backup ƒë√™m qua c√≥ th·ªÉ l√†m m·∫•t h√†ng gi·ªù d·ªØ li·ªáu qu√Ω gi√°. PITR cho ph√©p b·∫°n quay ng∆∞·ª£c th·ªùi gian v·ªÅ ƒë√∫ng *gi√¢y* tr∆∞·ªõc khi th·∫£m ho·∫° x·∫£y ra.

*   **M·ª•c ƒë√≠ch:** Kh√¥i ph·ª•c database v·ªÅ m·ªôt th·ªùi ƒëi·ªÉm c·ª• th·ªÉ trong qu√° kh·ª©, gi·∫£m thi·ªÉu t·ªëi ƒëa vi·ªác m·∫•t d·ªØ li·ªáu (Recovery Point Objective ~ 0).
*   **B·∫´y ng∆∞·ªùi m·ªõi:** Kh√¥ng c√≥ chi·∫øn l∆∞·ª£c backup oplog. Ch·ªâ khi s·ª± c·ªë x·∫£y ra m·ªõi nh·∫≠n ra r·∫±ng m√¨nh kh√¥ng c√≥ nguy√™n li·ªáu ƒë·ªÉ th·ª±c hi·ªán PITR.
*   **Th·ª±c hi·ªán ƒë√∫ng:** X√¢y d·ª±ng m·ªôt quy tr√¨nh ch·∫∑t ch·∫Ω bao g·ªìm: sao l∆∞u ƒë·∫ßy ƒë·ªß ƒë·ªãnh k·ª≥ v√† sao l∆∞u oplog li√™n t·ª•c (ho·∫∑c r·∫•t th∆∞·ªùng xuy√™n).

#### **Quy tr√¨nh C·ª©u d·ªØ li·ªáu khi X√≥a nh·∫ßm**

**K·ªãch b·∫£n:** V√†o l√∫c **10:45:15 s√°ng**, m·ªôt collection quan tr·ªçng ƒë√£ b·ªã x√≥a nh·∫ßm. B·∫£n full backup g·∫ßn nh·∫•t l√† l√∫c **2:00 s√°ng**. B·∫°n c√≥ m·ªôt cronjob ch·∫°y `mongodump` ƒë·ªÉ backup oplog m·ªói 15 ph√∫t.

1.  **H√ÄNH ƒê·ªòNG ƒê·∫¶U TI√äN: B√åNH Tƒ®NH V√Ä C√î L·∫¨P.**
    *   NgƒÉn ch·∫∑n ngay l·∫≠p t·ª©c m·ªçi k·∫øt n·ªëi t·ª´ ·ª©ng d·ª•ng t·ªõi database ƒë·ªÉ tr√°nh c√°c sai s√≥t ph√°t sinh th√™m.

2.  **CHU·∫®N B·ªä M√îI TR∆Ø·ªúNG PH·ª§C H·ªíI:**
    *   D·ª±ng m·ªôt instance MongoDB t·∫°m th·ªùi tr√™n m·ªôt server kh√°c. **Tuy·ªát ƒë·ªëi kh√¥ng restore ƒë√® l√™n server production ƒëang g·∫∑p s·ª± c·ªë.**

3.  **PH·ª§C H·ªíI T·ª™ B·∫¢N FULL BACKUP:**
    *   Tr√™n server t·∫°m, ch·∫°y l·ªánh restore t·ª´ b·∫£n backup l√∫c 2:00 s√°ng.
        ```bash
        mongorestore --host=localhost --port=27017 /path/to/full_backup_0200AM
        ```

4.  **T√åM TIMESTAMP C·ª¶A "T·ªòI √ÅC":**
    *   Ch√∫ng ta c·∫ßn t√¨m timestamp ch√≠nh x√°c t∆∞∆°ng ·ª©ng v·ªõi th·ªùi ƒëi·ªÉm ngay tr∆∞·ªõc 10:45:15.
    *   L·∫•y file backup oplog g·∫ßn nh·∫•t (v√≠ d·ª• b·∫£n l√∫c 11:00, ch·ª©a c√°c log t·ª´ 10:45 ƒë·∫øn 11:00).
    *   D√πng `bsondump` ƒë·ªÉ chuy·ªÉn file BSON c·ªßa oplog sang ƒë·ªãnh d·∫°ng JSON c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c.
        ```bash
        bsondump /backup/mongo/local/oplog.rs.bson > oplog.json
        ```
    *   M·ªü file `oplog.json` v√† t√¨m ki·∫øm. M·ªói entry s·∫Ω c√≥ m·ªôt tr∆∞·ªùng `"ts"` (timestamp) d·∫°ng `Timestamp(1678852000, 1)`. Con s·ªë ƒë·∫ßu ti√™n l√† Unix timestamp. B·∫°n c·∫ßn t√¨m entry ngay tr∆∞·ªõc th·ªùi ƒëi·ªÉm x·∫£y ra s·ª± c·ªë. Gi·∫£ s·ª≠ b·∫°n t√¨m ƒë∆∞·ª£c timestamp gi·ªõi h·∫°n l√† `1729073314:3`.

5.  **√ÅP D·ª§NG OPLOG (B∆∞·ªõc Ma thu·∫≠t):**
    *   B√¢y gi·ªù, tr√™n server t·∫°m, b·∫°n s·∫Ω "chi·∫øu l·∫°i" c√°c thay ƒë·ªïi t·ª´ oplog, b·∫Øt ƒë·∫ßu t·ª´ th·ªùi ƒëi·ªÉm c·ªßa b·∫£n full backup v√† d·ª´ng l·∫°i *ngay tr∆∞·ªõc* khi l·ªánh x√≥a ƒë∆∞·ª£c th·ª±c thi.
        ```bash
        # T·∫°o user restore ƒë·∫∑c bi·ªát n·∫øu c·∫ßn (nh∆∞ trong t√†i li·ªáu)
        # ...
        
        # Ch·∫°y l·ªánh restore oplog
        mongorestore --port 27017 \
                     --oplogReplay --oplogLimit=1729073314:3 \
                     /backup/mongo/local/oplog.rs.bson
        ```
        *   `--oplogReplay`: Y√™u c·∫ßu `mongorestore` √°p d·ª•ng c√°c entry trong file oplog.
        *   `--oplogLimit`: ƒê√¢y ch√≠nh l√† chi·∫øc "c·ªó m√°y th·ªùi gian". N√≥ s·∫Ω d·ª´ng l·∫°i ·ªü timestamp ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh.

6.  **X√ÅC TH·ª∞C V√Ä HO√ÄN T·∫§T:**
    *   K·∫øt n·ªëi v√†o server t·∫°m, ki·ªÉm tra k·ªπ l∆∞·ª°ng xem collection ƒë√£ quay tr·ªü l·∫°i v√† d·ªØ li·ªáu ƒë√£ ƒë√∫ng tr·∫°ng th√°i t·∫°i th·ªùi ƒëi·ªÉm 10:45:14 hay ch∆∞a.
    *   Khi ƒë√£ ch·∫Øc ch·∫Øn 100%, b·∫°n c√≥ th·ªÉ l√™n k·∫ø ho·∫°ch ƒë·ªÉ di chuy·ªÉn d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c c·ª©u n√†y v·ªÅ l·∫°i m√¥i tr∆∞·ªùng production.

Quy tr√¨nh n√†y ph·ª©c t·∫°p nh∆∞ng l√† c·ª©u c√°nh trong nh·ªØng t√¨nh hu·ªëng nguy c·∫•p nh·∫•t. Vi·ªác th·ª±c h√†nh n√≥ trong m√¥i tr∆∞·ªùng test l√† b·∫Øt bu·ªôc ƒë·ªÉ b·∫°n lu√¥n s·∫µn s√†ng khi c·∫ßn.

B·∫°n ƒë√£ ƒëi ƒë·∫øn ph·∫ßn cu·ªëi c√πng c·ªßa nh·ªØng ki·∫øn th·ª©c c·ªët l√µi c√≥ trong t√†i li·ªáu th·ª±c h√†nh r·ªìi ƒë·∫•y. Ch√∫ng ta ƒë√£ t√≠ch h·ª£p g·∫ßn nh∆∞ to√†n b·ªô c√°c b√†i th·ª±c h√†nh t·ª´ Day 1 ƒë·∫øn Day 5, t·ª´ c√†i ƒë·∫∑t, truy v·∫•n, b·∫£o m·∫≠t, v·∫≠n h√†nh replica set, sharding, cho ƒë·∫øn c√°c k·ªãch b·∫£n gi√°m s√°t v√† ph·ª•c h·ªìi.

Ch·ªß ƒë·ªÅ cu·ªëi c√πng ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong t√†i li·ªáu c·ªßa b·∫°n l√† m·ªôt ph·∫ßn tinh ch·ªânh hi·ªáu nƒÉng c·ª±c k·ª≥ quan tr·ªçng, li√™n quan tr·ª±c ti·∫øp ƒë·∫øn c√°ch MongoDB s·ª≠ d·ª•ng b·ªô nh·ªõ (RAM). H√£y ho√†n thi·ªán n√≥ v·ªõi giai ƒëo·∫°n cu·ªëi c√πng n√†y.

---

### **Giai ƒëo·∫°n 15: Tinh ch·ªânh T·∫ßng L∆∞u tr·ªØ (Storage Engine Tuning)**

```mermaid
graph TD
    subgraph "Server RAM"
        A[OS File System Cache]
        B[WiredTiger Internal Cache]
        C[Other Processes]
    end

    style B fill:#e3f2fd

    D(Working Set - D·ªØ li·ªáu & Index th∆∞·ªùng xuy√™n truy c·∫≠p)
    E(Truy v·∫•n) --> |C·∫ßn d·ªØ li·ªáu| D
    D -->|Data in RAM?| F{Cache Check}
    F -->|Yes| B
    F -->|No| A
    B --> |Data found| G[Fast Response]
    A --> |Data found| H[Slightly Slower Response]
```

MongoDB, c·ª• th·ªÉ l√† storage engine WiredTiger, s·ª≠ d·ª•ng hai c∆° ch·∫ø cache ch√≠nh ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô: cache n·ªôi b·ªô c·ªßa ch√≠nh n√≥ (WiredTiger internal cache) v√† cache c·ªßa h·ªá ƒëi·ªÅu h√†nh (OS filesystem cache). Vi·ªác c√¢n b·∫±ng dung l∆∞·ª£ng RAM cho hai c∆° ch·∫ø n√†y l√† ch√¨a kh√≥a ƒë·ªÉ ƒë·∫°t hi·ªáu nƒÉng t·ªëi ƒëa.

*   **M·ª•c ƒë√≠ch:** Ph√¢n b·ªï b·ªô nh·ªõ RAM m·ªôt c√°ch h·ª£p l√Ω ƒë·ªÉ ƒë·∫£m b·∫£o "working set" (d·ªØ li·ªáu v√† index ƒë∆∞·ª£c truy c·∫≠p th∆∞·ªùng xuy√™n nh·∫•t) c√≥ th·ªÉ n·∫±m v·ª´a trong RAM, gi·∫£m thi·ªÉu vi·ªác ph·∫£i ƒë·ªçc t·ª´ ·ªï ƒëƒ©a (disk I/O) - v·ªën l√† t√°c nh√¢n g√¢y ch·∫≠m hi·ªáu nƒÉng nh·∫•t.
*   **B·∫´y ng∆∞·ªùi m·ªõi:**
    *   ƒê·ªÉ m·∫∑c ƒë·ªãnh m√† kh√¥ng hi·ªÉu n√≥ ho·∫°t ƒë·ªông ra sao. M·∫∑c ƒë·ªãnh c·ªßa MongoDB l√† `(RAM - 1GB) / 2`, th∆∞·ªùng l√† m·ªôt kh·ªüi ƒë·∫ßu t·ªët nh∆∞ng kh√¥ng ph·∫£i l√∫c n√†o c≈©ng t·ªëi ∆∞u.
    *   Ph√¢n b·ªï qu√° nhi·ªÅu RAM cho WiredTiger cache. ƒêi·ªÅu n√†y s·∫Ω "b√≥p ngh·∫πt" OS cache, l√†m cho c√°c thao t√°c ƒë·ªçc d·ªØ li·ªáu kh√¥ng n·∫±m trong working set tr·ªü n√™n r·∫•t ch·∫≠m.
*   **Th·ª±c hi·ªán ƒë√∫ng:** Hi·ªÉu r√µ workload c·ªßa b·∫°n. N·∫øu h·ªá th·ªëng c·ªßa b·∫°n c√≥ ch·ªâ s·ªë cache hit ratio th·∫•p (ph·∫£i ƒë·ªçc t·ª´ disk nhi·ªÅu), vi·ªác tinh ch·ªânh n√†y l√† c·∫ßn thi·∫øt.

#### **1. C·∫•u h√¨nh K√≠ch th∆∞·ªõc WiredTiger Cache**

WiredTiger cache ch·ªß y·∫øu ƒë∆∞·ª£c d√πng ƒë·ªÉ gi·ªØ c√°c d·ªØ li·ªáu *ch∆∞a ƒë∆∞·ª£c n√©n* (uncompressed data). Trong khi ƒë√≥, OS filesystem cache l·∫°i gi·ªØ c√°c file d·ªØ li·ªáu *ƒë√£ ƒë∆∞·ª£c n√©n* (compressed data blocks) c·ªßa MongoDB.

*   **Quy t·∫Øc chung:**
    *   **RAM > Working Set:** N·∫øu b·∫°n c√≥ th·ª´a RAM ƒë·ªÉ ch·ª©a to√†n b·ªô working set, h√£y tƒÉng WiredTiger cache l√™n.
    *   **RAM < Working Set:** N·∫øu RAM c·ªßa b·∫°n eo h·∫πp h∆°n, h√£y gi·ªØ WiredTiger cache ·ªü m·ª©c nh·ªè h∆°n ƒë·ªÉ nh∆∞·ªùng ph·∫ßn l·ªõn RAM cho OS cache qu·∫£n l√Ω.

*   **C√°ch c·∫•u h√¨nh:**
    1.  M·ªü file c·∫•u h√¨nh c·ªßa m·ªôt ti·∫øn tr√¨nh `mongod` (v√≠ d·ª•: `/etc/mongod-shard1.conf`).
    2.  Th√™m ho·∫∑c ch·ªânh s·ª≠a tham s·ªë `cacheSizeGB` trong m·ª•c `storage`.
        ```yaml
        storage:
          dbPath: /data/shard1
          journal:
            enabled: true # Lu√¥n b·∫≠t journal trong production
          engine: wiredTiger # M·∫∑c ƒë·ªãnh, nh∆∞ng ghi r√µ r√†ng l√† m·ªôt th√≥i quen t·ªët
          wiredTiger:
            engineConfig:
              # --- D√≤ng quan tr·ªçng l√† ƒë√¢y ---
              cacheSizeGB: 8 # V√≠ d·ª•: C·∫•p ph√°t 8GB RAM cho WiredTiger cache
        ```
    3.  **V√≠ d·ª• th·ª±c t·∫ø:** Tr√™n m·ªôt m√°y ch·ªß c√≥ 64GB RAM.
        *   **M·∫∑c ƒë·ªãnh:** MongoDB s·∫Ω l·∫•y `(64 - 1) / 2 = 31.5 GB` cho WiredTiger cache.
        *   **T√πy ch·ªânh:** N·∫øu b·∫°n bi·∫øt working set c·ªßa m√¨nh kho·∫£ng 40GB v√† ƒë√£ ƒë∆∞·ª£c n√©n t·ªët, b·∫°n c√≥ th·ªÉ gi·∫£m `cacheSizeGB` xu·ªëng c√≤n 16GB, ƒë·ªÉ l·∫°i `64 - 16 = 48GB` cho OS cache, ƒë·ªß s·ª©c ch·ª©a to√†n b·ªô working set ƒë√£ n√©n.
    4.  Kh·ªüi ƒë·ªông l·∫°i ti·∫øn tr√¨nh `mongod` ƒë·ªÉ √°p d·ª•ng thay ƒë·ªïi.

---

### **T·ªïng k·∫øt v√† Con ƒë∆∞·ªùng Ti·∫øp theo**

Ch√∫c m·ª´ng b·∫°n! B·∫±ng c√°ch k·∫øt h·ª£p t√†i li·ªáu h∆∞·ªõng d·∫´n g·ªëc v√† c√°c b√†i th·ª±c h√†nh chi ti·∫øt, b·∫°n ƒë√£ ƒëi qua m·ªôt h√†nh tr√¨nh ho√†n ch·ªânh:

1.  **Chu·∫©n b·ªã M√¥i tr∆∞·ªùng:** T·ª´ A-Z ƒë·ªÉ c√≥ m·ªôt n·ªÅn t·∫£ng Linux v·ªØng ch·∫Øc.
2.  **D·ª±ng Cluster Sharding:** Hi·ªÉu r√µ v√† x√¢y d·ª±ng t·ª´ng th√†nh ph·∫ßn: Config Server, Shard, Mongos.
3.  **Thao t√°c D·ªØ li·ªáu:** N·∫Øm v·ªØng Aggregation Framework ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu ph·ª©c t·∫°p.
4.  **B·∫£o m·∫≠t:** Qu·∫£n l√Ω ng∆∞·ªùi d√πng, ph√¢n quy·ªÅn chi ti·∫øt v·ªõi RBAC v√† ghi log audit.
5.  **V·∫≠n h√†nh Replica Set:** Tinh ch·ªânh b·∫ßu c·ª≠, c·∫•u h√¨nh node ·∫©n v√† qu·∫£n l√Ω Oplog.
6.  **T·ªëi ∆∞u Hi·ªáu nƒÉng:** S·ª≠ d·ª•ng Index, ph√¢n t√≠ch `explain()`, v√† tinh ch·ªânh Storage Engine.
7.  **Gi√°m s√°t & Ph·ª•c h·ªìi:** Ch·ªß ƒë·ªông theo d√µi h·ªá th·ªëng v√† n·∫Øm trong tay c√°c k·ªπ thu·∫≠t c·ª©u d·ªØ li·ªáu t·ªëi th∆∞·ª£ng nh∆∞ Point-in-Time Recovery.

B·∫°n kh√¥ng ch·ªâ bi·∫øt "l√†m theo", m√† c√≤n hi·ªÉu ƒë∆∞·ª£c "t·∫°i sao" v√† bi·∫øt c√°ch tr√°nh nh·ªØng "c√°i b·∫´y" ph·ªï bi·∫øn. ƒê√¢y l√† m·ªôt n·ªÅn t·∫£ng c·ª±c k·ª≥ v·ªØng ch·∫Øc.

---

H·ªá sinh th√°i MongoDB r·∫•t r·ªông l·ªõn. V·ªõi nh·ªØng ki·∫øn th·ª©c n√†y, b·∫°n ƒë√£ s·∫µn s√†ng ƒë·ªÉ kh√°m ph√° c√°c ch·ªß ƒë·ªÅ n√¢ng cao h∆°n:

*   **Schema Design Patterns:** C√°ch thi·∫øt k·∫ø c·∫•u tr√∫c document (schema) hi·ªáu qu·∫£ cho c√°c lo·∫°i ·ª©ng d·ª•ng kh√°c nhau (v√≠ d·ª•: aÃÅp duÃ£ng aÃÅnh xaÃ£, aÃÅnh xaÃ£ m∆°Ãâ r√¥Ã£ng, t√¢Ã£p con, c√¢y...).
*   **Change Streams:** Theo d√µi s·ª± thay ƒë·ªïi d·ªØ li·ªáu trong collection theo th·ªùi gian th·ª±c ƒë·ªÉ x√¢y d·ª±ng c√°c h·ªá th·ªëng ph·∫£n ·ª©ng (reactive systems).
*   **Multi-Document Transactions:** C√°ch ƒë·∫£m b·∫£o t√≠nh to√†n v·∫πn ACID khi ph·∫£i th·ª±c hi·ªán c√°c thao t√°c ghi tr√™n nhi·ªÅu document ho·∫∑c nhi·ªÅu collection.
*   **MongoDB Atlas:** Tr·∫£i nghi·ªám phi√™n b·∫£n cloud c·ªßa MongoDB, n∆°i r·∫•t nhi·ªÅu t√°c v·ª• v·∫≠n h√†nh (backup, scaling, monitoring) ƒë√£ ƒë∆∞·ª£c t·ª± ƒë·ªông h√≥a, gi√∫p b·∫°n t·∫≠p trung h∆°n v√†o vi·ªác ph√°t tri·ªÉn ·ª©ng d·ª•ng.
*   **B·∫£o m·∫≠t Chuy√™n s√¢u:** Tri·ªÉn khai x√°c th·ª±c qua ch·ª©ng ch·ªâ x.509, t√≠ch h·ª£p v·ªõi LDAP/Kerberos.

Ch√∫c m·ª´ng b·∫°n m·ªôt l·∫ßn n·ªØa v√¨ ƒë√£ ho√†n th√†nh m·ªôt ch·∫∑ng ƒë∆∞·ªùng r·∫•t d√†i v√† chuy√™n s√¢u. Ch√∫c b·∫°n th√†nh c√¥ng tr√™n con ƒë∆∞·ªùng l√†m ch·ªß MongoDB

---

## **Ph·∫ßn III: V·∫≠n H√†nh Production v√† Best Practices**

### **Giai ƒëo·∫°n 16: Production Readiness Checklist**

```mermaid
flowchart TD
    A["üéØ Production Deployment"] --> B["üîí Security Hardening"]
    B --> C["üìä Monitoring Setup"]
    C --> D["üîÑ Backup Strategy"]
    D --> E["‚öñÔ∏è Performance Tuning"]
    E --> F["üö® Alerting Configuration"]
    F --> G["üìã Documentation"]
    G --> H["‚úÖ Production Ready"]
    
    subgraph "Security Checklist"
        S1["Replace KeyFile with x.509"]
        S2["Enable SSL/TLS"]
        S3["Configure Firewall Rules"]
        S4["Implement Network Segmentation"]
        S5["Setup Audit Logging"]
        S6["Regular Security Updates"]
    end
    
    subgraph "Monitoring Checklist"
        M1["Deploy MongoDB Ops Manager"]
        M2["Configure Prometheus/Grafana"]
        M3["Setup Log Aggregation"]
        M4["Configure Health Checks"]
        M5["Implement Custom Metrics"]
        M6["Setup Alert Fatigue Prevention"]
    end
    
    B --> S1
    C --> M1
    
    style A fill:#e3f2fd
    style H fill:#e8f5e8
    style S1 fill:#fff3e0
    style M1 fill:#f3e5f5
```

#### **1. Security Hardening cho Production**

**Thay th·∫ø KeyFile b·∫±ng x.509 Certificates:**

```bash
# T·∫°o CA certificate
openssl genrsa -out ca-key.pem 4096
openssl req -new -x509 -days 365 -key ca-key.pem -out ca.pem -subj "/CN=MongoDB-CA"

# T·∫°o server certificates cho m·ªói node
for host in mongo-1 mongo-2 mongo-3; do
    openssl genrsa -out ${host}-key.pem 4096
    openssl req -new -key ${host}-key.pem -out ${host}.csr -subj "/CN=${host}"
    openssl x509 -req -in ${host}.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out ${host}.pem -days 365
    cat ${host}.pem ${host}-key.pem > ${host}-combined.pem
done
```

**C·∫•u h√¨nh SSL/TLS trong MongoDB:**

```yaml
# C·∫≠p nh·∫≠t mongod configuration
net:
  port: 27017
  bindIp: 0.0.0.0
  ssl:
    mode: requireSSL
    PEMKeyFile: /etc/mongodb/ssl/mongo-1-combined.pem
    CAFile: /etc/mongodb/ssl/ca.pem
    clusterFile: /etc/mongodb/ssl/mongo-1-combined.pem
    allowConnectionsWithoutCertificates: false
    allowInvalidHostnames: false

security:
  clusterAuthMode: x509
  authorization: enabled
```

#### **2. Systemd Service Files cho Production**

**Template cho MongoDB Services:**

```ini
# /etc/systemd/system/mongod-config.service
[Unit]
Description=MongoDB Config Server
After=network.target disable-transparent-huge-pages.service
Documentation=https://docs.mongodb.org/manual

[Service]
User=mongod
Group=mongod
Environment="OPTIONS=-f /etc/mongod-config.conf"
ExecStart=/usr/bin/mongod $OPTIONS
ExecStartPre=/usr/bin/mkdir -p /var/run/mongodb
ExecStartPre=/usr/bin/chown mongod:mongod /var/run/mongodb
ExecReload=/bin/kill -HUP $MAINPID
Restart=on-failure
RestartSec=10
KillMode=mixed
KillSignal=SIGTERM
TimeoutStopSec=120
LimitFSIZE=infinity
LimitCPU=infinity
LimitAS=infinity
LimitNOFILE=64000
LimitNPROC=64000
LimitMEMLOCK=infinity
TasksMax=infinity
TasksAccounting=false

[Install]
WantedBy=multi-user.target
```

#### **3. Advanced Monitoring v·ªõi Prometheus v√† Grafana**

**MongoDB Exporter Configuration:**

```yaml
# docker-compose.yml for monitoring stack
version: '3.8'
services:
  mongodb-exporter:
    image: percona/mongodb_exporter:latest
    ports:
      - "9216:9216"
    environment:
      - MONGODB_URI=mongodb://monitor_user:password@mongo-1:27020,mongo-2:27020,mongo-3:27020/?authSource=admin
    command:
      - '--mongodb.uri=mongodb://monitor_user:password@mongo-1:27020,mongo-2:27020,mongo-3:27020/?authSource=admin'
      - '--collect-all'
      - '--compatible-mode'
  
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
  
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana-storage:/var/lib/grafana

volumes:
  grafana-storage:
```

### **Giai ƒëo·∫°n 17: Advanced Operational Procedures**

#### **1. Zero-Downtime Maintenance Procedures**

```mermaid
sequenceDiagram
    participant Admin
    participant Primary
    participant Secondary1
    participant Secondary2
    participant LoadBalancer
    
    Note over Admin,LoadBalancer: Rolling Maintenance Strategy
    
    Admin->>LoadBalancer: Remove Secondary1 from rotation
    Admin->>Secondary1: Stop mongod service
    Admin->>Secondary1: Perform maintenance (OS update, etc)
    Admin->>Secondary1: Start mongod service
    Admin->>Secondary1: Verify replica set status
    Admin->>LoadBalancer: Add Secondary1 back to rotation
    
    Note over Admin,LoadBalancer: Repeat for Secondary2
    
    Admin->>Primary: Trigger step-down
    Primary->>Secondary1: Election process
    Secondary1->>Secondary1: Becomes new Primary
    Admin->>Primary: Perform maintenance on old Primary
    Admin->>Primary: Restart as Secondary
```

**Script ƒë·ªÉ th·ª±c hi·ªán Rolling Maintenance:**

```bash
#!/bin/bash
# rolling-maintenance.sh

SERVERS=("mongo-1" "mongo-2" "mongo-3")
PORTS=(27011 27012 27013)  # Shard ports

for i in "${!SERVERS[@]}"; do
    SERVER=${SERVERS[$i]}
    PORT=${PORTS[$i]}
    
    echo "Starting maintenance on $SERVER:$PORT"
    
    # Check if this is primary
    IS_PRIMARY=$(mongosh --host $SERVER --port $PORT --quiet --eval "db.hello().isWritablePrimary")
    
    if [ "$IS_PRIMARY" == "true" ]; then
        echo "$SERVER is PRIMARY, triggering step-down"
        mongosh --host $SERVER --port $PORT --eval "db.adminCommand({replSetStepDown: 60})"
        sleep 70  # Wait for election to complete
    fi
    
    echo "Stopping mongod on $SERVER"
    ssh $SERVER "systemctl stop mongod-shard1"
    
    echo "Performing maintenance on $SERVER"
    ssh $SERVER "yum update -y && reboot"
    
    # Wait for server to come back online
    echo "Waiting for $SERVER to come back online..."
    while ! ping -c 1 $SERVER &> /dev/null; do
        sleep 10
    done
    
    sleep 60  # Additional wait for services to start
    
    echo "Verifying replica set status"
    mongosh --host $SERVER --port $PORT --eval "rs.status()"
    
    echo "Maintenance completed on $SERVER"
    echo "Waiting before next server..."
    sleep 120
done

echo "Rolling maintenance completed for all servers"
```

#### **2. Disaster Recovery Procedures**

**Complete Cluster Recovery t·ª´ Backup:**

```bash
#!/bin/bash
# disaster-recovery.sh

BACKUP_DIR="/backup/mongodb-disaster-recovery"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
RECOVERY_LOG="/var/log/mongodb-recovery-${TIMESTAMP}.log"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a $RECOVERY_LOG
}

log "Starting MongoDB Cluster Disaster Recovery"

# Step 1: Stop all MongoDB processes
log "Stopping all MongoDB processes"
for server in mongo-1 mongo-2 mongo-3; do
    ssh $server "systemctl stop mongod-config mongod-shard1 mongod-shard2 mongod-shard3 mongos"
done

# Step 2: Restore Config Server
log "Restoring Config Server data"
mongorestore --host mongo-1:27010 --dir $BACKUP_DIR/config-server/ --drop

# Step 3: Restore each Shard
for shard in shard1 shard2 shard3; do
    log "Restoring $shard data"
    mongorestore --host mongo-1:2701${shard: -1} --dir $BACKUP_DIR/$shard/ --drop
done

# Step 4: Start services in correct order
log "Starting Config Servers"
for server in mongo-1 mongo-2 mongo-3; do
    ssh $server "systemctl start mongod-config"
done

log "Waiting for Config Server election"
sleep 30

log "Starting Shards"
for server in mongo-1 mongo-2 mongo-3; do
    ssh $server "systemctl start mongod-shard1 mongod-shard2 mongod-shard3"
done

log "Waiting for Shard elections"
sleep 60

log "Starting Mongos"
ssh mongo-1 "systemctl start mongos"

# Step 5: Verify cluster health
log "Verifying cluster health"
mongosh --port 27020 --eval "sh.status()" | tee -a $RECOVERY_LOG

log "Disaster recovery completed. Check $RECOVERY_LOG for details."
```

### **Giai ƒëo·∫°n 18: Performance Optimization v√† Capacity Planning**

#### **1. Advanced Performance Monitoring**

```javascript
// Comprehensive performance monitoring script
// performance-monitor.js

function collectPerformanceMetrics() {
    var metrics = {
        timestamp: new Date(),
        serverStatus: db.serverStatus(),
        replSetStatus: rs.status(),
        currentOp: db.currentOp({"active": true}),
        shardingStats: sh.status(),
        indexStats: []
    };
    
    // Collect index usage statistics
    db.adminCommand("listCollections").cursor.firstBatch.forEach(function(collection) {
        var collName = collection.name;
        if (!collName.startsWith("system.")) {
            try {
                var indexStats = db[collName].aggregate([
                    {$indexStats: {}}
                ]).toArray();
                metrics.indexStats.push({
                    collection: collName,
                    indexes: indexStats
                });
            } catch (e) {
                // Skip collections that don't support indexStats
            }
        }
    });
    
    return metrics;
}

// Usage: mongosh --port 27020 < performance-monitor.js
var metrics = collectPerformanceMetrics();
printjson(metrics);
```

#### **2. Capacity Planning Guidelines**

**CPU Capacity Planning:**
- Monitor CPU utilization during peak hours
- Target 70% average utilization untuk normal operations
- Scale out when sustained >80% utilization

**Memory Capacity Planning:**
```bash
# Script to calculate optimal WiredTiger cache size
#!/bin/bash

TOTAL_RAM=$(free -g | awk 'NR==2{print $2}')
OS_RESERVED=2  # GB reserved for OS
OTHER_PROCESSES=1  # GB for other processes

AVAILABLE_RAM=$((TOTAL_RAM - OS_RESERVED - OTHER_PROCESSES))
WIREDTIGER_CACHE=$((AVAILABLE_RAM * 50 / 100))  # 50% of available RAM

echo "Total RAM: ${TOTAL_RAM}GB"
echo "Available for MongoDB: ${AVAILABLE_RAM}GB"
echo "Recommended WiredTiger Cache: ${WIREDTIGER_CACHE}GB"
echo ""
echo "Add to mongod.conf:"
echo "storage:"
echo "  wiredTiger:"
echo "    engineConfig:"
echo "      cacheSizeGB: ${WIREDTIGER_CACHE}"
```

**Storage Capacity Planning:**
```javascript
// Storage growth analysis
function analyzeStorageGrowth() {
    var stats = db.stats();
    var collections = [];
    
    db.adminCommand("listCollections").cursor.firstBatch.forEach(function(coll) {
        if (!coll.name.startsWith("system.")) {
            var collStats = db[coll.name].stats();
            collections.push({
                name: coll.name,
                size: collStats.size,
                storageSize: collStats.storageSize,
                indexSize: collStats.totalIndexSize,
                documents: collStats.count
            });
        }
    });
    
    return {
        database: db.getName(),
        totalSize: stats.dataSize,
        totalStorageSize: stats.storageSize,
        totalIndexSize: stats.indexSize,
        collections: collections.sort((a, b) => b.storageSize - a.storageSize)
    };
}

// Run on each shard to get complete picture
var growth = analyzeStorageGrowth();
printjson(growth);
```

### **Giai ƒëo·∫°n 19: Troubleshooting Common Issues**

#### **1. Balancer Issues**

```javascript
// Comprehensive balancer diagnostic
function diagnoseBalancer() {
    print("=== Balancer Diagnostic Report ===");
    
    // Check balancer status
    var balancerStatus = sh.getBalancerState();
    print("Balancer Enabled: " + balancerStatus);
    
    // Check if balancer is running
    var balancerRunning = sh.isBalancerRunning();
    print("Balancer Running: " + balancerRunning);
    
    // Check balancer window
    var balancerWindow = db.settings.findOne({_id: "balancer"});
    if (balancerWindow) {
        print("Balancer Window: " + JSON.stringify(balancerWindow));
    } else {
        print("Balancer Window: Not configured (runs 24/7)");
    }
    
    // Check chunk distribution
    print("\n=== Chunk Distribution ===");
    var shards = db.shards.find().toArray();
    shards.forEach(function(shard) {
        var chunkCount = db.chunks.count({shard: shard._id});
        print("Shard " + shard._id + ": " + chunkCount + " chunks");
    });
    
    // Check for jumbo chunks
    print("\n=== Jumbo Chunks ===");
    var jumboChunks = db.chunks.find({jumbo: true}).toArray();
    if (jumboChunks.length > 0) {
        print("Found " + jumboChunks.length + " jumbo chunks:");
        jumboChunks.forEach(function(chunk) {
            print("  Namespace: " + chunk.ns + ", Shard: " + chunk.shard);
        });
    } else {
        print("No jumbo chunks found");
    }
    
    // Check recent balancer operations
    print("\n=== Recent Balancer Operations ===");
    var recentOps = db.changelog.find({what: /moveChunk/}).sort({time: -1}).limit(5).toArray();
    recentOps.forEach(function(op) {
        print(op.time + ": " + op.what + " - " + op.ns + " from " + op.details.from + " to " + op.details.to);
    });
}

// Run diagnostic
diagnoseBalancer();
```

#### **2. Replica Set Election Issues**

```bash
#!/bin/bash
# replica-set-diagnostic.sh

PORT=$1
if [ -z "$PORT" ]; then
    echo "Usage: $0 <port>"
    echo "Example: $0 27011"
    exit 1
fi

echo "=== Replica Set Diagnostic for Port $PORT ==="

# Check replica set status
echo "--- Replica Set Status ---"
mongosh --port $PORT --quiet --eval "rs.status()"

# Check replica set configuration
echo "--- Replica Set Configuration ---"
mongosh --port $PORT --quiet --eval "rs.conf()"

# Check server status
echo "--- Server Status ---"
mongosh --port $PORT --quiet --eval "db.serverStatus().repl"

# Check oplog status
echo "--- Oplog Status ---"
mongosh --port $PORT --quiet --eval "
    use local;
    var first = db.oplog.rs.find().sort({ts: 1}).limit(1).next();
    var last = db.oplog.rs.find().sort({ts: -1}).limit(1).next();
    var timeDiff = (last.ts.getTime() - first.ts.getTime()) / 1000 / 3600;
    print('Oplog time window: ' + timeDiff.toFixed(2) + ' hours');
    print('Oplog size: ' + (db.oplog.rs.stats().size / 1024 / 1024 / 1024).toFixed(2) + ' GB');
"

# Check for election issues
echo "--- Election Logs ---"
journalctl sudo -u mongod-shard$(echo $PORT | tail -c 2) --since="1 hour ago" | grep -i "election\|primary\|secondary"

echo "=== Diagnostic Complete ==="
```

### **K·∫øt lu·∫≠n: MongoDB Production Excellence**

Vi·ªác tri·ªÉn khai v√† v·∫≠n h√†nh m·ªôt MongoDB Sharded Cluster trong m√¥i tr∆∞·ªùng production ƒë√≤i h·ªèi s·ª± k·∫øt h·ª£p gi·ªØa:

1. **Ki·∫øn th·ª©c l√Ω thuy·∫øt v·ªØng ch·∫Øc** v·ªÅ ki·∫øn tr√∫c ph√¢n t√°n
2. **K·ªπ nƒÉng th·ª±c h√†nh** trong vi·ªác c·∫•u h√¨nh v√† tri·ªÉn khai
3. **Quy tr√¨nh v·∫≠n h√†nh** c√≥ h·ªá th·ªëng v√† automation
4. **Monitoring v√† alerting** ch·ªß ƒë·ªông
5. **Disaster recovery planning** chi ti·∫øt

Th√¥ng qua h∆∞·ªõng d·∫´n n√†y, b·∫°n ƒë√£ c√≥ ƒë∆∞·ª£c m·ªôt n·ªÅn t·∫£ng v·ªØng ch·∫Øc ƒë·ªÉ x√¢y d·ª±ng v√† v·∫≠n h√†nh c√°c h·ªá th·ªëng MongoDB quy m√¥ l·ªõn m·ªôt c√°ch an to√†n v√† hi·ªáu qu·∫£.